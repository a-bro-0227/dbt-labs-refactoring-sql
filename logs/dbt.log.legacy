2022-04-21 01:12:11.942182 (MainThread): Running with dbt=1.0.4
2022-04-21 01:12:12.159779 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-04-21 01:12:12.174109 (MainThread): Tracking: tracking
2022-04-21 01:12:12.174346 (MainThread): 01:12:12  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cb271b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3894f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3890a0>]}
2022-04-21 01:12:12.174628 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=22
2022-04-21 01:12:12.174857 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-04-21 01:12:12.175009 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-04-21 01:12:12.177275 (Thread-12): 01:12:12  Partial parse save file not found. Starting full parse.
2022-04-21 01:12:12.177507 (Thread-12): 01:12:12  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e393040>]}
2022-04-21 01:12:12.204569 (Thread-12): 01:12:12  Parsing macros/adapters.sql
2022-04-21 01:12:12.242666 (Thread-12): 01:12:12  Parsing macros/catalog.sql
2022-04-21 01:12:12.244523 (Thread-12): 01:12:12  Parsing macros/materializations/table.sql
2022-04-21 01:12:12.247531 (Thread-12): 01:12:12  Parsing macros/materializations/seed.sql
2022-04-21 01:12:12.252581 (Thread-12): 01:12:12  Parsing macros/materializations/incremental.sql
2022-04-21 01:12:12.260739 (Thread-12): 01:12:12  Parsing macros/materializations/merge.sql
2022-04-21 01:12:12.264413 (Thread-12): 01:12:12  Parsing macros/materializations/snapshot.sql
2022-04-21 01:12:12.265327 (Thread-12): 01:12:12  Parsing macros/materializations/view.sql
2022-04-21 01:12:12.266610 (Thread-12): 01:12:12  Parsing macros/adapters/metadata.sql
2022-04-21 01:12:12.273483 (Thread-12): 01:12:12  Parsing macros/adapters/columns.sql
2022-04-21 01:12:12.283023 (Thread-12): 01:12:12  Parsing macros/adapters/freshness.sql
2022-04-21 01:12:12.285805 (Thread-12): 01:12:12  Parsing macros/adapters/persist_docs.sql
2022-04-21 01:12:12.290040 (Thread-12): 01:12:12  Parsing macros/adapters/relation.sql
2022-04-21 01:12:12.299364 (Thread-12): 01:12:12  Parsing macros/adapters/schema.sql
2022-04-21 01:12:12.301446 (Thread-12): 01:12:12  Parsing macros/adapters/indexes.sql
2022-04-21 01:12:12.304097 (Thread-12): 01:12:12  Parsing macros/get_custom_name/get_custom_schema.sql
2022-04-21 01:12:12.306529 (Thread-12): 01:12:12  Parsing macros/get_custom_name/get_custom_alias.sql
2022-04-21 01:12:12.308005 (Thread-12): 01:12:12  Parsing macros/get_custom_name/get_custom_database.sql
2022-04-21 01:12:12.309551 (Thread-12): 01:12:12  Parsing macros/etc/datetime.sql
2022-04-21 01:12:12.317602 (Thread-12): 01:12:12  Parsing macros/etc/statement.sql
2022-04-21 01:12:12.321857 (Thread-12): 01:12:12  Parsing macros/generic_test_sql/unique.sql
2022-04-21 01:12:12.322545 (Thread-12): 01:12:12  Parsing macros/generic_test_sql/not_null.sql
2022-04-21 01:12:12.323125 (Thread-12): 01:12:12  Parsing macros/generic_test_sql/accepted_values.sql
2022-04-21 01:12:12.324458 (Thread-12): 01:12:12  Parsing macros/generic_test_sql/relationships.sql
2022-04-21 01:12:12.325304 (Thread-12): 01:12:12  Parsing macros/materializations/configs.sql
2022-04-21 01:12:12.327557 (Thread-12): 01:12:12  Parsing macros/materializations/hooks.sql
2022-04-21 01:12:12.331304 (Thread-12): 01:12:12  Parsing macros/materializations/models/table/table.sql
2022-04-21 01:12:12.338559 (Thread-12): 01:12:12  Parsing macros/materializations/models/table/create_table_as.sql
2022-04-21 01:12:12.341344 (Thread-12): 01:12:12  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-04-21 01:12:12.343964 (Thread-12): 01:12:12  Parsing macros/materializations/models/view/helpers.sql
2022-04-21 01:12:12.345232 (Thread-12): 01:12:12  Parsing macros/materializations/models/view/create_view_as.sql
2022-04-21 01:12:12.347482 (Thread-12): 01:12:12  Parsing macros/materializations/models/view/view.sql
2022-04-21 01:12:12.354364 (Thread-12): 01:12:12  Parsing macros/materializations/models/incremental/incremental.sql
2022-04-21 01:12:12.365798 (Thread-12): 01:12:12  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-04-21 01:12:12.380897 (Thread-12): 01:12:12  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-04-21 01:12:12.382337 (Thread-12): 01:12:12  Parsing macros/materializations/models/incremental/merge.sql
2022-04-21 01:12:12.393301 (Thread-12): 01:12:12  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-04-21 01:12:12.397575 (Thread-12): 01:12:12  Parsing macros/materializations/seeds/helpers.sql
2022-04-21 01:12:12.413440 (Thread-12): 01:12:12  Parsing macros/materializations/seeds/seed.sql
2022-04-21 01:12:12.419212 (Thread-12): 01:12:12  Parsing macros/materializations/tests/helpers.sql
2022-04-21 01:12:12.420931 (Thread-12): 01:12:12  Parsing macros/materializations/tests/test.sql
2022-04-21 01:12:12.425200 (Thread-12): 01:12:12  Parsing macros/materializations/tests/where_subquery.sql
2022-04-21 01:12:12.426934 (Thread-12): 01:12:12  Parsing macros/materializations/snapshots/helpers.sql
2022-04-21 01:12:12.437950 (Thread-12): 01:12:12  Parsing macros/materializations/snapshots/strategies.sql
2022-04-21 01:12:12.454207 (Thread-12): 01:12:12  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-04-21 01:12:12.455831 (Thread-12): 01:12:12  Parsing macros/materializations/snapshots/snapshot.sql
2022-04-21 01:12:12.467002 (Thread-12): 01:12:12  Parsing tests/generic/builtin.sql
2022-04-21 01:12:12.660078 (Thread-12): 01:12:12  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-04-21 01:12:12.672010 (Thread-12): 01:12:12  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-04-21 01:12:12.748784 (Thread-12): 01:12:12  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1d4610>]}
2022-04-21 01:12:13.226265 (Thread-13): handling status request
2022-04-21 01:12:13.226600 (Thread-13): 01:12:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6c05b370>]}
2022-04-21 01:12:13.227573 (Thread-13): sending response (<Response 15565 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:12:13.231114 (Thread-14): handling status request
2022-04-21 01:12:13.231331 (Thread-14): 01:12:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3891f0>]}
2022-04-21 01:12:13.232005 (Thread-14): sending response (<Response 15565 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:12:46.043423 (Thread-15): handling status request
2022-04-21 01:12:46.044982 (Thread-15): 01:12:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1d4250>]}
2022-04-21 01:12:46.045809 (Thread-15): sending response (<Response 15565 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:12:48.555483 (Thread-16): 01:12:48  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-21 01:12:48.555663 (Thread-16): 01:12:48  Partial parsing enabled, no changes found, skipping parsing
2022-04-21 01:12:48.560300 (Thread-16): 01:12:48  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f16a550>]}
2022-04-21 01:12:49.249872 (Thread-17): handling status request
2022-04-21 01:12:49.250186 (Thread-17): 01:12:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f15ff70>]}
2022-04-21 01:12:49.250629 (Thread-17): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:12:49.321475 (Thread-18): handling status request
2022-04-21 01:12:49.321693 (Thread-18): 01:12:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f15fe20>]}
2022-04-21 01:12:49.322033 (Thread-18): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:15.622157 (Thread-19): 01:19:15  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-21 01:19:15.623652 (Thread-19): 01:19:15  Partial parsing enabled, no changes found, skipping parsing
2022-04-21 01:19:15.628520 (Thread-19): 01:19:15  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0eb6d0>]}
2022-04-21 01:19:16.390842 (Thread-20): handling status request
2022-04-21 01:19:16.391194 (Thread-20): 01:19:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1ec6a0>]}
2022-04-21 01:19:16.391647 (Thread-20): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:16.412436 (Thread-21): handling status request
2022-04-21 01:19:16.412657 (Thread-21): 01:19:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1ec880>]}
2022-04-21 01:19:16.413030 (Thread-21): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:42.385407 (Thread-22): 01:19:42  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-21 01:19:42.387413 (Thread-22): 01:19:42  Partial parsing enabled, no changes found, skipping parsing
2022-04-21 01:19:42.393202 (Thread-22): 01:19:42  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1f8190>]}
2022-04-21 01:19:43.145106 (Thread-23): handling status request
2022-04-21 01:19:43.145506 (Thread-23): 01:19:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0e2640>]}
2022-04-21 01:19:43.145972 (Thread-23): sending response (<Response 1219 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:43.162260 (Thread-24): handling list request
2022-04-21 01:19:43.162482 (Thread-24): 01:19:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f16bf70>]}
2022-04-21 01:19:43.195535 (Thread-24): 01:19:43  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1d4a00>]}
2022-04-21 01:19:43.195801 (Thread-24): 01:19:43  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:19:43.198280 (Thread-24): 01:19:43  The selection criterion '+models/_archive/orginal_query+' does not match any nodes
2022-04-21 01:19:43.198421 (Thread-24): 01:19:43  No nodes selected!
2022-04-21 01:19:43.199915 (Thread-24): sending response (<Response 1942 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:43.293446 (Thread-25): handling status request
2022-04-21 01:19:43.293747 (Thread-25): 01:19:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2c1ca0>]}
2022-04-21 01:19:43.294200 (Thread-25): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:43.346730 (Thread-26): handling status request
2022-04-21 01:19:43.347015 (Thread-26): 01:19:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0e2400>]}
2022-04-21 01:19:43.347403 (Thread-26): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:55.297357 (Thread-27): 01:19:55  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-04-21 01:19:55.297674 (Thread-27): 01:19:55  Partial parsing: added file: my_new_project://models/_archive/orginal_query.sql
2022-04-21 01:19:55.301423 (Thread-27): 01:19:55  1699: static parser successfully parsed _archive/orginal_query.sql
2022-04-21 01:19:55.350152 (Thread-27): 01:19:55  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ae550>]}
2022-04-21 01:19:55.975294 (Thread-28): handling status request
2022-04-21 01:19:55.975616 (Thread-28): 01:19:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ce790>]}
2022-04-21 01:19:55.976071 (Thread-28): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:56.128076 (Thread-29): handling status request
2022-04-21 01:19:56.128392 (Thread-29): 01:19:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ce5b0>]}
2022-04-21 01:19:56.128841 (Thread-29): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:56.201329 (Thread-30): handling status request
2022-04-21 01:19:56.201569 (Thread-30): 01:19:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ce430>]}
2022-04-21 01:19:56.201957 (Thread-30): sending response (<Response 1546 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:56.218702 (Thread-31): handling list request
2022-04-21 01:19:56.218915 (Thread-31): 01:19:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ce220>]}
2022-04-21 01:19:56.248488 (Thread-31): 01:19:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f169b20>]}
2022-04-21 01:19:56.248742 (Thread-31): 01:19:56  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:19:56.250996 (Thread-31): 01:19:56  The selection criterion '+models/_archive/orginal_query+' does not match any nodes
2022-04-21 01:19:56.251134 (Thread-31): 01:19:56  No nodes selected!
2022-04-21 01:19:56.252284 (Thread-31): sending response (<Response 1942 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:57.198001 (Thread-32): handling status request
2022-04-21 01:19:57.198368 (Thread-32): 01:19:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1ece80>]}
2022-04-21 01:19:57.198829 (Thread-32): sending response (<Response 1546 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:57.204568 (Thread-33): handling list request
2022-04-21 01:19:57.204773 (Thread-33): 01:19:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ae0a0>]}
2022-04-21 01:19:57.235916 (Thread-33): 01:19:57  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0e2430>]}
2022-04-21 01:19:57.236193 (Thread-33): 01:19:57  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:19:57.236937 (Thread-33): 01:19:57  The selection criterion '+models/_archive/orginal_query.sql+' does not match any nodes
2022-04-21 01:19:57.237059 (Thread-33): 01:19:57  No nodes selected!
2022-04-21 01:19:57.238187 (Thread-33): sending response (<Response 1946 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:20:23.285730 (Thread-34): handling status request
2022-04-21 01:20:23.286082 (Thread-34): 01:20:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ce790>]}
2022-04-21 01:20:23.286537 (Thread-34): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:20:23.695899 (Thread-35): handling run_sql request
2022-04-21 01:20:23.696216 (Thread-35): 01:20:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0af280>]}
2022-04-21 01:20:25.952428 (Thread-35): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:20:25.976144 (MainThread): 01:20:25  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '28774b76-3860-43ef-afc8-b1af39d5c2da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa83a6da6d0>]}
2022-04-21 01:20:25.976652 (MainThread): 01:20:25  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:20:25.977314 (Thread-1): 01:20:25  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:20:25.977455 (Thread-1): 01:20:25  Began compiling node rpc.my_new_project.request
2022-04-21 01:20:25.977548 (Thread-1): 01:20:25  Compiling rpc.my_new_project.request
2022-04-21 01:20:25.978612 (Thread-1): 01:20:25  finished collecting timing info
2022-04-21 01:20:25.978743 (Thread-1): 01:20:25  Began executing node rpc.my_new_project.request
2022-04-21 01:20:25.981850 (Thread-1): 01:20:25  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:20:25.981945 (Thread-1): 01:20:25  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)
cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`
    
*/
-- logical cte's
-- final cte's
-- select statement

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM `dbt-public.interview_task.orders` o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as int64) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM `dbt-public.interview_task.devices` d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM `dbt-public.interview_task.orders` as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join `dbt-public.interview_task.addresses` oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM `dbt-public.interview_task.payments`
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:20:25.982026 (Thread-1): 01:20:25  Opening a new connection, currently in state init
2022-04-21 01:20:26.345201 (Thread-36): handling poll request
2022-04-21 01:20:26.345593 (Thread-36): 01:20:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b4ac0>]}
2022-04-21 01:20:26.374501 (Thread-36): sending response (<Response 7618 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:20:27.159259 (Thread-1): 01:20:27  Snowflake adapter: Snowflake query id: 01a3beb0-0501-6083-0004-7d83048388ce
2022-04-21 01:20:27.159473 (Thread-1): 01:20:27  Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 0 unexpected 'FROM'.
2022-04-21 01:20:27.159671 (Thread-1): 01:20:27  finished collecting timing info
2022-04-21 01:20:27.159858 (Thread-1): 01:20:27  On rpc.my_new_project.request: Close
2022-04-21 01:20:27.365486 (Thread-1): Got an exception: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 0 unexpected 'FROM'.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 001003 (42000): SQL compilation error:
syntax error line 1 at position 0 unexpected 'FROM'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 0 unexpected 'FROM'.
2022-04-21 01:20:27.366465 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  001003 (42000): SQL compilation error:\n  syntax error line 1 at position 0 unexpected 'FROM'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  001003 (42000): SQL compilation error:\n  syntax error line 1 at position 0 unexpected 'FROM'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:20:27.825514 (Thread-37): handling poll request
2022-04-21 01:20:27.825901 (Thread-37): 01:20:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b4f40>]}
2022-04-21 01:20:27.826649 (Thread-37): sending response (<Response 38127 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:21:29.236789 (Thread-38): handling status request
2022-04-21 01:21:29.239142 (Thread-38): 01:21:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d038340>]}
2022-04-21 01:21:29.239655 (Thread-38): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:21:29.679815 (Thread-39): handling run_sql request
2022-04-21 01:21:29.680081 (Thread-39): 01:21:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d038ca0>]}
2022-04-21 01:21:31.889443 (Thread-39): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:21:31.916339 (MainThread): 01:21:31  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '612d75d3-a4e3-496f-bc73-563519a20940', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe46f79a6a0>]}
2022-04-21 01:21:31.916855 (MainThread): 01:21:31  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:21:31.917527 (Thread-1): 01:21:31  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:21:31.917661 (Thread-1): 01:21:31  Began compiling node rpc.my_new_project.request
2022-04-21 01:21:31.917754 (Thread-1): 01:21:31  Compiling rpc.my_new_project.request
2022-04-21 01:21:31.918839 (Thread-1): 01:21:31  finished collecting timing info
2022-04-21 01:21:31.918996 (Thread-1): 01:21:31  Began executing node rpc.my_new_project.request
2022-04-21 01:21:31.922482 (Thread-1): 01:21:31  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:21:31.922582 (Thread-1): 01:21:31  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)
cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM `dbt-public.interview_task.orders` o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as int64) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM `dbt-public.interview_task.devices` d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM `dbt-public.interview_task.orders` as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join `dbt-public.interview_task.addresses` oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM `dbt-public.interview_task.payments`
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:21:31.922664 (Thread-1): 01:21:31  Opening a new connection, currently in state init
2022-04-21 01:21:32.247354 (Thread-40): handling poll request
2022-04-21 01:21:32.248238 (Thread-40): 01:21:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b4e50>]}
2022-04-21 01:21:32.249075 (Thread-40): sending response (<Response 7955 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:21:32.914651 (Thread-1): 01:21:32  Snowflake adapter: Snowflake query id: 01a3beb1-0501-602e-0004-7d8304837ef2
2022-04-21 01:21:32.914912 (Thread-1): 01:21:32  Snowflake adapter: Snowflake error: 002040 (42601): SQL compilation error:
Unsupported data type 'INT64'.
2022-04-21 01:21:32.915163 (Thread-1): 01:21:32  finished collecting timing info
2022-04-21 01:21:32.915368 (Thread-1): 01:21:32  On rpc.my_new_project.request: Close
2022-04-21 01:21:33.117179 (Thread-1): Got an exception: Database Error
  002040 (42601): SQL compilation error:
  Unsupported data type 'INT64'.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002040 (42601): SQL compilation error:
Unsupported data type 'INT64'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  002040 (42601): SQL compilation error:
  Unsupported data type 'INT64'.
2022-04-21 01:21:33.118154 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002040 (42601): SQL compilation error:\n  Unsupported data type 'INT64'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002040 (42601): SQL compilation error:\n  Unsupported data type 'INT64'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:21:33.656996 (Thread-41): handling poll request
2022-04-21 01:21:33.657327 (Thread-41): 01:21:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d03d160>]}
2022-04-21 01:21:33.658280 (Thread-41): sending response (<Response 40404 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:23:48.949200 (Thread-42): handling status request
2022-04-21 01:23:48.951794 (Thread-42): 01:23:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d03d6a0>]}
2022-04-21 01:23:48.952518 (Thread-42): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:23:49.325790 (Thread-43): handling run_sql request
2022-04-21 01:23:49.326104 (Thread-43): 01:23:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d03d910>]}
2022-04-21 01:23:51.541857 (Thread-43): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:23:51.569112 (MainThread): 01:23:51  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3f22efce-de2b-4fc3-863b-f6e94a50093d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfe67da6d0>]}
2022-04-21 01:23:51.569616 (MainThread): 01:23:51  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:23:51.570260 (Thread-1): 01:23:51  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:23:51.570405 (Thread-1): 01:23:51  Began compiling node rpc.my_new_project.request
2022-04-21 01:23:51.570500 (Thread-1): 01:23:51  Compiling rpc.my_new_project.request
2022-04-21 01:23:51.571622 (Thread-1): 01:23:51  finished collecting timing info
2022-04-21 01:23:51.571746 (Thread-1): 01:23:51  Began executing node rpc.my_new_project.request
2022-04-21 01:23:51.575260 (Thread-1): 01:23:51  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:23:51.575359 (Thread-1): 01:23:51  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)
cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM `dbt-public.interview_task.orders` o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as int64) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM `dbt-public.interview_task.devices` d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM `dbt-public.interview_task.orders` as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join `dbt-public.interview_task.addresses` oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM `dbt-public.interview_task.payments`
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:23:51.575441 (Thread-1): 01:23:51  Opening a new connection, currently in state init
2022-04-21 01:23:51.881976 (Thread-44): handling poll request
2022-04-21 01:23:51.882361 (Thread-44): 01:23:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d0408e0>]}
2022-04-21 01:23:51.883245 (Thread-44): sending response (<Response 7955 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:23:52.461251 (Thread-1): 01:23:52  Snowflake adapter: Snowflake query id: 01a3beb3-0501-5f4a-0004-7d830483a0c6
2022-04-21 01:23:52.461467 (Thread-1): 01:23:52  Snowflake adapter: Snowflake error: 002040 (42601): SQL compilation error:
Unsupported data type 'INT64'.
2022-04-21 01:23:52.461653 (Thread-1): 01:23:52  finished collecting timing info
2022-04-21 01:23:52.461848 (Thread-1): 01:23:52  On rpc.my_new_project.request: Close
2022-04-21 01:23:52.643510 (Thread-1): Got an exception: Database Error
  002040 (42601): SQL compilation error:
  Unsupported data type 'INT64'.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002040 (42601): SQL compilation error:
Unsupported data type 'INT64'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  002040 (42601): SQL compilation error:
  Unsupported data type 'INT64'.
2022-04-21 01:23:52.644500 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002040 (42601): SQL compilation error:\n  Unsupported data type 'INT64'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002040 (42601): SQL compilation error:\n  Unsupported data type 'INT64'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:23:53.285006 (Thread-45): handling poll request
2022-04-21 01:23:53.285357 (Thread-45): 01:23:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d040b80>]}
2022-04-21 01:23:53.286059 (Thread-45): sending response (<Response 40404 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:29:24.062461 (Thread-46): handling status request
2022-04-21 01:29:24.064146 (Thread-46): 01:29:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d046370>]}
2022-04-21 01:29:24.064661 (Thread-46): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:29:24.402678 (Thread-47): handling run_sql request
2022-04-21 01:29:24.403075 (Thread-47): 01:29:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d046550>]}
2022-04-21 01:29:26.684706 (Thread-47): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:29:26.711539 (MainThread): 01:29:26  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '316e1927-d005-4eb4-9101-957bd2cedbfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdb74246a0>]}
2022-04-21 01:29:26.712091 (MainThread): 01:29:26  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:29:26.712749 (Thread-1): 01:29:26  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:29:26.712894 (Thread-1): 01:29:26  Began compiling node rpc.my_new_project.request
2022-04-21 01:29:26.712988 (Thread-1): 01:29:26  Compiling rpc.my_new_project.request
2022-04-21 01:29:26.714109 (Thread-1): 01:29:26  finished collecting timing info
2022-04-21 01:29:26.714244 (Thread-1): 01:29:26  Began executing node rpc.my_new_project.request
2022-04-21 01:29:26.717787 (Thread-1): 01:29:26  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:29:26.717889 (Thread-1): 01:29:26  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)
cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM `dbt-public.interview_task.orders` o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as float) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM `dbt-public.interview_task.devices` d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM `dbt-public.interview_task.orders` as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join `dbt-public.interview_task.addresses` oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM `dbt-public.interview_task.payments`
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:29:26.717972 (Thread-1): 01:29:26  Opening a new connection, currently in state init
2022-04-21 01:29:27.037820 (Thread-48): handling poll request
2022-04-21 01:29:27.038216 (Thread-48): 01:29:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d04e520>]}
2022-04-21 01:29:27.039089 (Thread-48): sending response (<Response 7955 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:29:27.654005 (Thread-1): 01:29:27  Snowflake adapter: Snowflake query id: 01a3beb9-0501-602e-0004-7d8304837f7e
2022-04-21 01:29:27.654239 (Thread-1): 01:29:27  Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object '"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"' does not exist or not authorized.
2022-04-21 01:29:27.654430 (Thread-1): 01:29:27  finished collecting timing info
2022-04-21 01:29:27.654624 (Thread-1): 01:29:27  On rpc.my_new_project.request: Close
2022-04-21 01:29:27.850118 (Thread-1): Got an exception: Database Error
  002003 (42S02): SQL compilation error:
  Object '"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"' does not exist or not authorized.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): SQL compilation error:
Object '"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"' does not exist or not authorized.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  002003 (42S02): SQL compilation error:
  Object '"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"' does not exist or not authorized.
2022-04-21 01:29:27.851285 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object \'"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"\' does not exist or not authorized.', 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object \'"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"\' does not exist or not authorized.', 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:29:28.378806 (Thread-49): handling poll request
2022-04-21 01:29:28.379184 (Thread-49): 01:29:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d04e820>]}
2022-04-21 01:29:28.380303 (Thread-49): sending response (<Response 40765 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:02.696225 (Thread-50): handling status request
2022-04-21 01:33:02.697981 (Thread-50): 01:33:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d040340>]}
2022-04-21 01:33:02.698468 (Thread-50): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:03.085444 (Thread-51): handling run_sql request
2022-04-21 01:33:03.085804 (Thread-51): 01:33:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d04e790>]}
2022-04-21 01:33:05.301495 (Thread-51): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:05.328026 (MainThread): 01:33:05  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '64b36024-7f6f-4a77-8158-fdc38395e148', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee541f9400>]}
2022-04-21 01:33:05.328540 (MainThread): 01:33:05  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:33:05.329197 (Thread-1): 01:33:05  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:33:05.329347 (Thread-1): 01:33:05  Began compiling node rpc.my_new_project.request
2022-04-21 01:33:05.329443 (Thread-1): 01:33:05  Compiling rpc.my_new_project.request
2022-04-21 01:33:05.330523 (Thread-1): 01:33:05  finished collecting timing info
2022-04-21 01:33:05.330652 (Thread-1): 01:33:05  Began executing node rpc.my_new_project.request
2022-04-21 01:33:05.334241 (Thread-1): 01:33:05  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:33:05.334342 (Thread-1): 01:33:05  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)

cte's we found in query:
    `raw.interview_sample_data.intreview_orders` o
    `raw.interview_sample_data.intreview_devices` d
    `raw.interview_sample_data.intreview_orders` as fo -- potentially redunant
    `raw.interview_sample_data.intreview_addresses` oa 
    `raw.interview_sample_data.intreview_payments`

a couple of errors that were resolved:
  data type int64 to float
  rename tables to: 
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM `raw.interview_sample_data.intreview_orders` o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as float) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM `raw.interview_sample_data.intreview_devices` d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM `raw.interview_sample_data.intreview_orders` as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join `raw.interview_sample_data.intreview_addresses` oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM `raw.interview_sample_data.intreview_payments`
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:33:05.334425 (Thread-1): 01:33:05  Opening a new connection, currently in state init
2022-04-21 01:33:05.658078 (Thread-52): handling poll request
2022-04-21 01:33:05.658444 (Thread-52): 01:33:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d058790>]}
2022-04-21 01:33:05.659315 (Thread-52): sending response (<Response 8159 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:06.392746 (Thread-1): 01:33:06  Snowflake adapter: Snowflake query id: 01a3bebd-0501-5fd8-0004-7d83048399e2
2022-04-21 01:33:06.392986 (Thread-1): 01:33:06  Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object '"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"' does not exist or not authorized.
2022-04-21 01:33:06.393170 (Thread-1): 01:33:06  finished collecting timing info
2022-04-21 01:33:06.393364 (Thread-1): 01:33:06  On rpc.my_new_project.request: Close
2022-04-21 01:33:06.631592 (Thread-1): Got an exception: Database Error
  002003 (42S02): SQL compilation error:
  Object '"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"' does not exist or not authorized.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): SQL compilation error:
Object '"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"' does not exist or not authorized.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  002003 (42S02): SQL compilation error:
  Object '"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"' does not exist or not authorized.
2022-04-21 01:33:06.632552 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object \'"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"\' does not exist or not authorized.', 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    `raw.interview_sample_data.intreview_orders` o\r\n    `raw.interview_sample_data.intreview_devices` d\r\n    `raw.interview_sample_data.intreview_orders` as fo -- potentially redunant\r\n    `raw.interview_sample_data.intreview_addresses` oa \r\n    `raw.interview_sample_data.intreview_payments`\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `raw.interview_sample_data.intreview_orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `raw.interview_sample_data.intreview_devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `raw.interview_sample_data.intreview_orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `raw.interview_sample_data.intreview_addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `raw.interview_sample_data.intreview_payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    `raw.interview_sample_data.intreview_orders` o\r\n    `raw.interview_sample_data.intreview_devices` d\r\n    `raw.interview_sample_data.intreview_orders` as fo -- potentially redunant\r\n    `raw.interview_sample_data.intreview_addresses` oa \r\n    `raw.interview_sample_data.intreview_payments`\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `raw.interview_sample_data.intreview_orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `raw.interview_sample_data.intreview_devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `raw.interview_sample_data.intreview_orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `raw.interview_sample_data.intreview_addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `raw.interview_sample_data.intreview_payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object \'"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"\' does not exist or not authorized.', 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    `raw.interview_sample_data.intreview_orders` o\r\n    `raw.interview_sample_data.intreview_devices` d\r\n    `raw.interview_sample_data.intreview_orders` as fo -- potentially redunant\r\n    `raw.interview_sample_data.intreview_addresses` oa \r\n    `raw.interview_sample_data.intreview_payments`\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `raw.interview_sample_data.intreview_orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `raw.interview_sample_data.intreview_devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `raw.interview_sample_data.intreview_orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `raw.interview_sample_data.intreview_addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `raw.interview_sample_data.intreview_payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    `raw.interview_sample_data.intreview_orders` o\r\n    `raw.interview_sample_data.intreview_devices` d\r\n    `raw.interview_sample_data.intreview_orders` as fo -- potentially redunant\r\n    `raw.interview_sample_data.intreview_addresses` oa \r\n    `raw.interview_sample_data.intreview_payments`\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `raw.interview_sample_data.intreview_orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `raw.interview_sample_data.intreview_devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `raw.interview_sample_data.intreview_orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `raw.interview_sample_data.intreview_addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `raw.interview_sample_data.intreview_payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:33:07.041684 (Thread-53): handling poll request
2022-04-21 01:33:07.041998 (Thread-53): 01:33:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d058a90>]}
2022-04-21 01:33:07.042714 (Thread-53): sending response (<Response 42303 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:22.583895 (Thread-54): handling status request
2022-04-21 01:33:22.584223 (Thread-54): 01:33:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d058f10>]}
2022-04-21 01:33:22.584722 (Thread-54): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:22.952498 (Thread-55): handling run_sql request
2022-04-21 01:33:22.952798 (Thread-55): 01:33:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d0660d0>]}
2022-04-21 01:33:25.167370 (Thread-55): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:25.191246 (MainThread): 01:33:25  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be1fa11d-c25a-4528-aaf9-4188df147145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6c73a7e20>]}
2022-04-21 01:33:25.191751 (MainThread): 01:33:25  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:33:25.192402 (Thread-1): 01:33:25  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:33:25.192557 (Thread-1): 01:33:25  Began compiling node rpc.my_new_project.request
2022-04-21 01:33:25.192651 (Thread-1): 01:33:25  Compiling rpc.my_new_project.request
2022-04-21 01:33:25.193755 (Thread-1): 01:33:25  finished collecting timing info
2022-04-21 01:33:25.193880 (Thread-1): 01:33:25  Began executing node rpc.my_new_project.request
2022-04-21 01:33:25.197489 (Thread-1): 01:33:25  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:33:25.197589 (Thread-1): 01:33:25  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)

cte's we found in query:
    raw.interview_sample_data.intreview_orders o
    raw.interview_sample_data.intreview_devices d
    raw.interview_sample_data.intreview_orders as fo -- potentially redunant
    raw.interview_sample_data.intreview_addresses oa 
    raw.interview_sample_data.intreview_payments

a couple of errors that were resolved:
  data type int64 to float
  rename tables to: 
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM raw.interview_sample_data.intreview_orders o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as float) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM raw.interview_sample_data.intreview_devices d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM raw.interview_sample_data.intreview_orders as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join raw.interview_sample_data.intreview_addresses oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM raw.interview_sample_data.intreview_payments
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:33:25.197671 (Thread-1): 01:33:25  Opening a new connection, currently in state init
2022-04-21 01:33:25.519146 (Thread-56): handling poll request
2022-04-21 01:33:25.519560 (Thread-56): 01:33:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d06c100>]}
2022-04-21 01:33:25.520394 (Thread-56): sending response (<Response 8139 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:26.103914 (Thread-1): 01:33:26  Snowflake adapter: Snowflake query id: 01a3bebd-0501-6083-0004-7d8304838a72
2022-04-21 01:33:26.104160 (Thread-1): 01:33:26  Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.
2022-04-21 01:33:26.104385 (Thread-1): 01:33:26  finished collecting timing info
2022-04-21 01:33:26.104613 (Thread-1): 01:33:26  On rpc.my_new_project.request: Close
2022-04-21 01:33:26.315277 (Thread-1): Got an exception: Database Error
  002003 (42S02): SQL compilation error:
  Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): SQL compilation error:
Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  002003 (42S02): SQL compilation error:
  Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.
2022-04-21 01:33:26.316262 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    raw.interview_sample_data.intreview_orders o\r\n    raw.interview_sample_data.intreview_devices d\r\n    raw.interview_sample_data.intreview_orders as fo -- potentially redunant\r\n    raw.interview_sample_data.intreview_addresses oa \r\n    raw.interview_sample_data.intreview_payments\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM raw.interview_sample_data.intreview_orders o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM raw.interview_sample_data.intreview_devices d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM raw.interview_sample_data.intreview_orders as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join raw.interview_sample_data.intreview_addresses oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM raw.interview_sample_data.intreview_payments\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    raw.interview_sample_data.intreview_orders o\r\n    raw.interview_sample_data.intreview_devices d\r\n    raw.interview_sample_data.intreview_orders as fo -- potentially redunant\r\n    raw.interview_sample_data.intreview_addresses oa \r\n    raw.interview_sample_data.intreview_payments\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM raw.interview_sample_data.intreview_orders o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM raw.interview_sample_data.intreview_devices d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM raw.interview_sample_data.intreview_orders as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join raw.interview_sample_data.intreview_addresses oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM raw.interview_sample_data.intreview_payments\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    raw.interview_sample_data.intreview_orders o\r\n    raw.interview_sample_data.intreview_devices d\r\n    raw.interview_sample_data.intreview_orders as fo -- potentially redunant\r\n    raw.interview_sample_data.intreview_addresses oa \r\n    raw.interview_sample_data.intreview_payments\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM raw.interview_sample_data.intreview_orders o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM raw.interview_sample_data.intreview_devices d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM raw.interview_sample_data.intreview_orders as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join raw.interview_sample_data.intreview_addresses oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM raw.interview_sample_data.intreview_payments\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    raw.interview_sample_data.intreview_orders o\r\n    raw.interview_sample_data.intreview_devices d\r\n    raw.interview_sample_data.intreview_orders as fo -- potentially redunant\r\n    raw.interview_sample_data.intreview_addresses oa \r\n    raw.interview_sample_data.intreview_payments\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM raw.interview_sample_data.intreview_orders o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM raw.interview_sample_data.intreview_devices d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM raw.interview_sample_data.intreview_orders as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join raw.interview_sample_data.intreview_addresses oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM raw.interview_sample_data.intreview_payments\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:33:26.819548 (Thread-57): handling poll request
2022-04-21 01:33:26.819858 (Thread-57): 01:33:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d06c400>]}
2022-04-21 01:33:26.820601 (Thread-57): sending response (<Response 42117 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:06.047364 (Thread-58): 01:37:06  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-04-21 01:37:06.049273 (Thread-58): 01:37:06  Partial parsing: added file: my_new_project://models/_archive/test.sql
2022-04-21 01:37:06.053288 (Thread-58): 01:37:06  1699: static parser successfully parsed _archive/test.sql
2022-04-21 01:37:06.096218 (Thread-58): 01:37:06  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfb3f70>]}
2022-04-21 01:37:06.889770 (Thread-59): handling status request
2022-04-21 01:37:06.890104 (Thread-59): 01:37:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9ad00>]}
2022-04-21 01:37:06.890595 (Thread-59): sending response (<Response 1550 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:06.929046 (Thread-60): handling status request
2022-04-21 01:37:06.929361 (Thread-60): 01:37:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9abe0>]}
2022-04-21 01:37:06.929815 (Thread-60): sending response (<Response 1550 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:53.670170 (Thread-61): handling status request
2022-04-21 01:37:53.670527 (Thread-61): 01:37:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9aa90>]}
2022-04-21 01:37:53.671047 (Thread-61): sending response (<Response 1550 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:53.993975 (Thread-62): handling run_sql request
2022-04-21 01:37:53.994309 (Thread-62): 01:37:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9a670>]}
2022-04-21 01:37:56.243784 (Thread-62): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:56.267658 (MainThread): 01:37:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e14148f2-1cd4-4846-b1a8-10a8cea9b224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8805c56dc0>]}
2022-04-21 01:37:56.268203 (MainThread): 01:37:56  Found 4 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:37:56.268873 (Thread-1): 01:37:56  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:37:56.269004 (Thread-1): 01:37:56  Began compiling node rpc.my_new_project.request
2022-04-21 01:37:56.269097 (Thread-1): 01:37:56  Compiling rpc.my_new_project.request
2022-04-21 01:37:56.270143 (Thread-1): 01:37:56  finished collecting timing info
2022-04-21 01:37:56.270275 (Thread-1): 01:37:56  Began executing node rpc.my_new_project.request
2022-04-21 01:37:56.270812 (Thread-1): 01:37:56  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:37:56.270908 (Thread-1): 01:37:56  On rpc.my_new_project.request: select * from raw.interview_sample_data.interview_orders
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:37:56.271020 (Thread-1): 01:37:56  Opening a new connection, currently in state init
2022-04-21 01:37:56.601501 (Thread-63): handling poll request
2022-04-21 01:37:56.601902 (Thread-63): 01:37:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d066bb0>]}
2022-04-21 01:37:56.602798 (Thread-63): sending response (<Response 3763 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:57.931418 (Thread-64): handling poll request
2022-04-21 01:37:57.931775 (Thread-64): 01:37:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d06c250>]}
2022-04-21 01:37:57.932278 (Thread-64): sending response (<Response 386 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:58.165255 (Thread-1): 01:37:58  SQL status: SUCCESS 500 in 1.89 seconds
2022-04-21 01:37:58.190293 (Thread-1): 01:37:58  finished collecting timing info
2022-04-21 01:37:58.190674 (Thread-1): 01:37:58  On rpc.my_new_project.request: Close
2022-04-21 01:37:59.248118 (Thread-65): handling poll request
2022-04-21 01:37:59.248470 (Thread-65): 01:37:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf96f70>]}
2022-04-21 01:37:59.251609 (Thread-65): sending response (<Response 62875 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:48.030585 (Thread-66): handling status request
2022-04-21 01:38:48.030929 (Thread-66): 01:38:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d06ce80>]}
2022-04-21 01:38:48.054242 (Thread-66): sending response (<Response 1550 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:48.387586 (Thread-67): handling run_sql request
2022-04-21 01:38:48.387946 (Thread-67): 01:38:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d06ce50>]}
2022-04-21 01:38:50.651110 (Thread-67): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:50.676442 (MainThread): 01:38:50  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1eb09f38-2567-4efa-9413-1efcfa94c1a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faebeaed760>]}
2022-04-21 01:38:50.676985 (MainThread): 01:38:50  Found 4 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:38:50.677654 (Thread-1): 01:38:50  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:38:50.677789 (Thread-1): 01:38:50  Began compiling node rpc.my_new_project.request
2022-04-21 01:38:50.677880 (Thread-1): 01:38:50  Compiling rpc.my_new_project.request
2022-04-21 01:38:50.679017 (Thread-1): 01:38:50  finished collecting timing info
2022-04-21 01:38:50.679151 (Thread-1): 01:38:50  Began executing node rpc.my_new_project.request
2022-04-21 01:38:50.682729 (Thread-1): 01:38:50  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:38:50.682840 (Thread-1): 01:38:50  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)

cte's we found in query:
    raw.interview_sample_data.interview_orders o
    raw.interview_sample_data.interview_devices d
    raw.interview_sample_data.interview_orders as fo -- potentially redunant
    raw.interview_sample_data.interview_addresses oa 
    raw.interview_sample_data.interview_payments

a couple of errors that were resolved:
  data type int64 to float
  rename tables to: 
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM raw.interview_sample_data.interview_orders o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as float) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM raw.interview_sample_data.interview_devices d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM raw.interview_sample_data.interview_orders as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join raw.interview_sample_data.interview_addresses oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM raw.interview_sample_data.interview_payments
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:38:50.682923 (Thread-1): 01:38:50  Opening a new connection, currently in state init
2022-04-21 01:38:50.990797 (Thread-68): handling poll request
2022-04-21 01:38:50.991228 (Thread-68): 01:38:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfb0160>]}
2022-04-21 01:38:50.992144 (Thread-68): sending response (<Response 8139 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:52.334602 (Thread-69): handling poll request
2022-04-21 01:38:52.334932 (Thread-69): 01:38:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfb00d0>]}
2022-04-21 01:38:52.335449 (Thread-69): sending response (<Response 395 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:53.123405 (Thread-1): 01:38:53  SQL status: SUCCESS 500 in 2.44 seconds
2022-04-21 01:38:53.657283 (Thread-70): handling poll request
2022-04-21 01:38:53.658000 (Thread-70): 01:38:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfb0550>]}
2022-04-21 01:38:53.658700 (Thread-70): sending response (<Response 1094 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:53.655991 (Thread-1): 01:38:53  finished collecting timing info
2022-04-21 01:38:53.656266 (Thread-1): 01:38:53  On rpc.my_new_project.request: Close
2022-04-21 01:38:55.001138 (Thread-71): handling poll request
2022-04-21 01:38:55.001484 (Thread-71): 01:38:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ebaf0>]}
2022-04-21 01:38:55.010705 (Thread-71): sending response (<Response 149494 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:45:59.850439 (Thread-72): 01:45:59  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-21 01:45:59.852126 (Thread-72): 01:45:59  Partial parsing enabled, no changes found, skipping parsing
2022-04-21 01:45:59.857139 (Thread-72): 01:45:59  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd1f850>]}
2022-04-21 01:46:00.729968 (Thread-73): handling status request
2022-04-21 01:46:00.730295 (Thread-73): 01:46:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ce135b0>]}
2022-04-21 01:46:00.730794 (Thread-73): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:46:00.863050 (Thread-74): handling status request
2022-04-21 01:46:00.863320 (Thread-74): 01:46:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ce133a0>]}
2022-04-21 01:46:00.863742 (Thread-74): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:46:10.210707 (Thread-75): 01:46:10  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-04-21 01:46:10.211044 (Thread-75): 01:46:10  Partial parsing: added file: my_new_project://models/_archive/stg_query.sql
2022-04-21 01:46:10.214643 (Thread-75): 01:46:10  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 01:46:10.261751 (Thread-75): 01:46:10  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ccb5730>]}
2022-04-21 01:46:10.888639 (Thread-76): handling status request
2022-04-21 01:46:10.888960 (Thread-76): 01:46:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd06c70>]}
2022-04-21 01:46:10.889424 (Thread-76): sending response (<Response 1560 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:46:10.937278 (Thread-77): handling status request
2022-04-21 01:46:10.937489 (Thread-77): 01:46:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd06a90>]}
2022-04-21 01:46:10.937837 (Thread-77): sending response (<Response 1560 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:47:57.952546 (Thread-78): 01:47:57  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 01:47:57.953382 (Thread-78): 01:47:57  Partial parsing: updated file: my_new_project://models/_archive/orginal_query.sql
2022-04-21 01:47:57.957067 (Thread-78): 01:47:57  1699: static parser successfully parsed _archive/orginal_query.sql
2022-04-21 01:47:58.002051 (Thread-78): 01:47:58  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc973a0>]}
2022-04-21 01:47:58.792011 (Thread-79): handling status request
2022-04-21 01:47:58.792344 (Thread-79): 01:47:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc88880>]}
2022-04-21 01:47:58.792829 (Thread-79): sending response (<Response 1570 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:47:58.849951 (Thread-80): handling status request
2022-04-21 01:47:58.851999 (Thread-80): 01:47:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc886a0>]}
2022-04-21 01:47:58.852487 (Thread-80): sending response (<Response 1570 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:00.735752 (Thread-81): 01:48:00  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 01:48:00.736099 (Thread-81): 01:48:00  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 01:48:00.870934 (Thread-81): 01:48:00  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 01:48:00.910117 (Thread-81): 01:48:00  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e307070>]}
2022-04-21 01:48:01.526018 (Thread-82): handling status request
2022-04-21 01:48:01.526371 (Thread-82): 01:48:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc6f820>]}
2022-04-21 01:48:01.526860 (Thread-82): sending response (<Response 1562 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:01.662502 (Thread-83): handling status request
2022-04-21 01:48:01.662845 (Thread-83): 01:48:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc6f640>]}
2022-04-21 01:48:01.663351 (Thread-83): sending response (<Response 1562 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:06.162436 (Thread-84): 01:48:06  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 01:48:06.162789 (Thread-84): 01:48:06  Partial parsing: updated file: my_new_project://models/_archive/test.sql
2022-04-21 01:48:06.166280 (Thread-84): 01:48:06  1699: static parser successfully parsed _archive/test.sql
2022-04-21 01:48:06.209110 (Thread-84): 01:48:06  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3756a0>]}
2022-04-21 01:48:06.879416 (Thread-85): handling status request
2022-04-21 01:48:06.879761 (Thread-85): 01:48:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfa7070>]}
2022-04-21 01:48:06.880254 (Thread-85): sending response (<Response 1552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:06.883265 (Thread-86): handling status request
2022-04-21 01:48:06.883478 (Thread-86): 01:48:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfa7460>]}
2022-04-21 01:48:06.883831 (Thread-86): sending response (<Response 1552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:44.504513 (Thread-87): handling status request
2022-04-21 01:48:44.504849 (Thread-87): 01:48:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfa7850>]}
2022-04-21 01:48:44.505318 (Thread-87): sending response (<Response 1552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:47.063338 (Thread-88): 01:48:47  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-21 01:48:47.063522 (Thread-88): 01:48:47  Partial parsing enabled, no changes found, skipping parsing
2022-04-21 01:48:47.068421 (Thread-88): 01:48:47  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e334f70>]}
2022-04-21 01:48:47.778276 (Thread-89): handling status request
2022-04-21 01:48:47.778664 (Thread-89): 01:48:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc03e20>]}
2022-04-21 01:48:47.779182 (Thread-89): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:47.850822 (Thread-90): handling status request
2022-04-21 01:48:47.851150 (Thread-90): 01:48:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc03790>]}
2022-04-21 01:48:47.851599 (Thread-90): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:20.386841 (Thread-91): 01:56:20  Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
2022-04-21 01:56:20.387698 (Thread-91): 01:56:20  Partial parsing: added file: my_new_project://models/_archive/conn_test.sql
2022-04-21 01:56:20.387829 (Thread-91): 01:56:20  Partial parsing: deleted file: my_new_project://models/_archive/test.sql
2022-04-21 01:56:20.392148 (Thread-91): 01:56:20  1699: static parser successfully parsed _archive/conn_test.sql
2022-04-21 01:56:20.433038 (Thread-91): 01:56:20  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc2f8e0>]}
2022-04-21 01:56:21.106122 (Thread-92): handling status request
2022-04-21 01:56:21.106462 (Thread-92): 01:56:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0eae20>]}
2022-04-21 01:56:21.106957 (Thread-92): sending response (<Response 1873 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:21.410533 (Thread-93): handling status request
2022-04-21 01:56:21.410925 (Thread-93): 01:56:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0eaa60>]}
2022-04-21 01:56:21.411450 (Thread-93): sending response (<Response 1873 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:44.051128 (Thread-94): 01:56:44  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-04-21 01:56:44.051423 (Thread-94): 01:56:44  Partial parsing: added file: my_new_project://models/_archive/test_loop.sql
2022-04-21 01:56:44.054840 (Thread-94): 01:56:44  1699: static parser successfully parsed _archive/test_loop.sql
2022-04-21 01:56:44.105407 (Thread-94): 01:56:44  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3f0dc0>]}
2022-04-21 01:56:44.944149 (Thread-95): handling status request
2022-04-21 01:56:44.944480 (Thread-95): 01:56:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0a74c0>]}
2022-04-21 01:56:44.944954 (Thread-95): sending response (<Response 1560 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:44.993028 (Thread-96): handling status request
2022-04-21 01:56:44.993267 (Thread-96): 01:56:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0a7c70>]}
2022-04-21 01:56:45.014311 (Thread-96): sending response (<Response 1560 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:57.836546 (Thread-97): 01:56:57  Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
2022-04-21 01:56:57.836836 (Thread-97): 01:56:57  Partial parsing: added file: my_new_project://models/_archive/test_conn.sql
2022-04-21 01:56:57.836940 (Thread-97): 01:56:57  Partial parsing: deleted file: my_new_project://models/_archive/conn_test.sql
2022-04-21 01:56:57.840433 (Thread-97): 01:56:57  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 01:56:57.885641 (Thread-97): 01:56:57  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbf1e20>]}
2022-04-21 01:56:58.582161 (Thread-98): handling status request
2022-04-21 01:56:58.582481 (Thread-98): 01:56:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ccff9d0>]}
2022-04-21 01:56:58.583004 (Thread-98): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:58.659724 (Thread-99): handling status request
2022-04-21 01:56:58.660006 (Thread-99): 01:56:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ccff970>]}
2022-04-21 01:56:58.660457 (Thread-99): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:19.973810 (Thread-100): handling status request
2022-04-21 02:01:19.975926 (Thread-100): 02:01:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc6feb0>]}
2022-04-21 02:01:19.976426 (Thread-100): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:20.396317 (Thread-101): handling compile_sql request
2022-04-21 02:01:20.396648 (Thread-101): 02:01:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc6f940>]}
2022-04-21 02:01:22.641950 (Thread-101): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:22.668438 (MainThread): 02:01:22  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f072dd1c-f397-4123-836f-f1b94ef90996', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc51d7bfd0>]}
2022-04-21 02:01:22.669684 (MainThread): 02:01:22  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 02:01:22.670282 (Thread-1): 02:01:22  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:01:22.670417 (Thread-1): 02:01:22  Began compiling node rpc.my_new_project.request
2022-04-21 02:01:22.670508 (Thread-1): 02:01:22  Compiling rpc.my_new_project.request
2022-04-21 02:01:22.672953 (Thread-1): 02:01:22  finished collecting timing info
2022-04-21 02:01:22.673082 (Thread-1): 02:01:22  Began executing node rpc.my_new_project.request
2022-04-21 02:01:22.673180 (Thread-1): 02:01:22  finished collecting timing info
2022-04-21 02:01:23.022486 (Thread-102): handling poll request
2022-04-21 02:01:23.022889 (Thread-102): 02:01:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbfedc0>]}
2022-04-21 02:01:23.024098 (Thread-102): sending response (<Response 6192 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:44.376838 (Thread-103): handling status request
2022-04-21 02:01:44.377184 (Thread-103): 02:01:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbfe8b0>]}
2022-04-21 02:01:44.377722 (Thread-103): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:44.702081 (Thread-104): handling compile_sql request
2022-04-21 02:01:44.702420 (Thread-104): 02:01:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc93820>]}
2022-04-21 02:01:46.967176 (Thread-104): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:46.992977 (MainThread): 02:01:46  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '644e3b02-da66-4cd4-a073-4ab052d16ce7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd169a7eeb0>]}
2022-04-21 02:01:46.994296 (MainThread): 02:01:46  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 02:01:46.994909 (Thread-1): 02:01:46  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:01:46.995066 (Thread-1): 02:01:46  Began compiling node rpc.my_new_project.request
2022-04-21 02:01:46.995161 (Thread-1): 02:01:46  Compiling rpc.my_new_project.request
2022-04-21 02:01:46.997565 (Thread-1): 02:01:46  finished collecting timing info
2022-04-21 02:01:46.997698 (Thread-1): 02:01:46  Began executing node rpc.my_new_project.request
2022-04-21 02:01:46.997799 (Thread-1): 02:01:46  finished collecting timing info
2022-04-21 02:01:47.283389 (Thread-105): handling poll request
2022-04-21 02:01:47.283805 (Thread-105): 02:01:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0aee0>]}
2022-04-21 02:01:47.285004 (Thread-105): sending response (<Response 5705 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:57.156816 (Thread-106): handling status request
2022-04-21 02:01:57.157161 (Thread-106): 02:01:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0aa90>]}
2022-04-21 02:01:57.157696 (Thread-106): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:57.476661 (Thread-107): handling compile_sql request
2022-04-21 02:01:57.477010 (Thread-107): 02:01:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d284b80>]}
2022-04-21 02:01:59.771992 (Thread-107): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:59.797431 (MainThread): 02:01:59  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6fac08b-4805-45ed-8885-4dc688b80c35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2ff3bfd0>]}
2022-04-21 02:01:59.798713 (MainThread): 02:01:59  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 02:01:59.799336 (Thread-1): 02:01:59  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:01:59.799469 (Thread-1): 02:01:59  Began compiling node rpc.my_new_project.request
2022-04-21 02:01:59.799559 (Thread-1): 02:01:59  Compiling rpc.my_new_project.request
2022-04-21 02:01:59.801907 (Thread-1): 02:01:59  finished collecting timing info
2022-04-21 02:01:59.802039 (Thread-1): 02:01:59  Began executing node rpc.my_new_project.request
2022-04-21 02:01:59.802140 (Thread-1): 02:01:59  finished collecting timing info
2022-04-21 02:02:00.106206 (Thread-108): handling poll request
2022-04-21 02:02:00.106600 (Thread-108): 02:02:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbd7760>]}
2022-04-21 02:02:00.108367 (Thread-108): sending response (<Response 6137 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:04:59.334343 (Thread-109): handling status request
2022-04-21 02:04:59.336377 (Thread-109): 02:04:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbd7f10>]}
2022-04-21 02:04:59.337020 (Thread-109): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:04:59.704928 (Thread-110): handling compile_sql request
2022-04-21 02:04:59.705245 (Thread-110): 02:04:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbd78b0>]}
2022-04-21 02:05:01.924909 (Thread-110): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:01.950899 (MainThread): 02:05:01  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dcd083ee-c129-4118-934e-be3a21ed39fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5afbf4f40>]}
2022-04-21 02:05:01.952107 (MainThread): 02:05:01  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 02:05:01.952701 (Thread-1): 02:05:01  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:05:01.952835 (Thread-1): 02:05:01  Began compiling node rpc.my_new_project.request
2022-04-21 02:05:01.952929 (Thread-1): 02:05:01  Compiling rpc.my_new_project.request
2022-04-21 02:05:01.955438 (Thread-1): 02:05:01  finished collecting timing info
2022-04-21 02:05:01.955569 (Thread-1): 02:05:01  Began executing node rpc.my_new_project.request
2022-04-21 02:05:01.955670 (Thread-1): 02:05:01  finished collecting timing info
2022-04-21 02:05:02.276871 (Thread-111): handling poll request
2022-04-21 02:05:02.277264 (Thread-111): 02:05:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc1cdf0>]}
2022-04-21 02:05:02.278418 (Thread-111): sending response (<Response 6556 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:24.306236 (Thread-112): handling status request
2022-04-21 02:05:24.306607 (Thread-112): 02:05:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc1c6d0>]}
2022-04-21 02:05:24.307180 (Thread-112): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:24.682104 (Thread-113): handling compile_sql request
2022-04-21 02:05:24.682365 (Thread-113): 02:05:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3e4f10>]}
2022-04-21 02:05:26.887478 (Thread-113): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:26.912097 (MainThread): 02:05:26  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd2a5ab3-d0f8-4fde-97b9-b149f39d4b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e79cfbc40>]}
2022-04-21 02:05:26.913201 (MainThread): 02:05:26  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 02:05:26.913783 (Thread-1): 02:05:26  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:05:26.913915 (Thread-1): 02:05:26  Began compiling node rpc.my_new_project.request
2022-04-21 02:05:26.914005 (Thread-1): 02:05:26  Compiling rpc.my_new_project.request
2022-04-21 02:05:26.916471 (Thread-1): 02:05:26  finished collecting timing info
2022-04-21 02:05:26.916597 (Thread-1): 02:05:26  Began executing node rpc.my_new_project.request
2022-04-21 02:05:26.916694 (Thread-1): 02:05:26  finished collecting timing info
2022-04-21 02:05:27.247888 (Thread-114): handling poll request
2022-04-21 02:05:27.248274 (Thread-114): 02:05:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb8a460>]}
2022-04-21 02:05:27.249363 (Thread-114): sending response (<Response 6570 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:46.856678 (Thread-115): 02:05:46  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:05:46.857040 (Thread-115): 02:05:46  Partial parsing: updated file: my_new_project://models/_archive/test_loop.sql
2022-04-21 02:05:46.860875 (Thread-115): 02:05:46  1603: static parser failed on _archive/test_loop.sql
2022-04-21 02:05:46.864463 (Thread-115): 02:05:46  1602: parser fallback to jinja rendering on _archive/test_loop.sql
2022-04-21 02:05:46.912044 (Thread-115): 02:05:46  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc40d30>]}
2022-04-21 02:05:47.672695 (Thread-116): handling status request
2022-04-21 02:05:47.673012 (Thread-116): 02:05:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb68a30>]}
2022-04-21 02:05:47.673512 (Thread-116): sending response (<Response 1864 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:47.742090 (Thread-117): handling status request
2022-04-21 02:05:47.742308 (Thread-117): 02:05:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb68970>]}
2022-04-21 02:05:47.742694 (Thread-117): sending response (<Response 1864 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:49.340493 (Thread-118): 02:05:49  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:05:49.340829 (Thread-118): 02:05:49  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:05:49.345293 (Thread-118): 02:05:49  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:05:50.148317 (Thread-119): handling status request
2022-04-21 02:05:50.148649 (Thread-119): 02:05:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ca8eb50>]}
2022-04-21 02:05:50.149113 (Thread-119): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:50.166245 (Thread-120): handling status request
2022-04-21 02:05:50.166453 (Thread-120): 02:05:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ca8edf0>]}
2022-04-21 02:05:50.166793 (Thread-120): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:06:14.453127 (Thread-121): handling status request
2022-04-21 02:06:14.453506 (Thread-121): 02:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ca8ef70>]}
2022-04-21 02:06:14.453974 (Thread-121): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:06:16.961965 (Thread-122): 02:06:16  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:06:16.962300 (Thread-122): 02:06:16  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:06:16.966862 (Thread-122): 02:06:16  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:06:17.729677 (Thread-123): handling status request
2022-04-21 02:06:17.730007 (Thread-123): 02:06:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ca8bfa0>]}
2022-04-21 02:06:17.730471 (Thread-123): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:06:17.796118 (Thread-124): handling status request
2022-04-21 02:06:17.796369 (Thread-124): 02:06:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ca8b820>]}
2022-04-21 02:06:17.796770 (Thread-124): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:09:47.752708 (Thread-125): 02:09:47  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:09:47.754680 (Thread-125): 02:09:47  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:09:47.759364 (Thread-125): 02:09:47  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:09:48.717865 (Thread-126): handling status request
2022-04-21 02:09:48.718191 (Thread-126): 02:09:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c962370>]}
2022-04-21 02:09:48.718651 (Thread-126): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:09:48.749734 (Thread-127): handling status request
2022-04-21 02:09:48.749956 (Thread-127): 02:09:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c962550>]}
2022-04-21 02:09:48.750294 (Thread-127): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:09:58.192361 (Thread-128): 02:09:58  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:09:58.192749 (Thread-128): 02:09:58  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:09:58.197339 (Thread-128): 02:09:58  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:09:58.894065 (Thread-129): handling status request
2022-04-21 02:09:58.894402 (Thread-129): 02:09:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9fa2b0>]}
2022-04-21 02:09:58.894884 (Thread-129): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:09:59.223254 (Thread-130): handling status request
2022-04-21 02:09:59.223578 (Thread-130): 02:09:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9fa040>]}
2022-04-21 02:09:59.245019 (Thread-130): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:11:12.325745 (Thread-131): 02:11:12  Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
2022-04-21 02:11:12.328086 (Thread-131): 02:11:12  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:11:12.328320 (Thread-131): 02:11:12  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:11:12.332992 (Thread-131): 02:11:12  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:11:13.338265 (Thread-132): handling status request
2022-04-21 02:11:13.338627 (Thread-132): 02:11:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9deb80>]}
2022-04-21 02:11:13.339140 (Thread-132): sending response (<Response 1611 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:11:13.380022 (Thread-133): handling status request
2022-04-21 02:11:13.380231 (Thread-133): 02:11:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9de4c0>]}
2022-04-21 02:11:13.380583 (Thread-133): sending response (<Response 1611 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:11:29.765977 (Thread-134): 02:11:29  Partial parsing enabled: 0 files deleted, 2 files added, 1 files changed.
2022-04-21 02:11:29.766273 (Thread-134): 02:11:29  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:11:29.766440 (Thread-134): 02:11:29  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:11:29.766635 (Thread-134): 02:11:29  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:11:29.771245 (Thread-134): 02:11:29  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:11:30.731781 (Thread-135): handling status request
2022-04-21 02:11:30.732125 (Thread-135): 02:11:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c96d850>]}
2022-04-21 02:11:30.732687 (Thread-135): sending response (<Response 1926 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:11:30.780654 (Thread-136): handling status request
2022-04-21 02:11:30.780878 (Thread-136): 02:11:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e160>]}
2022-04-21 02:11:30.781269 (Thread-136): sending response (<Response 1926 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:21:49.828908 (Thread-137): handling status request
2022-04-21 02:21:49.830707 (Thread-137): 02:21:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e6a0>]}
2022-04-21 02:21:49.831207 (Thread-137): sending response (<Response 1926 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:21:50.185726 (Thread-138): handling run_sql request
2022-04-21 02:21:50.186035 (Thread-138): 02:21:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e7f0>]}
2022-04-21 02:21:50.186426 (Thread-138): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:13.944242 (Thread-139): handling status request
2022-04-21 02:22:13.944581 (Thread-139): 02:22:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e730>]}
2022-04-21 02:22:13.945599 (Thread-139): sending response (<Response 1926 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:14.280491 (Thread-140): handling run_sql request
2022-04-21 02:22:14.280819 (Thread-140): 02:22:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c7c25e0>]}
2022-04-21 02:22:14.281193 (Thread-140): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:43.011492 (Thread-141): 02:22:43  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:22:43.011817 (Thread-141): 02:22:43  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:22:43.011980 (Thread-141): 02:22:43  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:22:43.012186 (Thread-141): 02:22:43  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:22:43.012367 (Thread-141): 02:22:43  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:22:43.016765 (Thread-141): 02:22:43  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:22:43.019327 (Thread-141): 02:22:43  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:22:43.766752 (Thread-142): handling status request
2022-04-21 02:22:43.767138 (Thread-142): 02:22:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c734430>]}
2022-04-21 02:22:43.767682 (Thread-142): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:43.849741 (Thread-143): handling status request
2022-04-21 02:22:43.850075 (Thread-143): 02:22:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c734c40>]}
2022-04-21 02:22:43.850573 (Thread-143): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:48.142848 (Thread-144): handling status request
2022-04-21 02:22:48.143214 (Thread-144): 02:22:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9de790>]}
2022-04-21 02:22:48.143714 (Thread-144): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:48.457292 (Thread-145): handling run_sql request
2022-04-21 02:22:48.457649 (Thread-145): 02:22:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c734cd0>]}
2022-04-21 02:22:48.458059 (Thread-145): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:26:29.812930 (Thread-146): 02:26:29  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:26:29.814951 (Thread-146): 02:26:29  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:26:29.815223 (Thread-146): 02:26:29  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:26:29.815426 (Thread-146): 02:26:29  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:26:29.815606 (Thread-146): 02:26:29  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:26:29.820205 (Thread-146): 02:26:29  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:26:29.822746 (Thread-146): 02:26:29  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:26:30.534087 (Thread-147): handling status request
2022-04-21 02:26:30.534423 (Thread-147): 02:26:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6c66d0>]}
2022-04-21 02:26:30.534938 (Thread-147): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:26:30.558168 (Thread-148): handling status request
2022-04-21 02:26:30.558458 (Thread-148): 02:26:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6c6250>]}
2022-04-21 02:26:30.558955 (Thread-148): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:27:15.249448 (Thread-149): 02:27:15  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:27:15.249774 (Thread-149): 02:27:15  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:27:15.249959 (Thread-149): 02:27:15  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:27:15.250155 (Thread-149): 02:27:15  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:27:15.250406 (Thread-149): 02:27:15  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:27:15.254442 (Thread-149): 02:27:15  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:27:15.256941 (Thread-149): 02:27:15  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:27:15.928438 (Thread-150): handling status request
2022-04-21 02:27:15.928767 (Thread-150): 02:27:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6b5910>]}
2022-04-21 02:27:15.929265 (Thread-150): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:27:15.995904 (Thread-151): handling status request
2022-04-21 02:27:15.996162 (Thread-151): 02:27:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6e78b0>]}
2022-04-21 02:27:15.996566 (Thread-151): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:27:27.050355 (Thread-152): handling status request
2022-04-21 02:27:27.050713 (Thread-152): 02:27:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6b5e20>]}
2022-04-21 02:27:27.051276 (Thread-152): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:27:27.450588 (Thread-153): handling run_sql request
2022-04-21 02:27:27.450856 (Thread-153): 02:27:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6b5d90>]}
2022-04-21 02:27:27.451241 (Thread-153): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:24.418025 (Thread-154): handling status request
2022-04-21 02:28:24.418366 (Thread-154): 02:28:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e2700>]}
2022-04-21 02:28:24.418865 (Thread-154): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:24.791039 (Thread-155): handling run_sql request
2022-04-21 02:28:24.791317 (Thread-155): 02:28:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e2a90>]}
2022-04-21 02:28:24.791647 (Thread-155): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:30.535404 (Thread-156): handling status request
2022-04-21 02:28:30.535742 (Thread-156): 02:28:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e2b80>]}
2022-04-21 02:28:30.536257 (Thread-156): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:30.911490 (Thread-157): handling run_sql request
2022-04-21 02:28:30.911803 (Thread-157): 02:28:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e2e80>]}
2022-04-21 02:28:30.912162 (Thread-157): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:33.784150 (Thread-158): handling status request
2022-04-21 02:28:33.784479 (Thread-158): 02:28:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e9220>]}
2022-04-21 02:28:33.784975 (Thread-158): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:34.137842 (Thread-159): handling compile_sql request
2022-04-21 02:28:34.138139 (Thread-159): 02:28:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e9400>]}
2022-04-21 02:28:34.138479 (Thread-159): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:52.771654 (Thread-160): 02:28:52  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:28:52.771973 (Thread-160): 02:28:52  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:28:52.772156 (Thread-160): 02:28:52  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:28:52.772350 (Thread-160): 02:28:52  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:28:52.772623 (Thread-160): 02:28:52  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:28:52.776674 (Thread-160): 02:28:52  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:28:52.779169 (Thread-160): 02:28:52  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:28:53.485455 (Thread-161): handling status request
2022-04-21 02:28:53.485790 (Thread-161): 02:28:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c647130>]}
2022-04-21 02:28:53.486292 (Thread-161): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:53.637906 (Thread-162): handling status request
2022-04-21 02:28:53.638227 (Thread-162): 02:28:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c647730>]}
2022-04-21 02:28:53.638753 (Thread-162): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:29:42.943880 (Thread-163): 02:29:42  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:29:42.944211 (Thread-163): 02:29:42  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:29:42.944398 (Thread-163): 02:29:42  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:29:42.944599 (Thread-163): 02:29:42  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:29:42.944850 (Thread-163): 02:29:42  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:29:42.949023 (Thread-163): 02:29:42  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:29:42.951779 (Thread-163): 02:29:42  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:29:43.718125 (Thread-164): handling status request
2022-04-21 02:29:43.718466 (Thread-164): 02:29:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4fc5e0>]}
2022-04-21 02:29:43.719005 (Thread-164): sending response (<Response 2552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:29:43.821769 (Thread-165): handling status request
2022-04-21 02:29:43.822009 (Thread-165): 02:29:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4fc820>]}
2022-04-21 02:29:43.822447 (Thread-165): sending response (<Response 2552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:29:49.542144 (Thread-166): handling status request
2022-04-21 02:29:49.542473 (Thread-166): 02:29:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4fc1c0>]}
2022-04-21 02:29:49.543006 (Thread-166): sending response (<Response 2552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:29:49.914855 (Thread-167): handling run_sql request
2022-04-21 02:29:49.915205 (Thread-167): 02:29:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c498bb0>]}
2022-04-21 02:29:49.939854 (Thread-167): sending response (<Response 709 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:30:29.754642 (Thread-168): handling status request
2022-04-21 02:30:29.755017 (Thread-168): 02:30:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c498d90>]}
2022-04-21 02:30:29.755544 (Thread-168): sending response (<Response 2552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:30:30.091580 (Thread-169): handling run_sql request
2022-04-21 02:30:30.091920 (Thread-169): 02:30:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c49c1f0>]}
2022-04-21 02:30:30.092295 (Thread-169): sending response (<Response 709 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:08.142186 (Thread-170): handling status request
2022-04-21 02:31:08.142521 (Thread-170): 02:31:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c49cdc0>]}
2022-04-21 02:31:08.143072 (Thread-170): sending response (<Response 2552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:08.478591 (Thread-171): handling run_sql request
2022-04-21 02:31:08.478925 (Thread-171): 02:31:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c49c0d0>]}
2022-04-21 02:31:08.479349 (Thread-171): sending response (<Response 709 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:31.140923 (Thread-172): 02:31:31  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:31:31.141248 (Thread-172): 02:31:31  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:31:31.141435 (Thread-172): 02:31:31  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:31:31.141639 (Thread-172): 02:31:31  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:31:31.141891 (Thread-172): 02:31:31  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:31:31.280146 (Thread-172): 02:31:31  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:31:31.282153 (Thread-172): 02:31:31  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:31:31.820117 (Thread-173): handling status request
2022-04-21 02:31:31.820452 (Thread-173): 02:31:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c458790>]}
2022-04-21 02:31:31.820951 (Thread-173): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:32.035431 (Thread-174): handling status request
2022-04-21 02:31:32.035777 (Thread-174): 02:31:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5ddd90>]}
2022-04-21 02:31:32.036259 (Thread-174): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:33.458290 (Thread-175): handling status request
2022-04-21 02:31:33.458601 (Thread-175): 02:31:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c458370>]}
2022-04-21 02:31:33.459130 (Thread-175): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:33.854226 (Thread-176): handling run_sql request
2022-04-21 02:31:33.854531 (Thread-176): 02:31:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c458040>]}
2022-04-21 02:31:33.854900 (Thread-176): sending response (<Response 1375 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:28.190637 (Thread-177): 02:32:28  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:32:28.191168 (Thread-177): 02:32:28  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:32:28.191481 (Thread-177): 02:32:28  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:32:28.191782 (Thread-177): 02:32:28  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:32:28.192179 (Thread-177): 02:32:28  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:32:28.196491 (Thread-177): 02:32:28  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:32:28.198628 (Thread-177): 02:32:28  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:32:28.951114 (Thread-178): handling status request
2022-04-21 02:32:28.951442 (Thread-178): 02:32:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f9880>]}
2022-04-21 02:32:28.951933 (Thread-178): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:28.976455 (Thread-179): handling status request
2022-04-21 02:32:28.976688 (Thread-179): 02:32:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f9b80>]}
2022-04-21 02:32:28.977091 (Thread-179): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:48.740986 (Thread-180): handling status request
2022-04-21 02:32:48.741319 (Thread-180): 02:32:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f91c0>]}
2022-04-21 02:32:48.741811 (Thread-180): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:49.097572 (Thread-181): handling run_sql request
2022-04-21 02:32:49.097916 (Thread-181): 02:32:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f9a60>]}
2022-04-21 02:32:49.098269 (Thread-181): sending response (<Response 1375 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:58.698889 (Thread-182): handling status request
2022-04-21 02:32:58.699231 (Thread-182): 02:32:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f9550>]}
2022-04-21 02:32:58.699715 (Thread-182): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:59.048586 (Thread-183): handling run_sql request
2022-04-21 02:32:59.048854 (Thread-183): 02:32:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5ec070>]}
2022-04-21 02:32:59.049194 (Thread-183): sending response (<Response 1375 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:25.663415 (Thread-184): 02:33:25  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:33:25.663730 (Thread-184): 02:33:25  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:33:25.663917 (Thread-184): 02:33:25  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:33:25.664114 (Thread-184): 02:33:25  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:33:25.664364 (Thread-184): 02:33:25  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:33:25.667705 (Thread-184): 02:33:25  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:33:25.669559 (Thread-184): 02:33:25  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:33:26.383773 (Thread-185): handling status request
2022-04-21 02:33:26.384106 (Thread-185): 02:33:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c8e8580>]}
2022-04-21 02:33:26.384630 (Thread-185): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:26.428928 (Thread-186): handling status request
2022-04-21 02:33:26.429202 (Thread-186): 02:33:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f9bb0>]}
2022-04-21 02:33:26.429612 (Thread-186): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:28.033194 (Thread-187): 02:33:28  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:33:28.033509 (Thread-187): 02:33:28  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:33:28.033694 (Thread-187): 02:33:28  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:33:28.033888 (Thread-187): 02:33:28  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:33:28.034135 (Thread-187): 02:33:28  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:33:28.037511 (Thread-187): 02:33:28  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:33:28.039398 (Thread-187): 02:33:28  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:33:28.729046 (Thread-188): handling status request
2022-04-21 02:33:28.729387 (Thread-188): 02:33:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c725370>]}
2022-04-21 02:33:28.729907 (Thread-188): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:28.763933 (Thread-189): handling status request
2022-04-21 02:33:28.764151 (Thread-189): 02:33:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c725df0>]}
2022-04-21 02:33:28.764549 (Thread-189): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:33.528287 (Thread-190): handling status request
2022-04-21 02:33:33.528605 (Thread-190): 02:33:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f7d30>]}
2022-04-21 02:33:33.529093 (Thread-190): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:33.902017 (Thread-191): handling run_sql request
2022-04-21 02:33:33.902374 (Thread-191): 02:33:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c648970>]}
2022-04-21 02:33:33.902757 (Thread-191): sending response (<Response 1375 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:57.516043 (Thread-192): 02:33:57  Partial parsing enabled: 0 files deleted, 1 files added, 2 files changed.
2022-04-21 02:33:57.516364 (Thread-192): 02:33:57  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:33:57.516578 (Thread-192): 02:33:57  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:33:57.516759 (Thread-192): 02:33:57  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:33:57.520185 (Thread-192): 02:33:57  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:33:57.522047 (Thread-192): 02:33:57  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:33:58.236254 (Thread-193): handling status request
2022-04-21 02:33:58.236595 (Thread-193): 02:33:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c87c1f0>]}
2022-04-21 02:33:58.237091 (Thread-193): sending response (<Response 2582 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:58.283528 (Thread-194): handling status request
2022-04-21 02:33:58.283824 (Thread-194): 02:33:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c87cc40>]}
2022-04-21 02:33:58.284294 (Thread-194): sending response (<Response 2582 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:05.081835 (Thread-195): handling status request
2022-04-21 02:34:05.082168 (Thread-195): 02:34:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c87ca60>]}
2022-04-21 02:34:05.082674 (Thread-195): sending response (<Response 2582 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:05.425470 (Thread-196): handling run_sql request
2022-04-21 02:34:05.425767 (Thread-196): 02:34:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c87c190>]}
2022-04-21 02:34:05.426130 (Thread-196): sending response (<Response 1375 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:28.515271 (Thread-197): 02:34:28  Partial parsing enabled: 0 files deleted, 1 files added, 2 files changed.
2022-04-21 02:34:28.515586 (Thread-197): 02:34:28  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:34:28.515801 (Thread-197): 02:34:28  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:34:28.515982 (Thread-197): 02:34:28  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:34:28.519493 (Thread-197): 02:34:28  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:34:28.521396 (Thread-197): 02:34:28  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:34:28.572832 (Thread-197): 02:34:28  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4fc400>]}
2022-04-21 02:34:29.305945 (Thread-198): handling status request
2022-04-21 02:34:29.306268 (Thread-198): 02:34:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb65a00>]}
2022-04-21 02:34:29.306764 (Thread-198): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:29.338196 (Thread-199): handling status request
2022-04-21 02:34:29.338409 (Thread-199): 02:34:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb65820>]}
2022-04-21 02:34:29.338784 (Thread-199): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:31.972957 (Thread-200): handling status request
2022-04-21 02:34:31.973282 (Thread-200): 02:34:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb65670>]}
2022-04-21 02:34:31.973769 (Thread-200): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:32.332110 (Thread-201): handling run_sql request
2022-04-21 02:34:32.332381 (Thread-201): 02:34:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb654c0>]}
2022-04-21 02:34:34.543686 (Thread-201): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:34.567087 (MainThread): 02:34:34  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46b3fb4e-30e3-4468-98e2-4a35f0009db4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2449ba56d0>]}
2022-04-21 02:34:34.567571 (MainThread): 02:34:34  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 02:34:34.568741 (Thread-1): 02:34:34  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:34:34.568870 (Thread-1): 02:34:34  Began compiling node rpc.my_new_project.request
2022-04-21 02:34:34.568957 (Thread-1): 02:34:34  Compiling rpc.my_new_project.request
2022-04-21 02:34:34.569968 (Thread-1): 02:34:34  finished collecting timing info
2022-04-21 02:34:34.570102 (Thread-1): 02:34:34  Began executing node rpc.my_new_project.request
2022-04-21 02:34:34.570639 (Thread-1): 02:34:34  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 02:34:34.570729 (Thread-1): 02:34:34  On rpc.my_new_project.request: select * from raw.interview_sample_data.interview_orders
-- select * from raw.interview_sample_data.interview_devices;
-- select * from raw.interview_sample_data.interview_orders;
-- select * from raw.interview_sample_data.interview_addresses;
-- select * from raw.interview_sample_data.interview_payments
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 02:34:34.570811 (Thread-1): 02:34:34  Opening a new connection, currently in state init
2022-04-21 02:34:34.925685 (Thread-202): handling poll request
2022-04-21 02:34:34.926058 (Thread-202): 02:34:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb7d9a0>]}
2022-04-21 02:34:34.951072 (Thread-202): sending response (<Response 4039 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:35.632276 (Thread-1): 02:34:35  SQL status: SUCCESS 500 in 1.06 seconds
2022-04-21 02:34:35.646647 (Thread-1): 02:34:35  finished collecting timing info
2022-04-21 02:34:35.646880 (Thread-1): 02:34:35  On rpc.my_new_project.request: Close
2022-04-21 02:34:36.329836 (Thread-203): handling poll request
2022-04-21 02:34:36.330162 (Thread-203): 02:34:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b3760>]}
2022-04-21 02:34:36.333585 (Thread-203): sending response (<Response 63928 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:00.342404 (Thread-204): handling status request
2022-04-21 02:35:00.342728 (Thread-204): 02:35:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b34f0>]}
2022-04-21 02:35:00.343283 (Thread-204): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:00.737041 (Thread-205): handling run_sql request
2022-04-21 02:35:00.737353 (Thread-205): 02:35:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b3b20>]}
2022-04-21 02:35:02.947831 (Thread-205): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:02.971892 (MainThread): 02:35:02  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd0dd3730-4ff4-44b9-8f4d-81de05a12350', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65faf73cd0>]}
2022-04-21 02:35:02.972404 (MainThread): 02:35:02  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 02:35:02.973638 (Thread-1): 02:35:02  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:35:02.973773 (Thread-1): 02:35:02  Began compiling node rpc.my_new_project.request
2022-04-21 02:35:02.973865 (Thread-1): 02:35:02  Compiling rpc.my_new_project.request
2022-04-21 02:35:02.974919 (Thread-1): 02:35:02  finished collecting timing info
2022-04-21 02:35:02.975079 (Thread-1): 02:35:02  Began executing node rpc.my_new_project.request
2022-04-21 02:35:02.975628 (Thread-1): 02:35:02  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 02:35:02.975719 (Thread-1): 02:35:02  On rpc.my_new_project.request: -- select * from raw.interview_sample_data.interview_orders
select * from raw.interview_sample_data.interview_devices;
2022-04-21 02:35:02.975800 (Thread-1): 02:35:02  Opening a new connection, currently in state init
2022-04-21 02:35:03.275938 (Thread-206): handling poll request
2022-04-21 02:35:03.276333 (Thread-206): 02:35:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0d040>]}
2022-04-21 02:35:03.277242 (Thread-206): sending response (<Response 3786 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:05.049814 (Thread-207): handling poll request
2022-04-21 02:35:05.050150 (Thread-207): 02:35:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0d610>]}
2022-04-21 02:35:05.050634 (Thread-207): sending response (<Response 391 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:05.059697 (Thread-1): 02:35:05  SQL status: SUCCESS 4499 in 2.08 seconds
2022-04-21 02:35:05.060008 (Thread-1): 02:35:05  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 02:35:05.060102 (Thread-1): 02:35:05  On rpc.my_new_project.request: -- select * from raw.interview_sample_data.interview_orders;
-- select * from raw.interview_sample_data.interview_addresses;
-- select * from raw.interview_sample_data.interview_payments
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 02:35:05.228274 (Thread-1): 02:35:05  Snowflake adapter: Snowflake query id: 01a3befb-0501-6083-0004-7d830483ca3e
2022-04-21 02:35:05.228419 (Thread-1): 02:35:05  Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 0 unexpected 'limit'.
2022-04-21 02:35:05.228599 (Thread-1): 02:35:05  finished collecting timing info
2022-04-21 02:35:05.228766 (Thread-1): 02:35:05  On rpc.my_new_project.request: Close
2022-04-21 02:35:05.442848 (Thread-1): Got an exception: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 0 unexpected 'limit'.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 001003 (42000): SQL compilation error:
syntax error line 1 at position 0 unexpected 'limit'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 0 unexpected 'limit'.
2022-04-21 02:35:05.443811 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  001003 (42000): SQL compilation error:\n  syntax error line 1 at position 0 unexpected 'limit'.", 'raw_sql': '-- select * from raw.interview_sample_data.interview_orders\r\nselect * from raw.interview_sample_data.interview_devices;\r\n-- select * from raw.interview_sample_data.interview_orders;\r\n-- select * from raw.interview_sample_data.interview_addresses;\r\n-- select * from raw.interview_sample_data.interview_payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '-- select * from raw.interview_sample_data.interview_orders\r\nselect * from raw.interview_sample_data.interview_devices;\r\n-- select * from raw.interview_sample_data.interview_orders;\r\n-- select * from raw.interview_sample_data.interview_addresses;\r\n-- select * from raw.interview_sample_data.interview_payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  001003 (42000): SQL compilation error:\n  syntax error line 1 at position 0 unexpected 'limit'.", 'raw_sql': '-- select * from raw.interview_sample_data.interview_orders\r\nselect * from raw.interview_sample_data.interview_devices;\r\n-- select * from raw.interview_sample_data.interview_orders;\r\n-- select * from raw.interview_sample_data.interview_addresses;\r\n-- select * from raw.interview_sample_data.interview_payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '-- select * from raw.interview_sample_data.interview_orders\r\nselect * from raw.interview_sample_data.interview_devices;\r\n-- select * from raw.interview_sample_data.interview_orders;\r\n-- select * from raw.interview_sample_data.interview_addresses;\r\n-- select * from raw.interview_sample_data.interview_payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-04-21 02:35:06.425008 (Thread-208): handling poll request
2022-04-21 02:35:06.425366 (Thread-208): 02:35:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0a580>]}
2022-04-21 02:35:06.426046 (Thread-208): sending response (<Response 12946 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:18.309632 (Thread-209): handling status request
2022-04-21 02:35:18.309959 (Thread-209): 02:35:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ccff9d0>]}
2022-04-21 02:35:18.310767 (Thread-209): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:18.727338 (Thread-210): handling run_sql request
2022-04-21 02:35:18.727666 (Thread-210): 02:35:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0da30>]}
2022-04-21 02:35:20.994383 (Thread-210): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:21.018233 (MainThread): 02:35:21  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf5f4af1-b825-4b82-8bb2-13f239e25587', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6556a6d280>]}
2022-04-21 02:35:21.018753 (MainThread): 02:35:21  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 02:35:21.019997 (Thread-1): 02:35:21  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:35:21.020128 (Thread-1): 02:35:21  Began compiling node rpc.my_new_project.request
2022-04-21 02:35:21.020231 (Thread-1): 02:35:21  Compiling rpc.my_new_project.request
2022-04-21 02:35:21.021284 (Thread-1): 02:35:21  finished collecting timing info
2022-04-21 02:35:21.021413 (Thread-1): 02:35:21  Began executing node rpc.my_new_project.request
2022-04-21 02:35:21.021958 (Thread-1): 02:35:21  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 02:35:21.022046 (Thread-1): 02:35:21  On rpc.my_new_project.request: -- select * from raw.interview_sample_data.interview_orders
select * from raw.interview_sample_data.interview_devices
-- select * from raw.interview_sample_data.interview_orders;
-- select * from raw.interview_sample_data.interview_addresses;
-- select * from raw.interview_sample_data.interview_payments
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 02:35:21.022125 (Thread-1): 02:35:21  Opening a new connection, currently in state init
2022-04-21 02:35:21.320668 (Thread-211): handling poll request
2022-04-21 02:35:21.321072 (Thread-211): 02:35:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e31dca0>]}
2022-04-21 02:35:21.321966 (Thread-211): sending response (<Response 4038 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:22.208335 (Thread-1): 02:35:22  SQL status: SUCCESS 500 in 1.19 seconds
2022-04-21 02:35:22.220196 (Thread-1): 02:35:22  finished collecting timing info
2022-04-21 02:35:22.220429 (Thread-1): 02:35:22  On rpc.my_new_project.request: Close
2022-04-21 02:35:22.651602 (Thread-212): handling poll request
2022-04-21 02:35:22.651940 (Thread-212): 02:35:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e389220>]}
2022-04-21 02:35:22.654679 (Thread-212): sending response (<Response 31637 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:19.354940 (Thread-213): handling status request
2022-04-21 02:36:19.355340 (Thread-213): 02:36:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e389b80>]}
2022-04-21 02:36:19.355893 (Thread-213): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:19.733108 (Thread-214): handling run_sql request
2022-04-21 02:36:19.733423 (Thread-214): 02:36:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c9476d220>]}
2022-04-21 02:36:21.939618 (Thread-214): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:21.963604 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 125, in _get_exec_node
    add_new_refs(
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 50, in add_new_refs
    process_node(config, manifest, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1275, in process_node
    _process_sources_for_node(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1243, in _process_sources_for_node
    invalid_source_fail_unless_test(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 924, in invalid_source_fail_unless_test
    source_target_not_found(
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 651, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 454, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  Rpc 'rpc.my_new_project.request' (from remote system) depends on a source named 'interview_sample_data.orders' which was not found
2022-04-21 02:36:22.332226 (Thread-215): handling poll request
2022-04-21 02:36:22.332652 (Thread-215): 02:36:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9e5b0>]}
2022-04-21 02:36:22.333382 (Thread-215): sending response (<Response 2869 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:37.023044 (Thread-216): handling status request
2022-04-21 02:36:37.023397 (Thread-216): 02:36:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9e070>]}
2022-04-21 02:36:37.024019 (Thread-216): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:37.379852 (Thread-217): handling run_sql request
2022-04-21 02:36:37.380127 (Thread-217): 02:36:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0a7610>]}
2022-04-21 02:36:39.634111 (Thread-217): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:39.658174 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 125, in _get_exec_node
    add_new_refs(
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 50, in add_new_refs
    process_node(config, manifest, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1275, in process_node
    _process_sources_for_node(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1243, in _process_sources_for_node
    invalid_source_fail_unless_test(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 924, in invalid_source_fail_unless_test
    source_target_not_found(
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 651, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 454, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  Rpc 'rpc.my_new_project.request' (from remote system) depends on a source named 'interview_sample_data.intrview_orders' which was not found
2022-04-21 02:36:39.988355 (Thread-218): handling poll request
2022-04-21 02:36:39.988746 (Thread-218): 02:36:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3a79d0>]}
2022-04-21 02:36:39.989440 (Thread-218): sending response (<Response 2896 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:50.644980 (Thread-219): handling status request
2022-04-21 02:36:50.645319 (Thread-219): 02:36:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3a7820>]}
2022-04-21 02:36:50.645914 (Thread-219): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:51.007969 (Thread-220): handling run_sql request
2022-04-21 02:36:51.008242 (Thread-220): 02:36:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3a7e80>]}
2022-04-21 02:36:53.231557 (Thread-220): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:53.256944 (MainThread): 02:36:53  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a24544ca-347b-4c1b-b860-b2217c1f521b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd3937e2e0>]}
2022-04-21 02:36:53.258093 (MainThread): 02:36:53  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 02:36:53.258666 (Thread-1): 02:36:53  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:36:53.258798 (Thread-1): 02:36:53  Began compiling node rpc.my_new_project.request
2022-04-21 02:36:53.258890 (Thread-1): 02:36:53  Compiling rpc.my_new_project.request
2022-04-21 02:36:53.260959 (Thread-1): 02:36:53  finished collecting timing info
2022-04-21 02:36:53.261097 (Thread-1): 02:36:53  Began executing node rpc.my_new_project.request
2022-04-21 02:36:53.261643 (Thread-1): 02:36:53  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 02:36:53.261732 (Thread-1): 02:36:53  On rpc.my_new_project.request: -- select * from raw.interview_sample_data.interview_orders
-- select * from raw.interview_sample_data.interview_devices
-- select * from raw.interview_sample_data.interview_orders
-- select * from raw.interview_sample_data.interview_addresses
-- select * from raw.interview_sample_data.interview_payments

select * from raw.interview_sample_data.interview_orders
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 02:36:53.261813 (Thread-1): 02:36:53  Opening a new connection, currently in state init
2022-04-21 02:36:53.569121 (Thread-221): handling poll request
2022-04-21 02:36:53.569541 (Thread-221): 02:36:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2ca280>]}
2022-04-21 02:36:53.570501 (Thread-221): sending response (<Response 4091 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:54.292674 (Thread-1): 02:36:54  SQL status: SUCCESS 500 in 1.03 seconds
2022-04-21 02:36:54.308446 (Thread-1): 02:36:54  finished collecting timing info
2022-04-21 02:36:54.308766 (Thread-1): 02:36:54  On rpc.my_new_project.request: Close
2022-04-21 02:36:54.972832 (Thread-222): handling poll request
2022-04-21 02:36:54.973150 (Thread-222): 02:36:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2f0640>]}
2022-04-21 02:36:54.976514 (Thread-222): sending response (<Response 64293 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:37:39.343495 (Thread-223): 02:37:39  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:37:39.343923 (Thread-223): 02:37:39  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:37:39.348009 (Thread-223): 02:37:39  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:37:39.389309 (Thread-223): 02:37:39  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd1dc70>]}
2022-04-21 02:37:40.122140 (Thread-224): handling status request
2022-04-21 02:37:40.122479 (Thread-224): 02:37:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306bb0>]}
2022-04-21 02:37:40.123029 (Thread-224): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:37:40.192056 (Thread-225): handling status request
2022-04-21 02:37:40.192386 (Thread-225): 02:37:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306dc0>]}
2022-04-21 02:37:40.192879 (Thread-225): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:39:35.038775 (Thread-226): handling status request
2022-04-21 02:39:35.039665 (Thread-226): 02:39:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306a30>]}
2022-04-21 02:39:35.040160 (Thread-226): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:39:35.370456 (Thread-227): handling compile_sql request
2022-04-21 02:39:35.370788 (Thread-227): 02:39:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306a60>]}
2022-04-21 02:39:37.706141 (Thread-227): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:39:37.721180 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{source('interview_sample_data', 'interview_'{{t}} ),

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{source('interview_sample_data', 'interview_'{{t}} ),
2022-04-21 02:39:38.047086 (Thread-228): handling poll request
2022-04-21 02:39:38.047498 (Thread-228): 02:39:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3fc400>]}
2022-04-21 02:39:38.048245 (Thread-228): sending response (<Response 4511 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:40:06.279999 (Thread-229): handling status request
2022-04-21 02:40:06.280371 (Thread-229): 02:40:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3fcb50>]}
2022-04-21 02:40:06.280922 (Thread-229): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:40:06.616815 (Thread-230): handling compile_sql request
2022-04-21 02:40:06.617175 (Thread-230): 02:40:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3fcbb0>]}
2022-04-21 02:40:08.872309 (Thread-230): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:40:08.887165 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}} }} ),

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}} }} ),
2022-04-21 02:40:09.193409 (Thread-231): handling poll request
2022-04-21 02:40:09.193833 (Thread-231): 02:40:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e320850>]}
2022-04-21 02:40:09.194599 (Thread-231): sending response (<Response 4454 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:07.463026 (Thread-232): handling status request
2022-04-21 02:41:07.463365 (Thread-232): 02:41:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e377430>]}
2022-04-21 02:41:07.487693 (Thread-232): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:07.823226 (Thread-233): handling compile_sql request
2022-04-21 02:41:07.823573 (Thread-233): 02:41:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc03eb0>]}
2022-04-21 02:41:10.066288 (Thread-233): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:10.081174 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ),

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ),
2022-04-21 02:41:10.378375 (Thread-234): handling poll request
2022-04-21 02:41:10.378769 (Thread-234): 02:41:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c656fd0>]}
2022-04-21 02:41:10.379543 (Thread-234): sending response (<Response 4458 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:36.547705 (Thread-235): handling status request
2022-04-21 02:41:36.548050 (Thread-235): 02:41:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2ce6a0>]}
2022-04-21 02:41:36.548579 (Thread-235): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:36.889959 (Thread-236): handling compile_sql request
2022-04-21 02:41:36.890316 (Thread-236): 02:41:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2ced60>]}
2022-04-21 02:41:39.133848 (Thread-236): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:39.159321 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 125, in _get_exec_node
    add_new_refs(
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 50, in add_new_refs
    process_node(config, manifest, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1275, in process_node
    _process_sources_for_node(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1243, in _process_sources_for_node
    invalid_source_fail_unless_test(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 924, in invalid_source_fail_unless_test
    source_target_not_found(
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 651, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 454, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  Rpc 'rpc.my_new_project.request' (from remote system) depends on a source named 'interview_sample_data.interview_{{t}}' which was not found
2022-04-21 02:41:39.455366 (Thread-237): handling poll request
2022-04-21 02:41:39.455790 (Thread-237): 02:41:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3208e0>]}
2022-04-21 02:41:39.456531 (Thread-237): sending response (<Response 3030 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:16.331745 (Thread-238): handling status request
2022-04-21 02:42:16.332106 (Thread-238): 02:42:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306940>]}
2022-04-21 02:42:16.332689 (Thread-238): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:16.712732 (Thread-239): handling compile_sql request
2022-04-21 02:42:16.713000 (Thread-239): 02:42:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306130>]}
2022-04-21 02:42:18.929860 (Thread-239): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:18.944242 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ),

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ),
2022-04-21 02:42:19.257640 (Thread-240): handling poll request
2022-04-21 02:42:19.258085 (Thread-240): 02:42:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc6fc40>]}
2022-04-21 02:42:19.258832 (Thread-240): sending response (<Response 4458 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:32.028756 (Thread-241): handling status request
2022-04-21 02:42:32.029109 (Thread-241): 02:42:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc9fe80>]}
2022-04-21 02:42:32.029649 (Thread-241): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:32.388791 (Thread-242): handling compile_sql request
2022-04-21 02:42:32.389084 (Thread-242): 02:42:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc9f550>]}
2022-04-21 02:42:34.648961 (Thread-242): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:34.663545 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} )

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} )
2022-04-21 02:42:34.969776 (Thread-243): handling poll request
2022-04-21 02:42:34.970189 (Thread-243): 02:42:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e307880>]}
2022-04-21 02:42:34.970914 (Thread-243): sending response (<Response 4454 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:59.827191 (Thread-244): handling status request
2022-04-21 02:42:59.827547 (Thread-244): 02:42:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e307850>]}
2022-04-21 02:42:59.828099 (Thread-244): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:00.205881 (Thread-245): handling compile_sql request
2022-04-21 02:43:00.206164 (Thread-245): 02:43:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc97e50>]}
2022-04-21 02:43:02.437716 (Thread-245): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:02.452119 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ,)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ,)
2022-04-21 02:43:02.785333 (Thread-246): handling poll request
2022-04-21 02:43:02.785754 (Thread-246): 02:43:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc97f10>]}
2022-04-21 02:43:02.786514 (Thread-246): sending response (<Response 4458 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:21.769334 (Thread-247): 02:43:21  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:43:21.769705 (Thread-247): 02:43:21  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:43:21.774458 (Thread-247): 02:43:21  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:43:21.816605 (Thread-247): 02:43:21  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9052b0>]}
2022-04-21 02:43:22.490313 (Thread-248): handling status request
2022-04-21 02:43:22.490640 (Thread-248): 02:43:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e2b0>]}
2022-04-21 02:43:22.491150 (Thread-248): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:22.596782 (Thread-249): handling status request
2022-04-21 02:43:22.597065 (Thread-249): 02:43:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79ee50>]}
2022-04-21 02:43:22.604373 (Thread-249): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:26.528859 (Thread-250): handling status request
2022-04-21 02:43:26.529226 (Thread-250): 02:43:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c532fd0>]}
2022-04-21 02:43:26.529686 (Thread-250): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:26.843280 (Thread-251): handling compile_sql request
2022-04-21 02:43:26.843599 (Thread-251): 02:43:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e790>]}
2022-04-21 02:43:29.085570 (Thread-251): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:29.100014 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as select * from {{ source('interview_sample_data', 'interview_'{{t}}) }}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as select * from {{ source('interview_sample_data', 'interview_'{{t}}) }}
2022-04-21 02:43:29.446450 (Thread-252): handling poll request
2022-04-21 02:43:29.446824 (Thread-252): 02:43:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e2700>]}
2022-04-21 02:43:29.447559 (Thread-252): sending response (<Response 4438 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:45:06.677166 (Thread-253): 02:45:06  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:45:06.679416 (Thread-253): 02:45:06  Partial parsing: updated file: my_new_project://models/_archive/test_loop.sql
2022-04-21 02:45:06.683248 (Thread-253): 02:45:06  1603: static parser failed on _archive/test_loop.sql
2022-04-21 02:45:07.392038 (Thread-254): handling status request
2022-04-21 02:45:07.392378 (Thread-254): 02:45:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c65e100>]}
2022-04-21 02:45:07.392862 (Thread-254): sending response (<Response 1317 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:45:07.420001 (Thread-255): handling status request
2022-04-21 02:45:07.420250 (Thread-255): 02:45:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2ca3a0>]}
2022-04-21 02:45:07.420594 (Thread-255): sending response (<Response 1317 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:45:32.929445 (Thread-256): handling status request
2022-04-21 02:45:32.929780 (Thread-256): 02:45:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c65e1f0>]}
2022-04-21 02:45:32.930247 (Thread-256): sending response (<Response 1317 bytes [200 OK]>) to 10.0.26.132
