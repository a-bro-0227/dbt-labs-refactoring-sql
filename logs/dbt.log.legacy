2022-04-21 01:12:11.942182 (MainThread): Running with dbt=1.0.4
2022-04-21 01:12:12.159779 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-04-21 01:12:12.174109 (MainThread): Tracking: tracking
2022-04-21 01:12:12.174346 (MainThread): 01:12:12  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cb271b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3894f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3890a0>]}
2022-04-21 01:12:12.174628 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=22
2022-04-21 01:12:12.174857 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-04-21 01:12:12.175009 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-04-21 01:12:12.177275 (Thread-12): 01:12:12  Partial parse save file not found. Starting full parse.
2022-04-21 01:12:12.177507 (Thread-12): 01:12:12  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e393040>]}
2022-04-21 01:12:12.204569 (Thread-12): 01:12:12  Parsing macros/adapters.sql
2022-04-21 01:12:12.242666 (Thread-12): 01:12:12  Parsing macros/catalog.sql
2022-04-21 01:12:12.244523 (Thread-12): 01:12:12  Parsing macros/materializations/table.sql
2022-04-21 01:12:12.247531 (Thread-12): 01:12:12  Parsing macros/materializations/seed.sql
2022-04-21 01:12:12.252581 (Thread-12): 01:12:12  Parsing macros/materializations/incremental.sql
2022-04-21 01:12:12.260739 (Thread-12): 01:12:12  Parsing macros/materializations/merge.sql
2022-04-21 01:12:12.264413 (Thread-12): 01:12:12  Parsing macros/materializations/snapshot.sql
2022-04-21 01:12:12.265327 (Thread-12): 01:12:12  Parsing macros/materializations/view.sql
2022-04-21 01:12:12.266610 (Thread-12): 01:12:12  Parsing macros/adapters/metadata.sql
2022-04-21 01:12:12.273483 (Thread-12): 01:12:12  Parsing macros/adapters/columns.sql
2022-04-21 01:12:12.283023 (Thread-12): 01:12:12  Parsing macros/adapters/freshness.sql
2022-04-21 01:12:12.285805 (Thread-12): 01:12:12  Parsing macros/adapters/persist_docs.sql
2022-04-21 01:12:12.290040 (Thread-12): 01:12:12  Parsing macros/adapters/relation.sql
2022-04-21 01:12:12.299364 (Thread-12): 01:12:12  Parsing macros/adapters/schema.sql
2022-04-21 01:12:12.301446 (Thread-12): 01:12:12  Parsing macros/adapters/indexes.sql
2022-04-21 01:12:12.304097 (Thread-12): 01:12:12  Parsing macros/get_custom_name/get_custom_schema.sql
2022-04-21 01:12:12.306529 (Thread-12): 01:12:12  Parsing macros/get_custom_name/get_custom_alias.sql
2022-04-21 01:12:12.308005 (Thread-12): 01:12:12  Parsing macros/get_custom_name/get_custom_database.sql
2022-04-21 01:12:12.309551 (Thread-12): 01:12:12  Parsing macros/etc/datetime.sql
2022-04-21 01:12:12.317602 (Thread-12): 01:12:12  Parsing macros/etc/statement.sql
2022-04-21 01:12:12.321857 (Thread-12): 01:12:12  Parsing macros/generic_test_sql/unique.sql
2022-04-21 01:12:12.322545 (Thread-12): 01:12:12  Parsing macros/generic_test_sql/not_null.sql
2022-04-21 01:12:12.323125 (Thread-12): 01:12:12  Parsing macros/generic_test_sql/accepted_values.sql
2022-04-21 01:12:12.324458 (Thread-12): 01:12:12  Parsing macros/generic_test_sql/relationships.sql
2022-04-21 01:12:12.325304 (Thread-12): 01:12:12  Parsing macros/materializations/configs.sql
2022-04-21 01:12:12.327557 (Thread-12): 01:12:12  Parsing macros/materializations/hooks.sql
2022-04-21 01:12:12.331304 (Thread-12): 01:12:12  Parsing macros/materializations/models/table/table.sql
2022-04-21 01:12:12.338559 (Thread-12): 01:12:12  Parsing macros/materializations/models/table/create_table_as.sql
2022-04-21 01:12:12.341344 (Thread-12): 01:12:12  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-04-21 01:12:12.343964 (Thread-12): 01:12:12  Parsing macros/materializations/models/view/helpers.sql
2022-04-21 01:12:12.345232 (Thread-12): 01:12:12  Parsing macros/materializations/models/view/create_view_as.sql
2022-04-21 01:12:12.347482 (Thread-12): 01:12:12  Parsing macros/materializations/models/view/view.sql
2022-04-21 01:12:12.354364 (Thread-12): 01:12:12  Parsing macros/materializations/models/incremental/incremental.sql
2022-04-21 01:12:12.365798 (Thread-12): 01:12:12  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-04-21 01:12:12.380897 (Thread-12): 01:12:12  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-04-21 01:12:12.382337 (Thread-12): 01:12:12  Parsing macros/materializations/models/incremental/merge.sql
2022-04-21 01:12:12.393301 (Thread-12): 01:12:12  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-04-21 01:12:12.397575 (Thread-12): 01:12:12  Parsing macros/materializations/seeds/helpers.sql
2022-04-21 01:12:12.413440 (Thread-12): 01:12:12  Parsing macros/materializations/seeds/seed.sql
2022-04-21 01:12:12.419212 (Thread-12): 01:12:12  Parsing macros/materializations/tests/helpers.sql
2022-04-21 01:12:12.420931 (Thread-12): 01:12:12  Parsing macros/materializations/tests/test.sql
2022-04-21 01:12:12.425200 (Thread-12): 01:12:12  Parsing macros/materializations/tests/where_subquery.sql
2022-04-21 01:12:12.426934 (Thread-12): 01:12:12  Parsing macros/materializations/snapshots/helpers.sql
2022-04-21 01:12:12.437950 (Thread-12): 01:12:12  Parsing macros/materializations/snapshots/strategies.sql
2022-04-21 01:12:12.454207 (Thread-12): 01:12:12  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-04-21 01:12:12.455831 (Thread-12): 01:12:12  Parsing macros/materializations/snapshots/snapshot.sql
2022-04-21 01:12:12.467002 (Thread-12): 01:12:12  Parsing tests/generic/builtin.sql
2022-04-21 01:12:12.660078 (Thread-12): 01:12:12  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-04-21 01:12:12.672010 (Thread-12): 01:12:12  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-04-21 01:12:12.748784 (Thread-12): 01:12:12  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1d4610>]}
2022-04-21 01:12:13.226265 (Thread-13): handling status request
2022-04-21 01:12:13.226600 (Thread-13): 01:12:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6c05b370>]}
2022-04-21 01:12:13.227573 (Thread-13): sending response (<Response 15565 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:12:13.231114 (Thread-14): handling status request
2022-04-21 01:12:13.231331 (Thread-14): 01:12:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3891f0>]}
2022-04-21 01:12:13.232005 (Thread-14): sending response (<Response 15565 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:12:46.043423 (Thread-15): handling status request
2022-04-21 01:12:46.044982 (Thread-15): 01:12:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1d4250>]}
2022-04-21 01:12:46.045809 (Thread-15): sending response (<Response 15565 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:12:48.555483 (Thread-16): 01:12:48  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-21 01:12:48.555663 (Thread-16): 01:12:48  Partial parsing enabled, no changes found, skipping parsing
2022-04-21 01:12:48.560300 (Thread-16): 01:12:48  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f16a550>]}
2022-04-21 01:12:49.249872 (Thread-17): handling status request
2022-04-21 01:12:49.250186 (Thread-17): 01:12:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f15ff70>]}
2022-04-21 01:12:49.250629 (Thread-17): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:12:49.321475 (Thread-18): handling status request
2022-04-21 01:12:49.321693 (Thread-18): 01:12:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f15fe20>]}
2022-04-21 01:12:49.322033 (Thread-18): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:15.622157 (Thread-19): 01:19:15  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-21 01:19:15.623652 (Thread-19): 01:19:15  Partial parsing enabled, no changes found, skipping parsing
2022-04-21 01:19:15.628520 (Thread-19): 01:19:15  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0eb6d0>]}
2022-04-21 01:19:16.390842 (Thread-20): handling status request
2022-04-21 01:19:16.391194 (Thread-20): 01:19:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1ec6a0>]}
2022-04-21 01:19:16.391647 (Thread-20): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:16.412436 (Thread-21): handling status request
2022-04-21 01:19:16.412657 (Thread-21): 01:19:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1ec880>]}
2022-04-21 01:19:16.413030 (Thread-21): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:42.385407 (Thread-22): 01:19:42  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-21 01:19:42.387413 (Thread-22): 01:19:42  Partial parsing enabled, no changes found, skipping parsing
2022-04-21 01:19:42.393202 (Thread-22): 01:19:42  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1f8190>]}
2022-04-21 01:19:43.145106 (Thread-23): handling status request
2022-04-21 01:19:43.145506 (Thread-23): 01:19:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0e2640>]}
2022-04-21 01:19:43.145972 (Thread-23): sending response (<Response 1219 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:43.162260 (Thread-24): handling list request
2022-04-21 01:19:43.162482 (Thread-24): 01:19:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f16bf70>]}
2022-04-21 01:19:43.195535 (Thread-24): 01:19:43  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1d4a00>]}
2022-04-21 01:19:43.195801 (Thread-24): 01:19:43  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:19:43.198280 (Thread-24): 01:19:43  The selection criterion '+models/_archive/orginal_query+' does not match any nodes
2022-04-21 01:19:43.198421 (Thread-24): 01:19:43  No nodes selected!
2022-04-21 01:19:43.199915 (Thread-24): sending response (<Response 1942 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:43.293446 (Thread-25): handling status request
2022-04-21 01:19:43.293747 (Thread-25): 01:19:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2c1ca0>]}
2022-04-21 01:19:43.294200 (Thread-25): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:43.346730 (Thread-26): handling status request
2022-04-21 01:19:43.347015 (Thread-26): 01:19:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0e2400>]}
2022-04-21 01:19:43.347403 (Thread-26): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:55.297357 (Thread-27): 01:19:55  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-04-21 01:19:55.297674 (Thread-27): 01:19:55  Partial parsing: added file: my_new_project://models/_archive/orginal_query.sql
2022-04-21 01:19:55.301423 (Thread-27): 01:19:55  1699: static parser successfully parsed _archive/orginal_query.sql
2022-04-21 01:19:55.350152 (Thread-27): 01:19:55  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ae550>]}
2022-04-21 01:19:55.975294 (Thread-28): handling status request
2022-04-21 01:19:55.975616 (Thread-28): 01:19:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ce790>]}
2022-04-21 01:19:55.976071 (Thread-28): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:56.128076 (Thread-29): handling status request
2022-04-21 01:19:56.128392 (Thread-29): 01:19:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ce5b0>]}
2022-04-21 01:19:56.128841 (Thread-29): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:56.201329 (Thread-30): handling status request
2022-04-21 01:19:56.201569 (Thread-30): 01:19:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ce430>]}
2022-04-21 01:19:56.201957 (Thread-30): sending response (<Response 1546 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:56.218702 (Thread-31): handling list request
2022-04-21 01:19:56.218915 (Thread-31): 01:19:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ce220>]}
2022-04-21 01:19:56.248488 (Thread-31): 01:19:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f169b20>]}
2022-04-21 01:19:56.248742 (Thread-31): 01:19:56  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:19:56.250996 (Thread-31): 01:19:56  The selection criterion '+models/_archive/orginal_query+' does not match any nodes
2022-04-21 01:19:56.251134 (Thread-31): 01:19:56  No nodes selected!
2022-04-21 01:19:56.252284 (Thread-31): sending response (<Response 1942 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:57.198001 (Thread-32): handling status request
2022-04-21 01:19:57.198368 (Thread-32): 01:19:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f1ece80>]}
2022-04-21 01:19:57.198829 (Thread-32): sending response (<Response 1546 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:19:57.204568 (Thread-33): handling list request
2022-04-21 01:19:57.204773 (Thread-33): 01:19:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ae0a0>]}
2022-04-21 01:19:57.235916 (Thread-33): 01:19:57  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0e2430>]}
2022-04-21 01:19:57.236193 (Thread-33): 01:19:57  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:19:57.236937 (Thread-33): 01:19:57  The selection criterion '+models/_archive/orginal_query.sql+' does not match any nodes
2022-04-21 01:19:57.237059 (Thread-33): 01:19:57  No nodes selected!
2022-04-21 01:19:57.238187 (Thread-33): sending response (<Response 1946 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:20:23.285730 (Thread-34): handling status request
2022-04-21 01:20:23.286082 (Thread-34): 01:20:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ce790>]}
2022-04-21 01:20:23.286537 (Thread-34): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:20:23.695899 (Thread-35): handling run_sql request
2022-04-21 01:20:23.696216 (Thread-35): 01:20:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0af280>]}
2022-04-21 01:20:25.952428 (Thread-35): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:20:25.976144 (MainThread): 01:20:25  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '28774b76-3860-43ef-afc8-b1af39d5c2da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa83a6da6d0>]}
2022-04-21 01:20:25.976652 (MainThread): 01:20:25  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:20:25.977314 (Thread-1): 01:20:25  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:20:25.977455 (Thread-1): 01:20:25  Began compiling node rpc.my_new_project.request
2022-04-21 01:20:25.977548 (Thread-1): 01:20:25  Compiling rpc.my_new_project.request
2022-04-21 01:20:25.978612 (Thread-1): 01:20:25  finished collecting timing info
2022-04-21 01:20:25.978743 (Thread-1): 01:20:25  Began executing node rpc.my_new_project.request
2022-04-21 01:20:25.981850 (Thread-1): 01:20:25  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:20:25.981945 (Thread-1): 01:20:25  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)
cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`
    
*/
-- logical cte's
-- final cte's
-- select statement

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM `dbt-public.interview_task.orders` o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as int64) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM `dbt-public.interview_task.devices` d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM `dbt-public.interview_task.orders` as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join `dbt-public.interview_task.addresses` oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM `dbt-public.interview_task.payments`
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:20:25.982026 (Thread-1): 01:20:25  Opening a new connection, currently in state init
2022-04-21 01:20:26.345201 (Thread-36): handling poll request
2022-04-21 01:20:26.345593 (Thread-36): 01:20:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b4ac0>]}
2022-04-21 01:20:26.374501 (Thread-36): sending response (<Response 7618 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:20:27.159259 (Thread-1): 01:20:27  Snowflake adapter: Snowflake query id: 01a3beb0-0501-6083-0004-7d83048388ce
2022-04-21 01:20:27.159473 (Thread-1): 01:20:27  Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 0 unexpected 'FROM'.
2022-04-21 01:20:27.159671 (Thread-1): 01:20:27  finished collecting timing info
2022-04-21 01:20:27.159858 (Thread-1): 01:20:27  On rpc.my_new_project.request: Close
2022-04-21 01:20:27.365486 (Thread-1): Got an exception: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 0 unexpected 'FROM'.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 001003 (42000): SQL compilation error:
syntax error line 1 at position 0 unexpected 'FROM'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 0 unexpected 'FROM'.
2022-04-21 01:20:27.366465 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  001003 (42000): SQL compilation error:\n  syntax error line 1 at position 0 unexpected 'FROM'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  001003 (42000): SQL compilation error:\n  syntax error line 1 at position 0 unexpected 'FROM'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:20:27.825514 (Thread-37): handling poll request
2022-04-21 01:20:27.825901 (Thread-37): 01:20:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b4f40>]}
2022-04-21 01:20:27.826649 (Thread-37): sending response (<Response 38127 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:21:29.236789 (Thread-38): handling status request
2022-04-21 01:21:29.239142 (Thread-38): 01:21:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d038340>]}
2022-04-21 01:21:29.239655 (Thread-38): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:21:29.679815 (Thread-39): handling run_sql request
2022-04-21 01:21:29.680081 (Thread-39): 01:21:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d038ca0>]}
2022-04-21 01:21:31.889443 (Thread-39): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:21:31.916339 (MainThread): 01:21:31  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '612d75d3-a4e3-496f-bc73-563519a20940', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe46f79a6a0>]}
2022-04-21 01:21:31.916855 (MainThread): 01:21:31  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:21:31.917527 (Thread-1): 01:21:31  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:21:31.917661 (Thread-1): 01:21:31  Began compiling node rpc.my_new_project.request
2022-04-21 01:21:31.917754 (Thread-1): 01:21:31  Compiling rpc.my_new_project.request
2022-04-21 01:21:31.918839 (Thread-1): 01:21:31  finished collecting timing info
2022-04-21 01:21:31.918996 (Thread-1): 01:21:31  Began executing node rpc.my_new_project.request
2022-04-21 01:21:31.922482 (Thread-1): 01:21:31  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:21:31.922582 (Thread-1): 01:21:31  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)
cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM `dbt-public.interview_task.orders` o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as int64) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM `dbt-public.interview_task.devices` d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM `dbt-public.interview_task.orders` as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join `dbt-public.interview_task.addresses` oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM `dbt-public.interview_task.payments`
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:21:31.922664 (Thread-1): 01:21:31  Opening a new connection, currently in state init
2022-04-21 01:21:32.247354 (Thread-40): handling poll request
2022-04-21 01:21:32.248238 (Thread-40): 01:21:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b4e50>]}
2022-04-21 01:21:32.249075 (Thread-40): sending response (<Response 7955 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:21:32.914651 (Thread-1): 01:21:32  Snowflake adapter: Snowflake query id: 01a3beb1-0501-602e-0004-7d8304837ef2
2022-04-21 01:21:32.914912 (Thread-1): 01:21:32  Snowflake adapter: Snowflake error: 002040 (42601): SQL compilation error:
Unsupported data type 'INT64'.
2022-04-21 01:21:32.915163 (Thread-1): 01:21:32  finished collecting timing info
2022-04-21 01:21:32.915368 (Thread-1): 01:21:32  On rpc.my_new_project.request: Close
2022-04-21 01:21:33.117179 (Thread-1): Got an exception: Database Error
  002040 (42601): SQL compilation error:
  Unsupported data type 'INT64'.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002040 (42601): SQL compilation error:
Unsupported data type 'INT64'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  002040 (42601): SQL compilation error:
  Unsupported data type 'INT64'.
2022-04-21 01:21:33.118154 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002040 (42601): SQL compilation error:\n  Unsupported data type 'INT64'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002040 (42601): SQL compilation error:\n  Unsupported data type 'INT64'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:21:33.656996 (Thread-41): handling poll request
2022-04-21 01:21:33.657327 (Thread-41): 01:21:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d03d160>]}
2022-04-21 01:21:33.658280 (Thread-41): sending response (<Response 40404 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:23:48.949200 (Thread-42): handling status request
2022-04-21 01:23:48.951794 (Thread-42): 01:23:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d03d6a0>]}
2022-04-21 01:23:48.952518 (Thread-42): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:23:49.325790 (Thread-43): handling run_sql request
2022-04-21 01:23:49.326104 (Thread-43): 01:23:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d03d910>]}
2022-04-21 01:23:51.541857 (Thread-43): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:23:51.569112 (MainThread): 01:23:51  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3f22efce-de2b-4fc3-863b-f6e94a50093d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfe67da6d0>]}
2022-04-21 01:23:51.569616 (MainThread): 01:23:51  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:23:51.570260 (Thread-1): 01:23:51  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:23:51.570405 (Thread-1): 01:23:51  Began compiling node rpc.my_new_project.request
2022-04-21 01:23:51.570500 (Thread-1): 01:23:51  Compiling rpc.my_new_project.request
2022-04-21 01:23:51.571622 (Thread-1): 01:23:51  finished collecting timing info
2022-04-21 01:23:51.571746 (Thread-1): 01:23:51  Began executing node rpc.my_new_project.request
2022-04-21 01:23:51.575260 (Thread-1): 01:23:51  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:23:51.575359 (Thread-1): 01:23:51  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)
cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM `dbt-public.interview_task.orders` o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as int64) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM `dbt-public.interview_task.devices` d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM `dbt-public.interview_task.orders` as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join `dbt-public.interview_task.addresses` oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM `dbt-public.interview_task.payments`
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:23:51.575441 (Thread-1): 01:23:51  Opening a new connection, currently in state init
2022-04-21 01:23:51.881976 (Thread-44): handling poll request
2022-04-21 01:23:51.882361 (Thread-44): 01:23:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d0408e0>]}
2022-04-21 01:23:51.883245 (Thread-44): sending response (<Response 7955 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:23:52.461251 (Thread-1): 01:23:52  Snowflake adapter: Snowflake query id: 01a3beb3-0501-5f4a-0004-7d830483a0c6
2022-04-21 01:23:52.461467 (Thread-1): 01:23:52  Snowflake adapter: Snowflake error: 002040 (42601): SQL compilation error:
Unsupported data type 'INT64'.
2022-04-21 01:23:52.461653 (Thread-1): 01:23:52  finished collecting timing info
2022-04-21 01:23:52.461848 (Thread-1): 01:23:52  On rpc.my_new_project.request: Close
2022-04-21 01:23:52.643510 (Thread-1): Got an exception: Database Error
  002040 (42601): SQL compilation error:
  Unsupported data type 'INT64'.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002040 (42601): SQL compilation error:
Unsupported data type 'INT64'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  002040 (42601): SQL compilation error:
  Unsupported data type 'INT64'.
2022-04-21 01:23:52.644500 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002040 (42601): SQL compilation error:\n  Unsupported data type 'INT64'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002040 (42601): SQL compilation error:\n  Unsupported data type 'INT64'.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as int64) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:23:53.285006 (Thread-45): handling poll request
2022-04-21 01:23:53.285357 (Thread-45): 01:23:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d040b80>]}
2022-04-21 01:23:53.286059 (Thread-45): sending response (<Response 40404 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:29:24.062461 (Thread-46): handling status request
2022-04-21 01:29:24.064146 (Thread-46): 01:29:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d046370>]}
2022-04-21 01:29:24.064661 (Thread-46): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:29:24.402678 (Thread-47): handling run_sql request
2022-04-21 01:29:24.403075 (Thread-47): 01:29:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d046550>]}
2022-04-21 01:29:26.684706 (Thread-47): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:29:26.711539 (MainThread): 01:29:26  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '316e1927-d005-4eb4-9101-957bd2cedbfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdb74246a0>]}
2022-04-21 01:29:26.712091 (MainThread): 01:29:26  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:29:26.712749 (Thread-1): 01:29:26  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:29:26.712894 (Thread-1): 01:29:26  Began compiling node rpc.my_new_project.request
2022-04-21 01:29:26.712988 (Thread-1): 01:29:26  Compiling rpc.my_new_project.request
2022-04-21 01:29:26.714109 (Thread-1): 01:29:26  finished collecting timing info
2022-04-21 01:29:26.714244 (Thread-1): 01:29:26  Began executing node rpc.my_new_project.request
2022-04-21 01:29:26.717787 (Thread-1): 01:29:26  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:29:26.717889 (Thread-1): 01:29:26  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)
cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM `dbt-public.interview_task.orders` o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as float) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM `dbt-public.interview_task.devices` d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM `dbt-public.interview_task.orders` as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join `dbt-public.interview_task.addresses` oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM `dbt-public.interview_task.payments`
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:29:26.717972 (Thread-1): 01:29:26  Opening a new connection, currently in state init
2022-04-21 01:29:27.037820 (Thread-48): handling poll request
2022-04-21 01:29:27.038216 (Thread-48): 01:29:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d04e520>]}
2022-04-21 01:29:27.039089 (Thread-48): sending response (<Response 7955 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:29:27.654005 (Thread-1): 01:29:27  Snowflake adapter: Snowflake query id: 01a3beb9-0501-602e-0004-7d8304837f7e
2022-04-21 01:29:27.654239 (Thread-1): 01:29:27  Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object '"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"' does not exist or not authorized.
2022-04-21 01:29:27.654430 (Thread-1): 01:29:27  finished collecting timing info
2022-04-21 01:29:27.654624 (Thread-1): 01:29:27  On rpc.my_new_project.request: Close
2022-04-21 01:29:27.850118 (Thread-1): Got an exception: Database Error
  002003 (42S02): SQL compilation error:
  Object '"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"' does not exist or not authorized.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): SQL compilation error:
Object '"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"' does not exist or not authorized.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  002003 (42S02): SQL compilation error:
  Object '"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"' does not exist or not authorized.
2022-04-21 01:29:27.851285 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object \'"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"\' does not exist or not authorized.', 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object \'"`DBT-PUBLIC.INTERVIEW_TASK.ORDERS`"\' does not exist or not authorized.', 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\ncte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `dbt-public.interview_task.orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `dbt-public.interview_task.devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `dbt-public.interview_task.orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `dbt-public.interview_task.addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `dbt-public.interview_task.payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:29:28.378806 (Thread-49): handling poll request
2022-04-21 01:29:28.379184 (Thread-49): 01:29:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d04e820>]}
2022-04-21 01:29:28.380303 (Thread-49): sending response (<Response 40765 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:02.696225 (Thread-50): handling status request
2022-04-21 01:33:02.697981 (Thread-50): 01:33:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d040340>]}
2022-04-21 01:33:02.698468 (Thread-50): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:03.085444 (Thread-51): handling run_sql request
2022-04-21 01:33:03.085804 (Thread-51): 01:33:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d04e790>]}
2022-04-21 01:33:05.301495 (Thread-51): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:05.328026 (MainThread): 01:33:05  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '64b36024-7f6f-4a77-8158-fdc38395e148', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee541f9400>]}
2022-04-21 01:33:05.328540 (MainThread): 01:33:05  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:33:05.329197 (Thread-1): 01:33:05  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:33:05.329347 (Thread-1): 01:33:05  Began compiling node rpc.my_new_project.request
2022-04-21 01:33:05.329443 (Thread-1): 01:33:05  Compiling rpc.my_new_project.request
2022-04-21 01:33:05.330523 (Thread-1): 01:33:05  finished collecting timing info
2022-04-21 01:33:05.330652 (Thread-1): 01:33:05  Began executing node rpc.my_new_project.request
2022-04-21 01:33:05.334241 (Thread-1): 01:33:05  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:33:05.334342 (Thread-1): 01:33:05  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)

cte's we found in query:
    `raw.interview_sample_data.intreview_orders` o
    `raw.interview_sample_data.intreview_devices` d
    `raw.interview_sample_data.intreview_orders` as fo -- potentially redunant
    `raw.interview_sample_data.intreview_addresses` oa 
    `raw.interview_sample_data.intreview_payments`

a couple of errors that were resolved:
  data type int64 to float
  rename tables to: 
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM `raw.interview_sample_data.intreview_orders` o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as float) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM `raw.interview_sample_data.intreview_devices` d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM `raw.interview_sample_data.intreview_orders` as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join `raw.interview_sample_data.intreview_addresses` oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM `raw.interview_sample_data.intreview_payments`
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:33:05.334425 (Thread-1): 01:33:05  Opening a new connection, currently in state init
2022-04-21 01:33:05.658078 (Thread-52): handling poll request
2022-04-21 01:33:05.658444 (Thread-52): 01:33:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d058790>]}
2022-04-21 01:33:05.659315 (Thread-52): sending response (<Response 8159 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:06.392746 (Thread-1): 01:33:06  Snowflake adapter: Snowflake query id: 01a3bebd-0501-5fd8-0004-7d83048399e2
2022-04-21 01:33:06.392986 (Thread-1): 01:33:06  Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object '"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"' does not exist or not authorized.
2022-04-21 01:33:06.393170 (Thread-1): 01:33:06  finished collecting timing info
2022-04-21 01:33:06.393364 (Thread-1): 01:33:06  On rpc.my_new_project.request: Close
2022-04-21 01:33:06.631592 (Thread-1): Got an exception: Database Error
  002003 (42S02): SQL compilation error:
  Object '"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"' does not exist or not authorized.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): SQL compilation error:
Object '"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"' does not exist or not authorized.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  002003 (42S02): SQL compilation error:
  Object '"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"' does not exist or not authorized.
2022-04-21 01:33:06.632552 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object \'"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"\' does not exist or not authorized.', 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    `raw.interview_sample_data.intreview_orders` o\r\n    `raw.interview_sample_data.intreview_devices` d\r\n    `raw.interview_sample_data.intreview_orders` as fo -- potentially redunant\r\n    `raw.interview_sample_data.intreview_addresses` oa \r\n    `raw.interview_sample_data.intreview_payments`\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `raw.interview_sample_data.intreview_orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `raw.interview_sample_data.intreview_devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `raw.interview_sample_data.intreview_orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `raw.interview_sample_data.intreview_addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `raw.interview_sample_data.intreview_payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    `raw.interview_sample_data.intreview_orders` o\r\n    `raw.interview_sample_data.intreview_devices` d\r\n    `raw.interview_sample_data.intreview_orders` as fo -- potentially redunant\r\n    `raw.interview_sample_data.intreview_addresses` oa \r\n    `raw.interview_sample_data.intreview_payments`\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `raw.interview_sample_data.intreview_orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `raw.interview_sample_data.intreview_devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `raw.interview_sample_data.intreview_orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `raw.interview_sample_data.intreview_addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `raw.interview_sample_data.intreview_payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object \'"`RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS`"\' does not exist or not authorized.', 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    `raw.interview_sample_data.intreview_orders` o\r\n    `raw.interview_sample_data.intreview_devices` d\r\n    `raw.interview_sample_data.intreview_orders` as fo -- potentially redunant\r\n    `raw.interview_sample_data.intreview_addresses` oa \r\n    `raw.interview_sample_data.intreview_payments`\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `raw.interview_sample_data.intreview_orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `raw.interview_sample_data.intreview_devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `raw.interview_sample_data.intreview_orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `raw.interview_sample_data.intreview_addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `raw.interview_sample_data.intreview_payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    `raw.interview_sample_data.intreview_orders` o\r\n    `raw.interview_sample_data.intreview_devices` d\r\n    `raw.interview_sample_data.intreview_orders` as fo -- potentially redunant\r\n    `raw.interview_sample_data.intreview_addresses` oa \r\n    `raw.interview_sample_data.intreview_payments`\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM `raw.interview_sample_data.intreview_orders` o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM `raw.interview_sample_data.intreview_devices` d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM `raw.interview_sample_data.intreview_orders` as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join `raw.interview_sample_data.intreview_addresses` oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM `raw.interview_sample_data.intreview_payments`\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:33:07.041684 (Thread-53): handling poll request
2022-04-21 01:33:07.041998 (Thread-53): 01:33:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d058a90>]}
2022-04-21 01:33:07.042714 (Thread-53): sending response (<Response 42303 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:22.583895 (Thread-54): handling status request
2022-04-21 01:33:22.584223 (Thread-54): 01:33:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d058f10>]}
2022-04-21 01:33:22.584722 (Thread-54): sending response (<Response 1568 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:22.952498 (Thread-55): handling run_sql request
2022-04-21 01:33:22.952798 (Thread-55): 01:33:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d0660d0>]}
2022-04-21 01:33:25.167370 (Thread-55): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:25.191246 (MainThread): 01:33:25  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be1fa11d-c25a-4528-aaf9-4188df147145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6c73a7e20>]}
2022-04-21 01:33:25.191751 (MainThread): 01:33:25  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:33:25.192402 (Thread-1): 01:33:25  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:33:25.192557 (Thread-1): 01:33:25  Began compiling node rpc.my_new_project.request
2022-04-21 01:33:25.192651 (Thread-1): 01:33:25  Compiling rpc.my_new_project.request
2022-04-21 01:33:25.193755 (Thread-1): 01:33:25  finished collecting timing info
2022-04-21 01:33:25.193880 (Thread-1): 01:33:25  Began executing node rpc.my_new_project.request
2022-04-21 01:33:25.197489 (Thread-1): 01:33:25  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:33:25.197589 (Thread-1): 01:33:25  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)

cte's we found in query:
    raw.interview_sample_data.intreview_orders o
    raw.interview_sample_data.intreview_devices d
    raw.interview_sample_data.intreview_orders as fo -- potentially redunant
    raw.interview_sample_data.intreview_addresses oa 
    raw.interview_sample_data.intreview_payments

a couple of errors that were resolved:
  data type int64 to float
  rename tables to: 
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM raw.interview_sample_data.intreview_orders o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as float) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM raw.interview_sample_data.intreview_devices d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM raw.interview_sample_data.intreview_orders as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join raw.interview_sample_data.intreview_addresses oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM raw.interview_sample_data.intreview_payments
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:33:25.197671 (Thread-1): 01:33:25  Opening a new connection, currently in state init
2022-04-21 01:33:25.519146 (Thread-56): handling poll request
2022-04-21 01:33:25.519560 (Thread-56): 01:33:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d06c100>]}
2022-04-21 01:33:25.520394 (Thread-56): sending response (<Response 8139 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:33:26.103914 (Thread-1): 01:33:26  Snowflake adapter: Snowflake query id: 01a3bebd-0501-6083-0004-7d8304838a72
2022-04-21 01:33:26.104160 (Thread-1): 01:33:26  Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.
2022-04-21 01:33:26.104385 (Thread-1): 01:33:26  finished collecting timing info
2022-04-21 01:33:26.104613 (Thread-1): 01:33:26  On rpc.my_new_project.request: Close
2022-04-21 01:33:26.315277 (Thread-1): Got an exception: Database Error
  002003 (42S02): SQL compilation error:
  Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): SQL compilation error:
Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  002003 (42S02): SQL compilation error:
  Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.
2022-04-21 01:33:26.316262 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    raw.interview_sample_data.intreview_orders o\r\n    raw.interview_sample_data.intreview_devices d\r\n    raw.interview_sample_data.intreview_orders as fo -- potentially redunant\r\n    raw.interview_sample_data.intreview_addresses oa \r\n    raw.interview_sample_data.intreview_payments\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM raw.interview_sample_data.intreview_orders o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM raw.interview_sample_data.intreview_devices d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM raw.interview_sample_data.intreview_orders as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join raw.interview_sample_data.intreview_addresses oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM raw.interview_sample_data.intreview_payments\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    raw.interview_sample_data.intreview_orders o\r\n    raw.interview_sample_data.intreview_devices d\r\n    raw.interview_sample_data.intreview_orders as fo -- potentially redunant\r\n    raw.interview_sample_data.intreview_addresses oa \r\n    raw.interview_sample_data.intreview_payments\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM raw.interview_sample_data.intreview_orders o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM raw.interview_sample_data.intreview_devices d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM raw.interview_sample_data.intreview_orders as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join raw.interview_sample_data.intreview_addresses oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM raw.interview_sample_data.intreview_payments\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  002003 (42S02): SQL compilation error:\n  Object 'RAW.INTERVIEW_SAMPLE_DATA.INTREVIEW_ORDERS' does not exist or not authorized.", 'raw_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    raw.interview_sample_data.intreview_orders o\r\n    raw.interview_sample_data.intreview_devices d\r\n    raw.interview_sample_data.intreview_orders as fo -- potentially redunant\r\n    raw.interview_sample_data.intreview_addresses oa \r\n    raw.interview_sample_data.intreview_payments\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM raw.interview_sample_data.intreview_orders o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM raw.interview_sample_data.intreview_devices d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM raw.interview_sample_data.intreview_orders as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join raw.interview_sample_data.intreview_addresses oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM raw.interview_sample_data.intreview_payments\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\r\n/*\r\nFirst it is best to pull out your source tables into CTE's\r\nThen we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)\r\n\r\ncte's we found in query:\r\n    raw.interview_sample_data.intreview_orders o\r\n    raw.interview_sample_data.intreview_devices d\r\n    raw.interview_sample_data.intreview_orders as fo -- potentially redunant\r\n    raw.interview_sample_data.intreview_addresses oa \r\n    raw.interview_sample_data.intreview_payments\r\n\r\na couple of errors that were resolved:\r\n  data type int64 to float\r\n  rename tables to: \r\n    \r\n*/\r\n-- logical cte's\r\n-- final cte's\r\n-- select statement\r\n\r\nSELECT\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nFROM (\r\n    \r\n    SELECT\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status AS order_status,\r\n      CASE\r\n        WHEN o.status IN (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) THEN 'completed'\r\n        ELSE o.status\r\n      END AS order_status_category,\r\n      CASE\r\n        WHEN oa.country_code IS NULL THEN 'Null country'\r\n        WHEN oa.country_code = 'US' THEN 'US'\r\n        WHEN oa.country_code != 'US' THEN 'International'\r\n      END AS country_type,\r\n      o.shipping_method,\r\n      CASE\r\n        WHEN d.device = 'web' THEN 'desktop'\r\n        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'\r\n        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'\r\n        when NULLIF(d.device, '') IS NULL THEN 'unknown'\r\n        ELSE 'ERROR'\r\n      END AS purchase_device_type,\r\n      d.device AS purchase_device,\r\n      CASE\r\n        WHEN fo.first_order_id = o.order_id THEN 'new'\r\n        ELSE 'repeat'\r\n      END AS user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      CASE\r\n        WHEN o.currency = 'USD' then o.amount_total_cents\r\n        ELSE pa.gross_total_amount_cents\r\n      END AS total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    FROM raw.interview_sample_data.intreview_orders o\r\n    LEFT JOIN (\r\n        SELECT\r\n          DISTINCT cast(d.type_id as float) as order_id,\r\n          FIRST_VALUE(d.device) OVER (\r\n            PARTITION BY d.type_id\r\n            ORDER BY\r\n              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING\r\n              AND UNBOUNDED FOLLOWING\r\n          ) AS device\r\n        FROM raw.interview_sample_data.intreview_devices d\r\n        WHERE d.type = 'order'\r\n    ) d ON d.order_id = o.order_id\r\n    LEFT JOIN (\r\n        SELECT\r\n          fo.user_id,\r\n          MIN(fo.order_id) as first_order_id\r\n        FROM raw.interview_sample_data.intreview_orders as fo\r\n        WHERE\r\n          fo.status != 'cancelled'\r\n        GROUP BY\r\n          fo.user_id\r\n      ) fo ON o.user_id = fo.user_id\r\n    left join raw.interview_sample_data.intreview_addresses oa \r\n      ON oa.order_id = o.order_id\r\n    LEFT JOIN (\r\n        select\r\n          order_id,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_tax_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n        ) as gross_shipping_amount_cents,\r\n          sum(\r\n            CASE\r\n              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents\r\n              ELSE 0\r\n            END\r\n          ) as gross_total_amount_cents\r\n        FROM raw.interview_sample_data.intreview_payments\r\n        GROUP BY order_id\r\n    ) pa ON pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 01:33:26.819548 (Thread-57): handling poll request
2022-04-21 01:33:26.819858 (Thread-57): 01:33:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d06c400>]}
2022-04-21 01:33:26.820601 (Thread-57): sending response (<Response 42117 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:06.047364 (Thread-58): 01:37:06  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-04-21 01:37:06.049273 (Thread-58): 01:37:06  Partial parsing: added file: my_new_project://models/_archive/test.sql
2022-04-21 01:37:06.053288 (Thread-58): 01:37:06  1699: static parser successfully parsed _archive/test.sql
2022-04-21 01:37:06.096218 (Thread-58): 01:37:06  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfb3f70>]}
2022-04-21 01:37:06.889770 (Thread-59): handling status request
2022-04-21 01:37:06.890104 (Thread-59): 01:37:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9ad00>]}
2022-04-21 01:37:06.890595 (Thread-59): sending response (<Response 1550 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:06.929046 (Thread-60): handling status request
2022-04-21 01:37:06.929361 (Thread-60): 01:37:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9abe0>]}
2022-04-21 01:37:06.929815 (Thread-60): sending response (<Response 1550 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:53.670170 (Thread-61): handling status request
2022-04-21 01:37:53.670527 (Thread-61): 01:37:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9aa90>]}
2022-04-21 01:37:53.671047 (Thread-61): sending response (<Response 1550 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:53.993975 (Thread-62): handling run_sql request
2022-04-21 01:37:53.994309 (Thread-62): 01:37:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9a670>]}
2022-04-21 01:37:56.243784 (Thread-62): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:56.267658 (MainThread): 01:37:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e14148f2-1cd4-4846-b1a8-10a8cea9b224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8805c56dc0>]}
2022-04-21 01:37:56.268203 (MainThread): 01:37:56  Found 4 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:37:56.268873 (Thread-1): 01:37:56  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:37:56.269004 (Thread-1): 01:37:56  Began compiling node rpc.my_new_project.request
2022-04-21 01:37:56.269097 (Thread-1): 01:37:56  Compiling rpc.my_new_project.request
2022-04-21 01:37:56.270143 (Thread-1): 01:37:56  finished collecting timing info
2022-04-21 01:37:56.270275 (Thread-1): 01:37:56  Began executing node rpc.my_new_project.request
2022-04-21 01:37:56.270812 (Thread-1): 01:37:56  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:37:56.270908 (Thread-1): 01:37:56  On rpc.my_new_project.request: select * from raw.interview_sample_data.interview_orders
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:37:56.271020 (Thread-1): 01:37:56  Opening a new connection, currently in state init
2022-04-21 01:37:56.601501 (Thread-63): handling poll request
2022-04-21 01:37:56.601902 (Thread-63): 01:37:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d066bb0>]}
2022-04-21 01:37:56.602798 (Thread-63): sending response (<Response 3763 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:57.931418 (Thread-64): handling poll request
2022-04-21 01:37:57.931775 (Thread-64): 01:37:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d06c250>]}
2022-04-21 01:37:57.932278 (Thread-64): sending response (<Response 386 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:37:58.165255 (Thread-1): 01:37:58  SQL status: SUCCESS 500 in 1.89 seconds
2022-04-21 01:37:58.190293 (Thread-1): 01:37:58  finished collecting timing info
2022-04-21 01:37:58.190674 (Thread-1): 01:37:58  On rpc.my_new_project.request: Close
2022-04-21 01:37:59.248118 (Thread-65): handling poll request
2022-04-21 01:37:59.248470 (Thread-65): 01:37:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf96f70>]}
2022-04-21 01:37:59.251609 (Thread-65): sending response (<Response 62875 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:48.030585 (Thread-66): handling status request
2022-04-21 01:38:48.030929 (Thread-66): 01:38:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d06ce80>]}
2022-04-21 01:38:48.054242 (Thread-66): sending response (<Response 1550 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:48.387586 (Thread-67): handling run_sql request
2022-04-21 01:38:48.387946 (Thread-67): 01:38:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3d06ce50>]}
2022-04-21 01:38:50.651110 (Thread-67): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:50.676442 (MainThread): 01:38:50  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1eb09f38-2567-4efa-9413-1efcfa94c1a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faebeaed760>]}
2022-04-21 01:38:50.676985 (MainThread): 01:38:50  Found 4 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 01:38:50.677654 (Thread-1): 01:38:50  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 01:38:50.677789 (Thread-1): 01:38:50  Began compiling node rpc.my_new_project.request
2022-04-21 01:38:50.677880 (Thread-1): 01:38:50  Compiling rpc.my_new_project.request
2022-04-21 01:38:50.679017 (Thread-1): 01:38:50  finished collecting timing info
2022-04-21 01:38:50.679151 (Thread-1): 01:38:50  Began executing node rpc.my_new_project.request
2022-04-21 01:38:50.682729 (Thread-1): 01:38:50  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 01:38:50.682840 (Thread-1): 01:38:50  On rpc.my_new_project.request: -- import cte's
/*
First it is best to pull out your source tables into CTE's
Then we create a _source.yml file in order to source those (which makes a pretty, more inuitive DAG)

cte's we found in query:
    raw.interview_sample_data.interview_orders o
    raw.interview_sample_data.interview_devices d
    raw.interview_sample_data.interview_orders as fo -- potentially redunant
    raw.interview_sample_data.interview_addresses oa 
    raw.interview_sample_data.interview_payments

a couple of errors that were resolved:
  data type int64 to float
  rename tables to: 
    
*/
-- logical cte's
-- final cte's
-- select statement

SELECT
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

FROM (
    
    SELECT
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status AS order_status,
      CASE
        WHEN o.status IN (
          'paid',
          'completed',
          'shipped'
        ) THEN 'completed'
        ELSE o.status
      END AS order_status_category,
      CASE
        WHEN oa.country_code IS NULL THEN 'Null country'
        WHEN oa.country_code = 'US' THEN 'US'
        WHEN oa.country_code != 'US' THEN 'International'
      END AS country_type,
      o.shipping_method,
      CASE
        WHEN d.device = 'web' THEN 'desktop'
        WHEN d.device IN ('ios-app', 'android-app') THEN 'mobile-app'
        when d.device IN ('mobile', 'tablet') THEN 'mobile-web'
        when NULLIF(d.device, '') IS NULL THEN 'unknown'
        ELSE 'ERROR'
      END AS purchase_device_type,
      d.device AS purchase_device,
      CASE
        WHEN fo.first_order_id = o.order_id THEN 'new'
        ELSE 'repeat'
      END AS user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      CASE
        WHEN o.currency = 'USD' then o.amount_total_cents
        ELSE pa.gross_total_amount_cents
      END AS total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    FROM raw.interview_sample_data.interview_orders o
    LEFT JOIN (
        SELECT
          DISTINCT cast(d.type_id as float) as order_id,
          FIRST_VALUE(d.device) OVER (
            PARTITION BY d.type_id
            ORDER BY
              d.created_at ROWS BETWEEN UNBOUNDED PRECEDING
              AND UNBOUNDED FOLLOWING
          ) AS device
        FROM raw.interview_sample_data.interview_devices d
        WHERE d.type = 'order'
    ) d ON d.order_id = o.order_id
    LEFT JOIN (
        SELECT
          fo.user_id,
          MIN(fo.order_id) as first_order_id
        FROM raw.interview_sample_data.interview_orders as fo
        WHERE
          fo.status != 'cancelled'
        GROUP BY
          fo.user_id
      ) fo ON o.user_id = fo.user_id
    left join raw.interview_sample_data.interview_addresses oa 
      ON oa.order_id = o.order_id
    LEFT JOIN (
        select
          order_id,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents
              ELSE 0
            END
          ) as gross_tax_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_cents
              ELSE 0
            END
          ) as gross_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN amount_shipping_cents
              ELSE 0
            END
        ) as gross_shipping_amount_cents,
          sum(
            CASE
              WHEN status = 'completed' THEN tax_amount_cents + amount_cents + amount_shipping_cents
              ELSE 0
            END
          ) as gross_total_amount_cents
        FROM raw.interview_sample_data.interview_payments
        GROUP BY order_id
    ) pa ON pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 01:38:50.682923 (Thread-1): 01:38:50  Opening a new connection, currently in state init
2022-04-21 01:38:50.990797 (Thread-68): handling poll request
2022-04-21 01:38:50.991228 (Thread-68): 01:38:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfb0160>]}
2022-04-21 01:38:50.992144 (Thread-68): sending response (<Response 8139 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:52.334602 (Thread-69): handling poll request
2022-04-21 01:38:52.334932 (Thread-69): 01:38:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfb00d0>]}
2022-04-21 01:38:52.335449 (Thread-69): sending response (<Response 395 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:53.123405 (Thread-1): 01:38:53  SQL status: SUCCESS 500 in 2.44 seconds
2022-04-21 01:38:53.657283 (Thread-70): handling poll request
2022-04-21 01:38:53.658000 (Thread-70): 01:38:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfb0550>]}
2022-04-21 01:38:53.658700 (Thread-70): sending response (<Response 1094 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:38:53.655991 (Thread-1): 01:38:53  finished collecting timing info
2022-04-21 01:38:53.656266 (Thread-1): 01:38:53  On rpc.my_new_project.request: Close
2022-04-21 01:38:55.001138 (Thread-71): handling poll request
2022-04-21 01:38:55.001484 (Thread-71): 01:38:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0ebaf0>]}
2022-04-21 01:38:55.010705 (Thread-71): sending response (<Response 149494 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:45:59.850439 (Thread-72): 01:45:59  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-21 01:45:59.852126 (Thread-72): 01:45:59  Partial parsing enabled, no changes found, skipping parsing
2022-04-21 01:45:59.857139 (Thread-72): 01:45:59  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd1f850>]}
2022-04-21 01:46:00.729968 (Thread-73): handling status request
2022-04-21 01:46:00.730295 (Thread-73): 01:46:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ce135b0>]}
2022-04-21 01:46:00.730794 (Thread-73): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:46:00.863050 (Thread-74): handling status request
2022-04-21 01:46:00.863320 (Thread-74): 01:46:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ce133a0>]}
2022-04-21 01:46:00.863742 (Thread-74): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:46:10.210707 (Thread-75): 01:46:10  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-04-21 01:46:10.211044 (Thread-75): 01:46:10  Partial parsing: added file: my_new_project://models/_archive/stg_query.sql
2022-04-21 01:46:10.214643 (Thread-75): 01:46:10  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 01:46:10.261751 (Thread-75): 01:46:10  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ccb5730>]}
2022-04-21 01:46:10.888639 (Thread-76): handling status request
2022-04-21 01:46:10.888960 (Thread-76): 01:46:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd06c70>]}
2022-04-21 01:46:10.889424 (Thread-76): sending response (<Response 1560 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:46:10.937278 (Thread-77): handling status request
2022-04-21 01:46:10.937489 (Thread-77): 01:46:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd06a90>]}
2022-04-21 01:46:10.937837 (Thread-77): sending response (<Response 1560 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:47:57.952546 (Thread-78): 01:47:57  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 01:47:57.953382 (Thread-78): 01:47:57  Partial parsing: updated file: my_new_project://models/_archive/orginal_query.sql
2022-04-21 01:47:57.957067 (Thread-78): 01:47:57  1699: static parser successfully parsed _archive/orginal_query.sql
2022-04-21 01:47:58.002051 (Thread-78): 01:47:58  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc973a0>]}
2022-04-21 01:47:58.792011 (Thread-79): handling status request
2022-04-21 01:47:58.792344 (Thread-79): 01:47:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc88880>]}
2022-04-21 01:47:58.792829 (Thread-79): sending response (<Response 1570 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:47:58.849951 (Thread-80): handling status request
2022-04-21 01:47:58.851999 (Thread-80): 01:47:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc886a0>]}
2022-04-21 01:47:58.852487 (Thread-80): sending response (<Response 1570 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:00.735752 (Thread-81): 01:48:00  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 01:48:00.736099 (Thread-81): 01:48:00  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 01:48:00.870934 (Thread-81): 01:48:00  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 01:48:00.910117 (Thread-81): 01:48:00  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e307070>]}
2022-04-21 01:48:01.526018 (Thread-82): handling status request
2022-04-21 01:48:01.526371 (Thread-82): 01:48:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc6f820>]}
2022-04-21 01:48:01.526860 (Thread-82): sending response (<Response 1562 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:01.662502 (Thread-83): handling status request
2022-04-21 01:48:01.662845 (Thread-83): 01:48:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc6f640>]}
2022-04-21 01:48:01.663351 (Thread-83): sending response (<Response 1562 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:06.162436 (Thread-84): 01:48:06  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 01:48:06.162789 (Thread-84): 01:48:06  Partial parsing: updated file: my_new_project://models/_archive/test.sql
2022-04-21 01:48:06.166280 (Thread-84): 01:48:06  1699: static parser successfully parsed _archive/test.sql
2022-04-21 01:48:06.209110 (Thread-84): 01:48:06  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3756a0>]}
2022-04-21 01:48:06.879416 (Thread-85): handling status request
2022-04-21 01:48:06.879761 (Thread-85): 01:48:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfa7070>]}
2022-04-21 01:48:06.880254 (Thread-85): sending response (<Response 1552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:06.883265 (Thread-86): handling status request
2022-04-21 01:48:06.883478 (Thread-86): 01:48:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfa7460>]}
2022-04-21 01:48:06.883831 (Thread-86): sending response (<Response 1552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:44.504513 (Thread-87): handling status request
2022-04-21 01:48:44.504849 (Thread-87): 01:48:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cfa7850>]}
2022-04-21 01:48:44.505318 (Thread-87): sending response (<Response 1552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:47.063338 (Thread-88): 01:48:47  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-21 01:48:47.063522 (Thread-88): 01:48:47  Partial parsing enabled, no changes found, skipping parsing
2022-04-21 01:48:47.068421 (Thread-88): 01:48:47  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e334f70>]}
2022-04-21 01:48:47.778276 (Thread-89): handling status request
2022-04-21 01:48:47.778664 (Thread-89): 01:48:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc03e20>]}
2022-04-21 01:48:47.779182 (Thread-89): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:48:47.850822 (Thread-90): handling status request
2022-04-21 01:48:47.851150 (Thread-90): 01:48:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc03790>]}
2022-04-21 01:48:47.851599 (Thread-90): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:20.386841 (Thread-91): 01:56:20  Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
2022-04-21 01:56:20.387698 (Thread-91): 01:56:20  Partial parsing: added file: my_new_project://models/_archive/conn_test.sql
2022-04-21 01:56:20.387829 (Thread-91): 01:56:20  Partial parsing: deleted file: my_new_project://models/_archive/test.sql
2022-04-21 01:56:20.392148 (Thread-91): 01:56:20  1699: static parser successfully parsed _archive/conn_test.sql
2022-04-21 01:56:20.433038 (Thread-91): 01:56:20  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc2f8e0>]}
2022-04-21 01:56:21.106122 (Thread-92): handling status request
2022-04-21 01:56:21.106462 (Thread-92): 01:56:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0eae20>]}
2022-04-21 01:56:21.106957 (Thread-92): sending response (<Response 1873 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:21.410533 (Thread-93): handling status request
2022-04-21 01:56:21.410925 (Thread-93): 01:56:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0eaa60>]}
2022-04-21 01:56:21.411450 (Thread-93): sending response (<Response 1873 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:44.051128 (Thread-94): 01:56:44  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-04-21 01:56:44.051423 (Thread-94): 01:56:44  Partial parsing: added file: my_new_project://models/_archive/test_loop.sql
2022-04-21 01:56:44.054840 (Thread-94): 01:56:44  1699: static parser successfully parsed _archive/test_loop.sql
2022-04-21 01:56:44.105407 (Thread-94): 01:56:44  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3f0dc0>]}
2022-04-21 01:56:44.944149 (Thread-95): handling status request
2022-04-21 01:56:44.944480 (Thread-95): 01:56:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0a74c0>]}
2022-04-21 01:56:44.944954 (Thread-95): sending response (<Response 1560 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:44.993028 (Thread-96): handling status request
2022-04-21 01:56:44.993267 (Thread-96): 01:56:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0a7c70>]}
2022-04-21 01:56:45.014311 (Thread-96): sending response (<Response 1560 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:57.836546 (Thread-97): 01:56:57  Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
2022-04-21 01:56:57.836836 (Thread-97): 01:56:57  Partial parsing: added file: my_new_project://models/_archive/test_conn.sql
2022-04-21 01:56:57.836940 (Thread-97): 01:56:57  Partial parsing: deleted file: my_new_project://models/_archive/conn_test.sql
2022-04-21 01:56:57.840433 (Thread-97): 01:56:57  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 01:56:57.885641 (Thread-97): 01:56:57  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbf1e20>]}
2022-04-21 01:56:58.582161 (Thread-98): handling status request
2022-04-21 01:56:58.582481 (Thread-98): 01:56:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ccff9d0>]}
2022-04-21 01:56:58.583004 (Thread-98): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 01:56:58.659724 (Thread-99): handling status request
2022-04-21 01:56:58.660006 (Thread-99): 01:56:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ccff970>]}
2022-04-21 01:56:58.660457 (Thread-99): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:19.973810 (Thread-100): handling status request
2022-04-21 02:01:19.975926 (Thread-100): 02:01:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc6feb0>]}
2022-04-21 02:01:19.976426 (Thread-100): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:20.396317 (Thread-101): handling compile_sql request
2022-04-21 02:01:20.396648 (Thread-101): 02:01:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc6f940>]}
2022-04-21 02:01:22.641950 (Thread-101): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:22.668438 (MainThread): 02:01:22  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f072dd1c-f397-4123-836f-f1b94ef90996', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc51d7bfd0>]}
2022-04-21 02:01:22.669684 (MainThread): 02:01:22  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 02:01:22.670282 (Thread-1): 02:01:22  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:01:22.670417 (Thread-1): 02:01:22  Began compiling node rpc.my_new_project.request
2022-04-21 02:01:22.670508 (Thread-1): 02:01:22  Compiling rpc.my_new_project.request
2022-04-21 02:01:22.672953 (Thread-1): 02:01:22  finished collecting timing info
2022-04-21 02:01:22.673082 (Thread-1): 02:01:22  Began executing node rpc.my_new_project.request
2022-04-21 02:01:22.673180 (Thread-1): 02:01:22  finished collecting timing info
2022-04-21 02:01:23.022486 (Thread-102): handling poll request
2022-04-21 02:01:23.022889 (Thread-102): 02:01:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbfedc0>]}
2022-04-21 02:01:23.024098 (Thread-102): sending response (<Response 6192 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:44.376838 (Thread-103): handling status request
2022-04-21 02:01:44.377184 (Thread-103): 02:01:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbfe8b0>]}
2022-04-21 02:01:44.377722 (Thread-103): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:44.702081 (Thread-104): handling compile_sql request
2022-04-21 02:01:44.702420 (Thread-104): 02:01:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc93820>]}
2022-04-21 02:01:46.967176 (Thread-104): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:46.992977 (MainThread): 02:01:46  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '644e3b02-da66-4cd4-a073-4ab052d16ce7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd169a7eeb0>]}
2022-04-21 02:01:46.994296 (MainThread): 02:01:46  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 02:01:46.994909 (Thread-1): 02:01:46  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:01:46.995066 (Thread-1): 02:01:46  Began compiling node rpc.my_new_project.request
2022-04-21 02:01:46.995161 (Thread-1): 02:01:46  Compiling rpc.my_new_project.request
2022-04-21 02:01:46.997565 (Thread-1): 02:01:46  finished collecting timing info
2022-04-21 02:01:46.997698 (Thread-1): 02:01:46  Began executing node rpc.my_new_project.request
2022-04-21 02:01:46.997799 (Thread-1): 02:01:46  finished collecting timing info
2022-04-21 02:01:47.283389 (Thread-105): handling poll request
2022-04-21 02:01:47.283805 (Thread-105): 02:01:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0aee0>]}
2022-04-21 02:01:47.285004 (Thread-105): sending response (<Response 5705 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:57.156816 (Thread-106): handling status request
2022-04-21 02:01:57.157161 (Thread-106): 02:01:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0aa90>]}
2022-04-21 02:01:57.157696 (Thread-106): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:57.476661 (Thread-107): handling compile_sql request
2022-04-21 02:01:57.477010 (Thread-107): 02:01:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d284b80>]}
2022-04-21 02:01:59.771992 (Thread-107): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:01:59.797431 (MainThread): 02:01:59  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6fac08b-4805-45ed-8885-4dc688b80c35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2ff3bfd0>]}
2022-04-21 02:01:59.798713 (MainThread): 02:01:59  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 02:01:59.799336 (Thread-1): 02:01:59  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:01:59.799469 (Thread-1): 02:01:59  Began compiling node rpc.my_new_project.request
2022-04-21 02:01:59.799559 (Thread-1): 02:01:59  Compiling rpc.my_new_project.request
2022-04-21 02:01:59.801907 (Thread-1): 02:01:59  finished collecting timing info
2022-04-21 02:01:59.802039 (Thread-1): 02:01:59  Began executing node rpc.my_new_project.request
2022-04-21 02:01:59.802140 (Thread-1): 02:01:59  finished collecting timing info
2022-04-21 02:02:00.106206 (Thread-108): handling poll request
2022-04-21 02:02:00.106600 (Thread-108): 02:02:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbd7760>]}
2022-04-21 02:02:00.108367 (Thread-108): sending response (<Response 6137 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:04:59.334343 (Thread-109): handling status request
2022-04-21 02:04:59.336377 (Thread-109): 02:04:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbd7f10>]}
2022-04-21 02:04:59.337020 (Thread-109): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:04:59.704928 (Thread-110): handling compile_sql request
2022-04-21 02:04:59.705245 (Thread-110): 02:04:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cbd78b0>]}
2022-04-21 02:05:01.924909 (Thread-110): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:01.950899 (MainThread): 02:05:01  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dcd083ee-c129-4118-934e-be3a21ed39fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5afbf4f40>]}
2022-04-21 02:05:01.952107 (MainThread): 02:05:01  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 02:05:01.952701 (Thread-1): 02:05:01  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:05:01.952835 (Thread-1): 02:05:01  Began compiling node rpc.my_new_project.request
2022-04-21 02:05:01.952929 (Thread-1): 02:05:01  Compiling rpc.my_new_project.request
2022-04-21 02:05:01.955438 (Thread-1): 02:05:01  finished collecting timing info
2022-04-21 02:05:01.955569 (Thread-1): 02:05:01  Began executing node rpc.my_new_project.request
2022-04-21 02:05:01.955670 (Thread-1): 02:05:01  finished collecting timing info
2022-04-21 02:05:02.276871 (Thread-111): handling poll request
2022-04-21 02:05:02.277264 (Thread-111): 02:05:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc1cdf0>]}
2022-04-21 02:05:02.278418 (Thread-111): sending response (<Response 6556 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:24.306236 (Thread-112): handling status request
2022-04-21 02:05:24.306607 (Thread-112): 02:05:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc1c6d0>]}
2022-04-21 02:05:24.307180 (Thread-112): sending response (<Response 1878 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:24.682104 (Thread-113): handling compile_sql request
2022-04-21 02:05:24.682365 (Thread-113): 02:05:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3e4f10>]}
2022-04-21 02:05:26.887478 (Thread-113): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:26.912097 (MainThread): 02:05:26  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd2a5ab3-d0f8-4fde-97b9-b149f39d4b7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e79cfbc40>]}
2022-04-21 02:05:26.913201 (MainThread): 02:05:26  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-04-21 02:05:26.913783 (Thread-1): 02:05:26  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:05:26.913915 (Thread-1): 02:05:26  Began compiling node rpc.my_new_project.request
2022-04-21 02:05:26.914005 (Thread-1): 02:05:26  Compiling rpc.my_new_project.request
2022-04-21 02:05:26.916471 (Thread-1): 02:05:26  finished collecting timing info
2022-04-21 02:05:26.916597 (Thread-1): 02:05:26  Began executing node rpc.my_new_project.request
2022-04-21 02:05:26.916694 (Thread-1): 02:05:26  finished collecting timing info
2022-04-21 02:05:27.247888 (Thread-114): handling poll request
2022-04-21 02:05:27.248274 (Thread-114): 02:05:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb8a460>]}
2022-04-21 02:05:27.249363 (Thread-114): sending response (<Response 6570 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:46.856678 (Thread-115): 02:05:46  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:05:46.857040 (Thread-115): 02:05:46  Partial parsing: updated file: my_new_project://models/_archive/test_loop.sql
2022-04-21 02:05:46.860875 (Thread-115): 02:05:46  1603: static parser failed on _archive/test_loop.sql
2022-04-21 02:05:46.864463 (Thread-115): 02:05:46  1602: parser fallback to jinja rendering on _archive/test_loop.sql
2022-04-21 02:05:46.912044 (Thread-115): 02:05:46  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc40d30>]}
2022-04-21 02:05:47.672695 (Thread-116): handling status request
2022-04-21 02:05:47.673012 (Thread-116): 02:05:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb68a30>]}
2022-04-21 02:05:47.673512 (Thread-116): sending response (<Response 1864 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:47.742090 (Thread-117): handling status request
2022-04-21 02:05:47.742308 (Thread-117): 02:05:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb68970>]}
2022-04-21 02:05:47.742694 (Thread-117): sending response (<Response 1864 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:49.340493 (Thread-118): 02:05:49  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:05:49.340829 (Thread-118): 02:05:49  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:05:49.345293 (Thread-118): 02:05:49  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:05:50.148317 (Thread-119): handling status request
2022-04-21 02:05:50.148649 (Thread-119): 02:05:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ca8eb50>]}
2022-04-21 02:05:50.149113 (Thread-119): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:05:50.166245 (Thread-120): handling status request
2022-04-21 02:05:50.166453 (Thread-120): 02:05:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ca8edf0>]}
2022-04-21 02:05:50.166793 (Thread-120): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:06:14.453127 (Thread-121): handling status request
2022-04-21 02:06:14.453506 (Thread-121): 02:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ca8ef70>]}
2022-04-21 02:06:14.453974 (Thread-121): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:06:16.961965 (Thread-122): 02:06:16  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:06:16.962300 (Thread-122): 02:06:16  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:06:16.966862 (Thread-122): 02:06:16  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:06:17.729677 (Thread-123): handling status request
2022-04-21 02:06:17.730007 (Thread-123): 02:06:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ca8bfa0>]}
2022-04-21 02:06:17.730471 (Thread-123): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:06:17.796118 (Thread-124): handling status request
2022-04-21 02:06:17.796369 (Thread-124): 02:06:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ca8b820>]}
2022-04-21 02:06:17.796770 (Thread-124): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:09:47.752708 (Thread-125): 02:09:47  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:09:47.754680 (Thread-125): 02:09:47  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:09:47.759364 (Thread-125): 02:09:47  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:09:48.717865 (Thread-126): handling status request
2022-04-21 02:09:48.718191 (Thread-126): 02:09:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c962370>]}
2022-04-21 02:09:48.718651 (Thread-126): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:09:48.749734 (Thread-127): handling status request
2022-04-21 02:09:48.749956 (Thread-127): 02:09:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c962550>]}
2022-04-21 02:09:48.750294 (Thread-127): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:09:58.192361 (Thread-128): 02:09:58  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:09:58.192749 (Thread-128): 02:09:58  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:09:58.197339 (Thread-128): 02:09:58  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:09:58.894065 (Thread-129): handling status request
2022-04-21 02:09:58.894402 (Thread-129): 02:09:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9fa2b0>]}
2022-04-21 02:09:58.894884 (Thread-129): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:09:59.223254 (Thread-130): handling status request
2022-04-21 02:09:59.223578 (Thread-130): 02:09:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9fa040>]}
2022-04-21 02:09:59.245019 (Thread-130): sending response (<Response 1298 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:11:12.325745 (Thread-131): 02:11:12  Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
2022-04-21 02:11:12.328086 (Thread-131): 02:11:12  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:11:12.328320 (Thread-131): 02:11:12  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:11:12.332992 (Thread-131): 02:11:12  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:11:13.338265 (Thread-132): handling status request
2022-04-21 02:11:13.338627 (Thread-132): 02:11:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9deb80>]}
2022-04-21 02:11:13.339140 (Thread-132): sending response (<Response 1611 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:11:13.380022 (Thread-133): handling status request
2022-04-21 02:11:13.380231 (Thread-133): 02:11:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9de4c0>]}
2022-04-21 02:11:13.380583 (Thread-133): sending response (<Response 1611 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:11:29.765977 (Thread-134): 02:11:29  Partial parsing enabled: 0 files deleted, 2 files added, 1 files changed.
2022-04-21 02:11:29.766273 (Thread-134): 02:11:29  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:11:29.766440 (Thread-134): 02:11:29  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:11:29.766635 (Thread-134): 02:11:29  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:11:29.771245 (Thread-134): 02:11:29  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:11:30.731781 (Thread-135): handling status request
2022-04-21 02:11:30.732125 (Thread-135): 02:11:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c96d850>]}
2022-04-21 02:11:30.732687 (Thread-135): sending response (<Response 1926 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:11:30.780654 (Thread-136): handling status request
2022-04-21 02:11:30.780878 (Thread-136): 02:11:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e160>]}
2022-04-21 02:11:30.781269 (Thread-136): sending response (<Response 1926 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:21:49.828908 (Thread-137): handling status request
2022-04-21 02:21:49.830707 (Thread-137): 02:21:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e6a0>]}
2022-04-21 02:21:49.831207 (Thread-137): sending response (<Response 1926 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:21:50.185726 (Thread-138): handling run_sql request
2022-04-21 02:21:50.186035 (Thread-138): 02:21:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e7f0>]}
2022-04-21 02:21:50.186426 (Thread-138): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:13.944242 (Thread-139): handling status request
2022-04-21 02:22:13.944581 (Thread-139): 02:22:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e730>]}
2022-04-21 02:22:13.945599 (Thread-139): sending response (<Response 1926 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:14.280491 (Thread-140): handling run_sql request
2022-04-21 02:22:14.280819 (Thread-140): 02:22:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c7c25e0>]}
2022-04-21 02:22:14.281193 (Thread-140): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:43.011492 (Thread-141): 02:22:43  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:22:43.011817 (Thread-141): 02:22:43  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:22:43.011980 (Thread-141): 02:22:43  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:22:43.012186 (Thread-141): 02:22:43  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:22:43.012367 (Thread-141): 02:22:43  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:22:43.016765 (Thread-141): 02:22:43  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:22:43.019327 (Thread-141): 02:22:43  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:22:43.766752 (Thread-142): handling status request
2022-04-21 02:22:43.767138 (Thread-142): 02:22:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c734430>]}
2022-04-21 02:22:43.767682 (Thread-142): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:43.849741 (Thread-143): handling status request
2022-04-21 02:22:43.850075 (Thread-143): 02:22:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c734c40>]}
2022-04-21 02:22:43.850573 (Thread-143): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:48.142848 (Thread-144): handling status request
2022-04-21 02:22:48.143214 (Thread-144): 02:22:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9de790>]}
2022-04-21 02:22:48.143714 (Thread-144): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:22:48.457292 (Thread-145): handling run_sql request
2022-04-21 02:22:48.457649 (Thread-145): 02:22:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c734cd0>]}
2022-04-21 02:22:48.458059 (Thread-145): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:26:29.812930 (Thread-146): 02:26:29  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:26:29.814951 (Thread-146): 02:26:29  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:26:29.815223 (Thread-146): 02:26:29  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:26:29.815426 (Thread-146): 02:26:29  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:26:29.815606 (Thread-146): 02:26:29  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:26:29.820205 (Thread-146): 02:26:29  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:26:29.822746 (Thread-146): 02:26:29  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:26:30.534087 (Thread-147): handling status request
2022-04-21 02:26:30.534423 (Thread-147): 02:26:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6c66d0>]}
2022-04-21 02:26:30.534938 (Thread-147): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:26:30.558168 (Thread-148): handling status request
2022-04-21 02:26:30.558458 (Thread-148): 02:26:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6c6250>]}
2022-04-21 02:26:30.558955 (Thread-148): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:27:15.249448 (Thread-149): 02:27:15  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:27:15.249774 (Thread-149): 02:27:15  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:27:15.249959 (Thread-149): 02:27:15  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:27:15.250155 (Thread-149): 02:27:15  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:27:15.250406 (Thread-149): 02:27:15  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:27:15.254442 (Thread-149): 02:27:15  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:27:15.256941 (Thread-149): 02:27:15  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:27:15.928438 (Thread-150): handling status request
2022-04-21 02:27:15.928767 (Thread-150): 02:27:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6b5910>]}
2022-04-21 02:27:15.929265 (Thread-150): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:27:15.995904 (Thread-151): handling status request
2022-04-21 02:27:15.996162 (Thread-151): 02:27:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6e78b0>]}
2022-04-21 02:27:15.996566 (Thread-151): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:27:27.050355 (Thread-152): handling status request
2022-04-21 02:27:27.050713 (Thread-152): 02:27:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6b5e20>]}
2022-04-21 02:27:27.051276 (Thread-152): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:27:27.450588 (Thread-153): handling run_sql request
2022-04-21 02:27:27.450856 (Thread-153): 02:27:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c6b5d90>]}
2022-04-21 02:27:27.451241 (Thread-153): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:24.418025 (Thread-154): handling status request
2022-04-21 02:28:24.418366 (Thread-154): 02:28:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e2700>]}
2022-04-21 02:28:24.418865 (Thread-154): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:24.791039 (Thread-155): handling run_sql request
2022-04-21 02:28:24.791317 (Thread-155): 02:28:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e2a90>]}
2022-04-21 02:28:24.791647 (Thread-155): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:30.535404 (Thread-156): handling status request
2022-04-21 02:28:30.535742 (Thread-156): 02:28:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e2b80>]}
2022-04-21 02:28:30.536257 (Thread-156): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:30.911490 (Thread-157): handling run_sql request
2022-04-21 02:28:30.911803 (Thread-157): 02:28:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e2e80>]}
2022-04-21 02:28:30.912162 (Thread-157): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:33.784150 (Thread-158): handling status request
2022-04-21 02:28:33.784479 (Thread-158): 02:28:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e9220>]}
2022-04-21 02:28:33.784975 (Thread-158): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:34.137842 (Thread-159): handling compile_sql request
2022-04-21 02:28:34.138139 (Thread-159): 02:28:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e9400>]}
2022-04-21 02:28:34.138479 (Thread-159): sending response (<Response 703 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:52.771654 (Thread-160): 02:28:52  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:28:52.771973 (Thread-160): 02:28:52  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:28:52.772156 (Thread-160): 02:28:52  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:28:52.772350 (Thread-160): 02:28:52  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:28:52.772623 (Thread-160): 02:28:52  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:28:52.776674 (Thread-160): 02:28:52  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:28:52.779169 (Thread-160): 02:28:52  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:28:53.485455 (Thread-161): handling status request
2022-04-21 02:28:53.485790 (Thread-161): 02:28:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c647130>]}
2022-04-21 02:28:53.486292 (Thread-161): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:28:53.637906 (Thread-162): handling status request
2022-04-21 02:28:53.638227 (Thread-162): 02:28:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c647730>]}
2022-04-21 02:28:53.638753 (Thread-162): sending response (<Response 2549 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:29:42.943880 (Thread-163): 02:29:42  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:29:42.944211 (Thread-163): 02:29:42  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:29:42.944398 (Thread-163): 02:29:42  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:29:42.944599 (Thread-163): 02:29:42  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:29:42.944850 (Thread-163): 02:29:42  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:29:42.949023 (Thread-163): 02:29:42  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:29:42.951779 (Thread-163): 02:29:42  1603: static parser failed on _archive/stg_query.sql
2022-04-21 02:29:43.718125 (Thread-164): handling status request
2022-04-21 02:29:43.718466 (Thread-164): 02:29:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4fc5e0>]}
2022-04-21 02:29:43.719005 (Thread-164): sending response (<Response 2552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:29:43.821769 (Thread-165): handling status request
2022-04-21 02:29:43.822009 (Thread-165): 02:29:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4fc820>]}
2022-04-21 02:29:43.822447 (Thread-165): sending response (<Response 2552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:29:49.542144 (Thread-166): handling status request
2022-04-21 02:29:49.542473 (Thread-166): 02:29:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4fc1c0>]}
2022-04-21 02:29:49.543006 (Thread-166): sending response (<Response 2552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:29:49.914855 (Thread-167): handling run_sql request
2022-04-21 02:29:49.915205 (Thread-167): 02:29:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c498bb0>]}
2022-04-21 02:29:49.939854 (Thread-167): sending response (<Response 709 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:30:29.754642 (Thread-168): handling status request
2022-04-21 02:30:29.755017 (Thread-168): 02:30:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c498d90>]}
2022-04-21 02:30:29.755544 (Thread-168): sending response (<Response 2552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:30:30.091580 (Thread-169): handling run_sql request
2022-04-21 02:30:30.091920 (Thread-169): 02:30:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c49c1f0>]}
2022-04-21 02:30:30.092295 (Thread-169): sending response (<Response 709 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:08.142186 (Thread-170): handling status request
2022-04-21 02:31:08.142521 (Thread-170): 02:31:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c49cdc0>]}
2022-04-21 02:31:08.143072 (Thread-170): sending response (<Response 2552 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:08.478591 (Thread-171): handling run_sql request
2022-04-21 02:31:08.478925 (Thread-171): 02:31:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c49c0d0>]}
2022-04-21 02:31:08.479349 (Thread-171): sending response (<Response 709 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:31.140923 (Thread-172): 02:31:31  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:31:31.141248 (Thread-172): 02:31:31  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:31:31.141435 (Thread-172): 02:31:31  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:31:31.141639 (Thread-172): 02:31:31  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:31:31.141891 (Thread-172): 02:31:31  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:31:31.280146 (Thread-172): 02:31:31  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:31:31.282153 (Thread-172): 02:31:31  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:31:31.820117 (Thread-173): handling status request
2022-04-21 02:31:31.820452 (Thread-173): 02:31:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c458790>]}
2022-04-21 02:31:31.820951 (Thread-173): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:32.035431 (Thread-174): handling status request
2022-04-21 02:31:32.035777 (Thread-174): 02:31:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5ddd90>]}
2022-04-21 02:31:32.036259 (Thread-174): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:33.458290 (Thread-175): handling status request
2022-04-21 02:31:33.458601 (Thread-175): 02:31:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c458370>]}
2022-04-21 02:31:33.459130 (Thread-175): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:31:33.854226 (Thread-176): handling run_sql request
2022-04-21 02:31:33.854531 (Thread-176): 02:31:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c458040>]}
2022-04-21 02:31:33.854900 (Thread-176): sending response (<Response 1375 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:28.190637 (Thread-177): 02:32:28  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:32:28.191168 (Thread-177): 02:32:28  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:32:28.191481 (Thread-177): 02:32:28  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:32:28.191782 (Thread-177): 02:32:28  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:32:28.192179 (Thread-177): 02:32:28  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:32:28.196491 (Thread-177): 02:32:28  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:32:28.198628 (Thread-177): 02:32:28  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:32:28.951114 (Thread-178): handling status request
2022-04-21 02:32:28.951442 (Thread-178): 02:32:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f9880>]}
2022-04-21 02:32:28.951933 (Thread-178): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:28.976455 (Thread-179): handling status request
2022-04-21 02:32:28.976688 (Thread-179): 02:32:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f9b80>]}
2022-04-21 02:32:28.977091 (Thread-179): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:48.740986 (Thread-180): handling status request
2022-04-21 02:32:48.741319 (Thread-180): 02:32:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f91c0>]}
2022-04-21 02:32:48.741811 (Thread-180): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:49.097572 (Thread-181): handling run_sql request
2022-04-21 02:32:49.097916 (Thread-181): 02:32:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f9a60>]}
2022-04-21 02:32:49.098269 (Thread-181): sending response (<Response 1375 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:58.698889 (Thread-182): handling status request
2022-04-21 02:32:58.699231 (Thread-182): 02:32:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f9550>]}
2022-04-21 02:32:58.699715 (Thread-182): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:32:59.048586 (Thread-183): handling run_sql request
2022-04-21 02:32:59.048854 (Thread-183): 02:32:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5ec070>]}
2022-04-21 02:32:59.049194 (Thread-183): sending response (<Response 1375 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:25.663415 (Thread-184): 02:33:25  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:33:25.663730 (Thread-184): 02:33:25  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:33:25.663917 (Thread-184): 02:33:25  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:33:25.664114 (Thread-184): 02:33:25  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:33:25.664364 (Thread-184): 02:33:25  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:33:25.667705 (Thread-184): 02:33:25  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:33:25.669559 (Thread-184): 02:33:25  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:33:26.383773 (Thread-185): handling status request
2022-04-21 02:33:26.384106 (Thread-185): 02:33:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c8e8580>]}
2022-04-21 02:33:26.384630 (Thread-185): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:26.428928 (Thread-186): handling status request
2022-04-21 02:33:26.429202 (Thread-186): 02:33:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f9bb0>]}
2022-04-21 02:33:26.429612 (Thread-186): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:28.033194 (Thread-187): 02:33:28  Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
2022-04-21 02:33:28.033509 (Thread-187): 02:33:28  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:33:28.033694 (Thread-187): 02:33:28  Partial parsing: added file: my_new_project://models/marts/_sources.yml
2022-04-21 02:33:28.033888 (Thread-187): 02:33:28  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:33:28.034135 (Thread-187): 02:33:28  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:33:28.037511 (Thread-187): 02:33:28  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:33:28.039398 (Thread-187): 02:33:28  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:33:28.729046 (Thread-188): handling status request
2022-04-21 02:33:28.729387 (Thread-188): 02:33:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c725370>]}
2022-04-21 02:33:28.729907 (Thread-188): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:28.763933 (Thread-189): handling status request
2022-04-21 02:33:28.764151 (Thread-189): 02:33:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c725df0>]}
2022-04-21 02:33:28.764549 (Thread-189): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:33.528287 (Thread-190): handling status request
2022-04-21 02:33:33.528605 (Thread-190): 02:33:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4f7d30>]}
2022-04-21 02:33:33.529093 (Thread-190): sending response (<Response 2895 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:33.902017 (Thread-191): handling run_sql request
2022-04-21 02:33:33.902374 (Thread-191): 02:33:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c648970>]}
2022-04-21 02:33:33.902757 (Thread-191): sending response (<Response 1375 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:57.516043 (Thread-192): 02:33:57  Partial parsing enabled: 0 files deleted, 1 files added, 2 files changed.
2022-04-21 02:33:57.516364 (Thread-192): 02:33:57  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:33:57.516578 (Thread-192): 02:33:57  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:33:57.516759 (Thread-192): 02:33:57  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:33:57.520185 (Thread-192): 02:33:57  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:33:57.522047 (Thread-192): 02:33:57  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:33:58.236254 (Thread-193): handling status request
2022-04-21 02:33:58.236595 (Thread-193): 02:33:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c87c1f0>]}
2022-04-21 02:33:58.237091 (Thread-193): sending response (<Response 2582 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:33:58.283528 (Thread-194): handling status request
2022-04-21 02:33:58.283824 (Thread-194): 02:33:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c87cc40>]}
2022-04-21 02:33:58.284294 (Thread-194): sending response (<Response 2582 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:05.081835 (Thread-195): handling status request
2022-04-21 02:34:05.082168 (Thread-195): 02:34:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c87ca60>]}
2022-04-21 02:34:05.082674 (Thread-195): sending response (<Response 2582 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:05.425470 (Thread-196): handling run_sql request
2022-04-21 02:34:05.425767 (Thread-196): 02:34:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c87c190>]}
2022-04-21 02:34:05.426130 (Thread-196): sending response (<Response 1375 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:28.515271 (Thread-197): 02:34:28  Partial parsing enabled: 0 files deleted, 1 files added, 2 files changed.
2022-04-21 02:34:28.515586 (Thread-197): 02:34:28  Partial parsing: added file: my_new_project://models/staging/_sources.yml
2022-04-21 02:34:28.515801 (Thread-197): 02:34:28  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:34:28.515982 (Thread-197): 02:34:28  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 02:34:28.519493 (Thread-197): 02:34:28  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:34:28.521396 (Thread-197): 02:34:28  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 02:34:28.572832 (Thread-197): 02:34:28  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c4fc400>]}
2022-04-21 02:34:29.305945 (Thread-198): handling status request
2022-04-21 02:34:29.306268 (Thread-198): 02:34:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb65a00>]}
2022-04-21 02:34:29.306764 (Thread-198): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:29.338196 (Thread-199): handling status request
2022-04-21 02:34:29.338409 (Thread-199): 02:34:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb65820>]}
2022-04-21 02:34:29.338784 (Thread-199): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:31.972957 (Thread-200): handling status request
2022-04-21 02:34:31.973282 (Thread-200): 02:34:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb65670>]}
2022-04-21 02:34:31.973769 (Thread-200): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:32.332110 (Thread-201): handling run_sql request
2022-04-21 02:34:32.332381 (Thread-201): 02:34:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb654c0>]}
2022-04-21 02:34:34.543686 (Thread-201): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:34.567087 (MainThread): 02:34:34  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46b3fb4e-30e3-4468-98e2-4a35f0009db4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2449ba56d0>]}
2022-04-21 02:34:34.567571 (MainThread): 02:34:34  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 02:34:34.568741 (Thread-1): 02:34:34  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:34:34.568870 (Thread-1): 02:34:34  Began compiling node rpc.my_new_project.request
2022-04-21 02:34:34.568957 (Thread-1): 02:34:34  Compiling rpc.my_new_project.request
2022-04-21 02:34:34.569968 (Thread-1): 02:34:34  finished collecting timing info
2022-04-21 02:34:34.570102 (Thread-1): 02:34:34  Began executing node rpc.my_new_project.request
2022-04-21 02:34:34.570639 (Thread-1): 02:34:34  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 02:34:34.570729 (Thread-1): 02:34:34  On rpc.my_new_project.request: select * from raw.interview_sample_data.interview_orders
-- select * from raw.interview_sample_data.interview_devices;
-- select * from raw.interview_sample_data.interview_orders;
-- select * from raw.interview_sample_data.interview_addresses;
-- select * from raw.interview_sample_data.interview_payments
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 02:34:34.570811 (Thread-1): 02:34:34  Opening a new connection, currently in state init
2022-04-21 02:34:34.925685 (Thread-202): handling poll request
2022-04-21 02:34:34.926058 (Thread-202): 02:34:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cb7d9a0>]}
2022-04-21 02:34:34.951072 (Thread-202): sending response (<Response 4039 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:34:35.632276 (Thread-1): 02:34:35  SQL status: SUCCESS 500 in 1.06 seconds
2022-04-21 02:34:35.646647 (Thread-1): 02:34:35  finished collecting timing info
2022-04-21 02:34:35.646880 (Thread-1): 02:34:35  On rpc.my_new_project.request: Close
2022-04-21 02:34:36.329836 (Thread-203): handling poll request
2022-04-21 02:34:36.330162 (Thread-203): 02:34:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b3760>]}
2022-04-21 02:34:36.333585 (Thread-203): sending response (<Response 63928 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:00.342404 (Thread-204): handling status request
2022-04-21 02:35:00.342728 (Thread-204): 02:35:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b34f0>]}
2022-04-21 02:35:00.343283 (Thread-204): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:00.737041 (Thread-205): handling run_sql request
2022-04-21 02:35:00.737353 (Thread-205): 02:35:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0b3b20>]}
2022-04-21 02:35:02.947831 (Thread-205): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:02.971892 (MainThread): 02:35:02  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd0dd3730-4ff4-44b9-8f4d-81de05a12350', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65faf73cd0>]}
2022-04-21 02:35:02.972404 (MainThread): 02:35:02  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 02:35:02.973638 (Thread-1): 02:35:02  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:35:02.973773 (Thread-1): 02:35:02  Began compiling node rpc.my_new_project.request
2022-04-21 02:35:02.973865 (Thread-1): 02:35:02  Compiling rpc.my_new_project.request
2022-04-21 02:35:02.974919 (Thread-1): 02:35:02  finished collecting timing info
2022-04-21 02:35:02.975079 (Thread-1): 02:35:02  Began executing node rpc.my_new_project.request
2022-04-21 02:35:02.975628 (Thread-1): 02:35:02  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 02:35:02.975719 (Thread-1): 02:35:02  On rpc.my_new_project.request: -- select * from raw.interview_sample_data.interview_orders
select * from raw.interview_sample_data.interview_devices;
2022-04-21 02:35:02.975800 (Thread-1): 02:35:02  Opening a new connection, currently in state init
2022-04-21 02:35:03.275938 (Thread-206): handling poll request
2022-04-21 02:35:03.276333 (Thread-206): 02:35:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0d040>]}
2022-04-21 02:35:03.277242 (Thread-206): sending response (<Response 3786 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:05.049814 (Thread-207): handling poll request
2022-04-21 02:35:05.050150 (Thread-207): 02:35:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0d610>]}
2022-04-21 02:35:05.050634 (Thread-207): sending response (<Response 391 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:05.059697 (Thread-1): 02:35:05  SQL status: SUCCESS 4499 in 2.08 seconds
2022-04-21 02:35:05.060008 (Thread-1): 02:35:05  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 02:35:05.060102 (Thread-1): 02:35:05  On rpc.my_new_project.request: -- select * from raw.interview_sample_data.interview_orders;
-- select * from raw.interview_sample_data.interview_addresses;
-- select * from raw.interview_sample_data.interview_payments
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 02:35:05.228274 (Thread-1): 02:35:05  Snowflake adapter: Snowflake query id: 01a3befb-0501-6083-0004-7d830483ca3e
2022-04-21 02:35:05.228419 (Thread-1): 02:35:05  Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 0 unexpected 'limit'.
2022-04-21 02:35:05.228599 (Thread-1): 02:35:05  finished collecting timing info
2022-04-21 02:35:05.228766 (Thread-1): 02:35:05  On rpc.my_new_project.request: Close
2022-04-21 02:35:05.442848 (Thread-1): Got an exception: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 0 unexpected 'limit'.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 001003 (42000): SQL compilation error:
syntax error line 1 at position 0 unexpected 'limit'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 0 unexpected 'limit'.
2022-04-21 02:35:05.443811 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  001003 (42000): SQL compilation error:\n  syntax error line 1 at position 0 unexpected 'limit'.", 'raw_sql': '-- select * from raw.interview_sample_data.interview_orders\r\nselect * from raw.interview_sample_data.interview_devices;\r\n-- select * from raw.interview_sample_data.interview_orders;\r\n-- select * from raw.interview_sample_data.interview_addresses;\r\n-- select * from raw.interview_sample_data.interview_payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '-- select * from raw.interview_sample_data.interview_orders\r\nselect * from raw.interview_sample_data.interview_devices;\r\n-- select * from raw.interview_sample_data.interview_orders;\r\n-- select * from raw.interview_sample_data.interview_addresses;\r\n-- select * from raw.interview_sample_data.interview_payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  001003 (42000): SQL compilation error:\n  syntax error line 1 at position 0 unexpected 'limit'.", 'raw_sql': '-- select * from raw.interview_sample_data.interview_orders\r\nselect * from raw.interview_sample_data.interview_devices;\r\n-- select * from raw.interview_sample_data.interview_orders;\r\n-- select * from raw.interview_sample_data.interview_addresses;\r\n-- select * from raw.interview_sample_data.interview_payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '-- select * from raw.interview_sample_data.interview_orders\r\nselect * from raw.interview_sample_data.interview_devices;\r\n-- select * from raw.interview_sample_data.interview_orders;\r\n-- select * from raw.interview_sample_data.interview_addresses;\r\n-- select * from raw.interview_sample_data.interview_payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-04-21 02:35:06.425008 (Thread-208): handling poll request
2022-04-21 02:35:06.425366 (Thread-208): 02:35:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0a580>]}
2022-04-21 02:35:06.426046 (Thread-208): sending response (<Response 12946 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:18.309632 (Thread-209): handling status request
2022-04-21 02:35:18.309959 (Thread-209): 02:35:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ccff9d0>]}
2022-04-21 02:35:18.310767 (Thread-209): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:18.727338 (Thread-210): handling run_sql request
2022-04-21 02:35:18.727666 (Thread-210): 02:35:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd0da30>]}
2022-04-21 02:35:20.994383 (Thread-210): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:21.018233 (MainThread): 02:35:21  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf5f4af1-b825-4b82-8bb2-13f239e25587', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6556a6d280>]}
2022-04-21 02:35:21.018753 (MainThread): 02:35:21  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 02:35:21.019997 (Thread-1): 02:35:21  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:35:21.020128 (Thread-1): 02:35:21  Began compiling node rpc.my_new_project.request
2022-04-21 02:35:21.020231 (Thread-1): 02:35:21  Compiling rpc.my_new_project.request
2022-04-21 02:35:21.021284 (Thread-1): 02:35:21  finished collecting timing info
2022-04-21 02:35:21.021413 (Thread-1): 02:35:21  Began executing node rpc.my_new_project.request
2022-04-21 02:35:21.021958 (Thread-1): 02:35:21  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 02:35:21.022046 (Thread-1): 02:35:21  On rpc.my_new_project.request: -- select * from raw.interview_sample_data.interview_orders
select * from raw.interview_sample_data.interview_devices
-- select * from raw.interview_sample_data.interview_orders;
-- select * from raw.interview_sample_data.interview_addresses;
-- select * from raw.interview_sample_data.interview_payments
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 02:35:21.022125 (Thread-1): 02:35:21  Opening a new connection, currently in state init
2022-04-21 02:35:21.320668 (Thread-211): handling poll request
2022-04-21 02:35:21.321072 (Thread-211): 02:35:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e31dca0>]}
2022-04-21 02:35:21.321966 (Thread-211): sending response (<Response 4038 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:35:22.208335 (Thread-1): 02:35:22  SQL status: SUCCESS 500 in 1.19 seconds
2022-04-21 02:35:22.220196 (Thread-1): 02:35:22  finished collecting timing info
2022-04-21 02:35:22.220429 (Thread-1): 02:35:22  On rpc.my_new_project.request: Close
2022-04-21 02:35:22.651602 (Thread-212): handling poll request
2022-04-21 02:35:22.651940 (Thread-212): 02:35:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e389220>]}
2022-04-21 02:35:22.654679 (Thread-212): sending response (<Response 31637 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:19.354940 (Thread-213): handling status request
2022-04-21 02:36:19.355340 (Thread-213): 02:36:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e389b80>]}
2022-04-21 02:36:19.355893 (Thread-213): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:19.733108 (Thread-214): handling run_sql request
2022-04-21 02:36:19.733423 (Thread-214): 02:36:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c9476d220>]}
2022-04-21 02:36:21.939618 (Thread-214): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:21.963604 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 125, in _get_exec_node
    add_new_refs(
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 50, in add_new_refs
    process_node(config, manifest, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1275, in process_node
    _process_sources_for_node(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1243, in _process_sources_for_node
    invalid_source_fail_unless_test(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 924, in invalid_source_fail_unless_test
    source_target_not_found(
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 651, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 454, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  Rpc 'rpc.my_new_project.request' (from remote system) depends on a source named 'interview_sample_data.orders' which was not found
2022-04-21 02:36:22.332226 (Thread-215): handling poll request
2022-04-21 02:36:22.332652 (Thread-215): 02:36:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9e5b0>]}
2022-04-21 02:36:22.333382 (Thread-215): sending response (<Response 2869 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:37.023044 (Thread-216): handling status request
2022-04-21 02:36:37.023397 (Thread-216): 02:36:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cf9e070>]}
2022-04-21 02:36:37.024019 (Thread-216): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:37.379852 (Thread-217): handling run_sql request
2022-04-21 02:36:37.380127 (Thread-217): 02:36:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3f0a7610>]}
2022-04-21 02:36:39.634111 (Thread-217): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:39.658174 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 125, in _get_exec_node
    add_new_refs(
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 50, in add_new_refs
    process_node(config, manifest, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1275, in process_node
    _process_sources_for_node(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1243, in _process_sources_for_node
    invalid_source_fail_unless_test(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 924, in invalid_source_fail_unless_test
    source_target_not_found(
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 651, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 454, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  Rpc 'rpc.my_new_project.request' (from remote system) depends on a source named 'interview_sample_data.intrview_orders' which was not found
2022-04-21 02:36:39.988355 (Thread-218): handling poll request
2022-04-21 02:36:39.988746 (Thread-218): 02:36:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3a79d0>]}
2022-04-21 02:36:39.989440 (Thread-218): sending response (<Response 2896 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:50.644980 (Thread-219): handling status request
2022-04-21 02:36:50.645319 (Thread-219): 02:36:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3a7820>]}
2022-04-21 02:36:50.645914 (Thread-219): sending response (<Response 2504 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:51.007969 (Thread-220): handling run_sql request
2022-04-21 02:36:51.008242 (Thread-220): 02:36:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3a7e80>]}
2022-04-21 02:36:53.231557 (Thread-220): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:53.256944 (MainThread): 02:36:53  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a24544ca-347b-4c1b-b860-b2217c1f521b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd3937e2e0>]}
2022-04-21 02:36:53.258093 (MainThread): 02:36:53  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 02:36:53.258666 (Thread-1): 02:36:53  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 02:36:53.258798 (Thread-1): 02:36:53  Began compiling node rpc.my_new_project.request
2022-04-21 02:36:53.258890 (Thread-1): 02:36:53  Compiling rpc.my_new_project.request
2022-04-21 02:36:53.260959 (Thread-1): 02:36:53  finished collecting timing info
2022-04-21 02:36:53.261097 (Thread-1): 02:36:53  Began executing node rpc.my_new_project.request
2022-04-21 02:36:53.261643 (Thread-1): 02:36:53  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 02:36:53.261732 (Thread-1): 02:36:53  On rpc.my_new_project.request: -- select * from raw.interview_sample_data.interview_orders
-- select * from raw.interview_sample_data.interview_devices
-- select * from raw.interview_sample_data.interview_orders
-- select * from raw.interview_sample_data.interview_addresses
-- select * from raw.interview_sample_data.interview_payments

select * from raw.interview_sample_data.interview_orders
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 02:36:53.261813 (Thread-1): 02:36:53  Opening a new connection, currently in state init
2022-04-21 02:36:53.569121 (Thread-221): handling poll request
2022-04-21 02:36:53.569541 (Thread-221): 02:36:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2ca280>]}
2022-04-21 02:36:53.570501 (Thread-221): sending response (<Response 4091 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:36:54.292674 (Thread-1): 02:36:54  SQL status: SUCCESS 500 in 1.03 seconds
2022-04-21 02:36:54.308446 (Thread-1): 02:36:54  finished collecting timing info
2022-04-21 02:36:54.308766 (Thread-1): 02:36:54  On rpc.my_new_project.request: Close
2022-04-21 02:36:54.972832 (Thread-222): handling poll request
2022-04-21 02:36:54.973150 (Thread-222): 02:36:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2f0640>]}
2022-04-21 02:36:54.976514 (Thread-222): sending response (<Response 64293 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:37:39.343495 (Thread-223): 02:37:39  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:37:39.343923 (Thread-223): 02:37:39  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:37:39.348009 (Thread-223): 02:37:39  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:37:39.389309 (Thread-223): 02:37:39  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cd1dc70>]}
2022-04-21 02:37:40.122140 (Thread-224): handling status request
2022-04-21 02:37:40.122479 (Thread-224): 02:37:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306bb0>]}
2022-04-21 02:37:40.123029 (Thread-224): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:37:40.192056 (Thread-225): handling status request
2022-04-21 02:37:40.192386 (Thread-225): 02:37:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306dc0>]}
2022-04-21 02:37:40.192879 (Thread-225): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:39:35.038775 (Thread-226): handling status request
2022-04-21 02:39:35.039665 (Thread-226): 02:39:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306a30>]}
2022-04-21 02:39:35.040160 (Thread-226): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:39:35.370456 (Thread-227): handling compile_sql request
2022-04-21 02:39:35.370788 (Thread-227): 02:39:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306a60>]}
2022-04-21 02:39:37.706141 (Thread-227): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:39:37.721180 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{source('interview_sample_data', 'interview_'{{t}} ),

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{source('interview_sample_data', 'interview_'{{t}} ),
2022-04-21 02:39:38.047086 (Thread-228): handling poll request
2022-04-21 02:39:38.047498 (Thread-228): 02:39:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3fc400>]}
2022-04-21 02:39:38.048245 (Thread-228): sending response (<Response 4511 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:40:06.279999 (Thread-229): handling status request
2022-04-21 02:40:06.280371 (Thread-229): 02:40:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3fcb50>]}
2022-04-21 02:40:06.280922 (Thread-229): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:40:06.616815 (Thread-230): handling compile_sql request
2022-04-21 02:40:06.617175 (Thread-230): 02:40:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3fcbb0>]}
2022-04-21 02:40:08.872309 (Thread-230): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:40:08.887165 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}} }} ),

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}} }} ),
2022-04-21 02:40:09.193409 (Thread-231): handling poll request
2022-04-21 02:40:09.193833 (Thread-231): 02:40:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e320850>]}
2022-04-21 02:40:09.194599 (Thread-231): sending response (<Response 4454 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:07.463026 (Thread-232): handling status request
2022-04-21 02:41:07.463365 (Thread-232): 02:41:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e377430>]}
2022-04-21 02:41:07.487693 (Thread-232): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:07.823226 (Thread-233): handling compile_sql request
2022-04-21 02:41:07.823573 (Thread-233): 02:41:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc03eb0>]}
2022-04-21 02:41:10.066288 (Thread-233): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:10.081174 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ),

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ),
2022-04-21 02:41:10.378375 (Thread-234): handling poll request
2022-04-21 02:41:10.378769 (Thread-234): 02:41:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c656fd0>]}
2022-04-21 02:41:10.379543 (Thread-234): sending response (<Response 4458 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:36.547705 (Thread-235): handling status request
2022-04-21 02:41:36.548050 (Thread-235): 02:41:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2ce6a0>]}
2022-04-21 02:41:36.548579 (Thread-235): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:36.889959 (Thread-236): handling compile_sql request
2022-04-21 02:41:36.890316 (Thread-236): 02:41:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2ced60>]}
2022-04-21 02:41:39.133848 (Thread-236): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:41:39.159321 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 125, in _get_exec_node
    add_new_refs(
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 50, in add_new_refs
    process_node(config, manifest, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1275, in process_node
    _process_sources_for_node(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 1243, in _process_sources_for_node
    invalid_source_fail_unless_test(
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/manifest.py", line 924, in invalid_source_fail_unless_test
    source_target_not_found(
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 651, in source_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 454, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  Rpc 'rpc.my_new_project.request' (from remote system) depends on a source named 'interview_sample_data.interview_{{t}}' which was not found
2022-04-21 02:41:39.455366 (Thread-237): handling poll request
2022-04-21 02:41:39.455790 (Thread-237): 02:41:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e3208e0>]}
2022-04-21 02:41:39.456531 (Thread-237): sending response (<Response 3030 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:16.331745 (Thread-238): handling status request
2022-04-21 02:42:16.332106 (Thread-238): 02:42:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306940>]}
2022-04-21 02:42:16.332689 (Thread-238): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:16.712732 (Thread-239): handling compile_sql request
2022-04-21 02:42:16.713000 (Thread-239): 02:42:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e306130>]}
2022-04-21 02:42:18.929860 (Thread-239): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:18.944242 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ),

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ),
2022-04-21 02:42:19.257640 (Thread-240): handling poll request
2022-04-21 02:42:19.258085 (Thread-240): 02:42:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc6fc40>]}
2022-04-21 02:42:19.258832 (Thread-240): sending response (<Response 4458 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:32.028756 (Thread-241): handling status request
2022-04-21 02:42:32.029109 (Thread-241): 02:42:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc9fe80>]}
2022-04-21 02:42:32.029649 (Thread-241): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:32.388791 (Thread-242): handling compile_sql request
2022-04-21 02:42:32.389084 (Thread-242): 02:42:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc9f550>]}
2022-04-21 02:42:34.648961 (Thread-242): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:34.663545 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} )

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} )
2022-04-21 02:42:34.969776 (Thread-243): handling poll request
2022-04-21 02:42:34.970189 (Thread-243): 02:42:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e307880>]}
2022-04-21 02:42:34.970914 (Thread-243): sending response (<Response 4454 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:42:59.827191 (Thread-244): handling status request
2022-04-21 02:42:59.827547 (Thread-244): 02:42:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6e307850>]}
2022-04-21 02:42:59.828099 (Thread-244): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:00.205881 (Thread-245): handling compile_sql request
2022-04-21 02:43:00.206164 (Thread-245): 02:43:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc97e50>]}
2022-04-21 02:43:02.437716 (Thread-245): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:02.452119 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ,)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as ( select * from {{ source('interview_sample_data', 'interview_'{{t}}) }} ,)
2022-04-21 02:43:02.785333 (Thread-246): handling poll request
2022-04-21 02:43:02.785754 (Thread-246): 02:43:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cc97f10>]}
2022-04-21 02:43:02.786514 (Thread-246): sending response (<Response 4458 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:21.769334 (Thread-247): 02:43:21  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:43:21.769705 (Thread-247): 02:43:21  Partial parsing: updated file: my_new_project://models/_archive/test_conn.sql
2022-04-21 02:43:21.774458 (Thread-247): 02:43:21  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 02:43:21.816605 (Thread-247): 02:43:21  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c9052b0>]}
2022-04-21 02:43:22.490313 (Thread-248): handling status request
2022-04-21 02:43:22.490640 (Thread-248): 02:43:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e2b0>]}
2022-04-21 02:43:22.491150 (Thread-248): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:22.596782 (Thread-249): handling status request
2022-04-21 02:43:22.597065 (Thread-249): 02:43:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79ee50>]}
2022-04-21 02:43:22.604373 (Thread-249): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:26.528859 (Thread-250): handling status request
2022-04-21 02:43:26.529226 (Thread-250): 02:43:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c532fd0>]}
2022-04-21 02:43:26.529686 (Thread-250): sending response (<Response 1566 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:26.843280 (Thread-251): handling compile_sql request
2022-04-21 02:43:26.843599 (Thread-251): 02:43:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c79e790>]}
2022-04-21 02:43:29.085570 (Thread-251): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:43:29.100014 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as select * from {{ source('interview_sample_data', 'interview_'{{t}}) }}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as select * from {{ source('interview_sample_data', 'interview_'{{t}}) }}
2022-04-21 02:43:29.446450 (Thread-252): handling poll request
2022-04-21 02:43:29.446824 (Thread-252): 02:43:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c5e2700>]}
2022-04-21 02:43:29.447559 (Thread-252): sending response (<Response 4438 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:45:06.677166 (Thread-253): 02:45:06  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:45:06.679416 (Thread-253): 02:45:06  Partial parsing: updated file: my_new_project://models/_archive/test_loop.sql
2022-04-21 02:45:06.683248 (Thread-253): 02:45:06  1603: static parser failed on _archive/test_loop.sql
2022-04-21 02:45:07.392038 (Thread-254): handling status request
2022-04-21 02:45:07.392378 (Thread-254): 02:45:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c65e100>]}
2022-04-21 02:45:07.392862 (Thread-254): sending response (<Response 1317 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:45:07.420001 (Thread-255): handling status request
2022-04-21 02:45:07.420250 (Thread-255): 02:45:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6d2ca3a0>]}
2022-04-21 02:45:07.420594 (Thread-255): sending response (<Response 1317 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:45:32.929445 (Thread-256): handling status request
2022-04-21 02:45:32.929780 (Thread-256): 02:45:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3c65e1f0>]}
2022-04-21 02:45:32.930247 (Thread-256): sending response (<Response 1317 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:45:35.711384 (Thread-257): 02:45:35  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 02:45:35.711742 (Thread-257): 02:45:35  Partial parsing: updated file: my_new_project://models/_archive/test_loop.sql
2022-04-21 02:45:35.715347 (Thread-257): 02:45:35  1603: static parser failed on _archive/test_loop.sql
2022-04-21 02:45:36.523791 (Thread-258): handling status request
2022-04-21 02:45:36.524128 (Thread-258): 02:45:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3cce4ee0>]}
2022-04-21 02:45:36.524597 (Thread-258): sending response (<Response 1317 bytes [200 OK]>) to 10.0.26.132
2022-04-21 02:45:36.589418 (Thread-259): handling status request
2022-04-21 02:45:36.589679 (Thread-259): 02:45:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e198575e-6fe8-469d-99f7-f2625cd635f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c3ccbf040>]}
2022-04-21 02:45:36.590084 (Thread-259): sending response (<Response 1317 bytes [200 OK]>) to 10.0.26.132
2022-04-21 23:07:31.062993 (MainThread): Running with dbt=1.0.5
2022-04-21 23:07:31.645791 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-04-21 23:07:31.655353 (MainThread): Tracking: tracking
2022-04-21 23:07:31.655686 (MainThread): 23:07:31  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad1b16670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d5a790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d65d60>]}
2022-04-21 23:07:31.656819 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=22
2022-04-21 23:07:31.661791 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-04-21 23:07:31.662027 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-04-21 23:07:31.683342 (Thread-12): 23:07:31  Unable to do partial parsing because of a dbt version mismatch. Saved manifest version: 1.0.4. Current version: 1.0.5.
2022-04-21 23:07:31.683648 (Thread-12): 23:07:31  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d2ed60>]}
2022-04-21 23:07:31.786132 (Thread-12): 23:07:31  Parsing macros/adapters.sql
2022-04-21 23:07:31.824450 (Thread-12): 23:07:31  Parsing macros/catalog.sql
2022-04-21 23:07:31.826382 (Thread-12): 23:07:31  Parsing macros/materializations/table.sql
2022-04-21 23:07:31.829389 (Thread-12): 23:07:31  Parsing macros/materializations/seed.sql
2022-04-21 23:07:31.834340 (Thread-12): 23:07:31  Parsing macros/materializations/incremental.sql
2022-04-21 23:07:31.842576 (Thread-12): 23:07:31  Parsing macros/materializations/merge.sql
2022-04-21 23:07:31.846193 (Thread-12): 23:07:31  Parsing macros/materializations/snapshot.sql
2022-04-21 23:07:31.847147 (Thread-12): 23:07:31  Parsing macros/materializations/view.sql
2022-04-21 23:07:31.848452 (Thread-12): 23:07:31  Parsing macros/adapters/metadata.sql
2022-04-21 23:07:31.855521 (Thread-12): 23:07:31  Parsing macros/adapters/columns.sql
2022-04-21 23:07:31.865118 (Thread-12): 23:07:31  Parsing macros/adapters/freshness.sql
2022-04-21 23:07:31.867928 (Thread-12): 23:07:31  Parsing macros/adapters/persist_docs.sql
2022-04-21 23:07:31.872155 (Thread-12): 23:07:31  Parsing macros/adapters/relation.sql
2022-04-21 23:07:31.881239 (Thread-12): 23:07:31  Parsing macros/adapters/schema.sql
2022-04-21 23:07:31.883344 (Thread-12): 23:07:31  Parsing macros/adapters/indexes.sql
2022-04-21 23:07:31.885915 (Thread-12): 23:07:31  Parsing macros/get_custom_name/get_custom_schema.sql
2022-04-21 23:07:31.888284 (Thread-12): 23:07:31  Parsing macros/get_custom_name/get_custom_alias.sql
2022-04-21 23:07:31.889732 (Thread-12): 23:07:31  Parsing macros/get_custom_name/get_custom_database.sql
2022-04-21 23:07:31.891257 (Thread-12): 23:07:31  Parsing macros/etc/datetime.sql
2022-04-21 23:07:31.899350 (Thread-12): 23:07:31  Parsing macros/etc/statement.sql
2022-04-21 23:07:31.903603 (Thread-12): 23:07:31  Parsing macros/generic_test_sql/unique.sql
2022-04-21 23:07:31.904309 (Thread-12): 23:07:31  Parsing macros/generic_test_sql/not_null.sql
2022-04-21 23:07:31.904864 (Thread-12): 23:07:31  Parsing macros/generic_test_sql/accepted_values.sql
2022-04-21 23:07:31.906181 (Thread-12): 23:07:31  Parsing macros/generic_test_sql/relationships.sql
2022-04-21 23:07:31.907071 (Thread-12): 23:07:31  Parsing macros/materializations/configs.sql
2022-04-21 23:07:31.909296 (Thread-12): 23:07:31  Parsing macros/materializations/hooks.sql
2022-04-21 23:07:31.912969 (Thread-12): 23:07:31  Parsing macros/materializations/models/table/table.sql
2022-04-21 23:07:31.920197 (Thread-12): 23:07:31  Parsing macros/materializations/models/table/create_table_as.sql
2022-04-21 23:07:31.922945 (Thread-12): 23:07:31  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-04-21 23:07:31.925524 (Thread-12): 23:07:31  Parsing macros/materializations/models/view/helpers.sql
2022-04-21 23:07:31.926818 (Thread-12): 23:07:31  Parsing macros/materializations/models/view/create_view_as.sql
2022-04-21 23:07:31.929043 (Thread-12): 23:07:31  Parsing macros/materializations/models/view/view.sql
2022-04-21 23:07:31.935890 (Thread-12): 23:07:31  Parsing macros/materializations/models/incremental/incremental.sql
2022-04-21 23:07:31.945466 (Thread-12): 23:07:31  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-04-21 23:07:31.960663 (Thread-12): 23:07:31  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-04-21 23:07:31.962178 (Thread-12): 23:07:31  Parsing macros/materializations/models/incremental/merge.sql
2022-04-21 23:07:31.973025 (Thread-12): 23:07:31  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-04-21 23:07:31.977365 (Thread-12): 23:07:31  Parsing macros/materializations/seeds/helpers.sql
2022-04-21 23:07:31.993005 (Thread-12): 23:07:31  Parsing macros/materializations/seeds/seed.sql
2022-04-21 23:07:31.998744 (Thread-12): 23:07:31  Parsing macros/materializations/tests/helpers.sql
2022-04-21 23:07:32.000579 (Thread-12): 23:07:32  Parsing macros/materializations/tests/test.sql
2022-04-21 23:07:32.004796 (Thread-12): 23:07:32  Parsing macros/materializations/tests/where_subquery.sql
2022-04-21 23:07:32.006557 (Thread-12): 23:07:32  Parsing macros/materializations/snapshots/helpers.sql
2022-04-21 23:07:32.017951 (Thread-12): 23:07:32  Parsing macros/materializations/snapshots/strategies.sql
2022-04-21 23:07:32.033891 (Thread-12): 23:07:32  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-04-21 23:07:32.035534 (Thread-12): 23:07:32  Parsing macros/materializations/snapshots/snapshot.sql
2022-04-21 23:07:32.046719 (Thread-12): 23:07:32  Parsing tests/generic/builtin.sql
2022-04-21 23:07:32.237655 (Thread-12): 23:07:32  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-04-21 23:07:32.249440 (Thread-12): 23:07:32  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-04-21 23:07:32.251536 (Thread-12): 23:07:32  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 23:07:32.253418 (Thread-12): 23:07:32  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 23:07:32.255360 (Thread-12): 23:07:32  1603: static parser failed on _archive/test_loop.sql
2022-04-21 23:07:34.751009 (Thread-13): handling status request
2022-04-21 23:07:34.751420 (Thread-13): 23:07:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4617160>]}
2022-04-21 23:07:34.752466 (Thread-13): sending response (<Response 16289 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:07:34.760560 (Thread-14): handling status request
2022-04-21 23:07:34.760890 (Thread-14): 23:07:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab45f14c0>]}
2022-04-21 23:07:34.761703 (Thread-14): sending response (<Response 16289 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:07:35.119757 (Thread-15): handling status request
2022-04-21 23:07:35.120149 (Thread-15): 23:07:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4617820>]}
2022-04-21 23:07:35.120991 (Thread-15): sending response (<Response 16289 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:07:35.154433 (Thread-16): handling ps request
2022-04-21 23:07:35.154833 (Thread-16): 23:07:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d03bb0>]}
2022-04-21 23:07:35.155309 (Thread-16): sending response (<Response 105 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:07:36.920966 (Thread-17): handling status request
2022-04-21 23:07:36.921389 (Thread-17): 23:07:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d028b0>]}
2022-04-21 23:07:36.922220 (Thread-17): sending response (<Response 16289 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:07:46.969657 (Thread-18): handling status request
2022-04-21 23:07:46.971283 (Thread-18): 23:07:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab460d7c0>]}
2022-04-21 23:07:46.972125 (Thread-18): sending response (<Response 16267 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:07:48.244281 (Thread-19): handling status request
2022-04-21 23:07:48.244668 (Thread-19): 23:07:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab460df10>]}
2022-04-21 23:07:48.245528 (Thread-19): sending response (<Response 16267 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:07:50.510061 (Thread-20): handling status request
2022-04-21 23:07:50.510514 (Thread-20): 23:07:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d03c10>]}
2022-04-21 23:07:50.511355 (Thread-20): sending response (<Response 16267 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:07:54.796011 (Thread-21): handling status request
2022-04-21 23:07:54.796366 (Thread-21): 23:07:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d65580>]}
2022-04-21 23:07:54.797169 (Thread-21): sending response (<Response 16267 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:10.830993 (Thread-22): handling status request
2022-04-21 23:08:10.832649 (Thread-22): 23:08:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4617160>]}
2022-04-21 23:08:10.833506 (Thread-22): sending response (<Response 16289 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:11.157724 (Thread-23): handling run_sql request
2022-04-21 23:08:11.158118 (Thread-23): 23:08:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4617610>]}
2022-04-21 23:08:11.158587 (Thread-23): sending response (<Response 741 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:28.772124 (Thread-24): 23:08:28  Unable to do partial parsing because of a dbt version mismatch. Saved manifest version: 1.0.4. Current version: 1.0.5.
2022-04-21 23:08:28.772444 (Thread-24): 23:08:28  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6cbf310>]}
2022-04-21 23:08:28.838587 (Thread-24): 23:08:28  Parsing macros/adapters.sql
2022-04-21 23:08:28.875726 (Thread-24): 23:08:28  Parsing macros/catalog.sql
2022-04-21 23:08:28.877608 (Thread-24): 23:08:28  Parsing macros/materializations/table.sql
2022-04-21 23:08:28.881185 (Thread-24): 23:08:28  Parsing macros/materializations/seed.sql
2022-04-21 23:08:28.886163 (Thread-24): 23:08:28  Parsing macros/materializations/incremental.sql
2022-04-21 23:08:28.894380 (Thread-24): 23:08:28  Parsing macros/materializations/merge.sql
2022-04-21 23:08:28.898017 (Thread-24): 23:08:28  Parsing macros/materializations/snapshot.sql
2022-04-21 23:08:28.898992 (Thread-24): 23:08:28  Parsing macros/materializations/view.sql
2022-04-21 23:08:28.900305 (Thread-24): 23:08:28  Parsing macros/adapters/metadata.sql
2022-04-21 23:08:28.907097 (Thread-24): 23:08:28  Parsing macros/adapters/columns.sql
2022-04-21 23:08:28.916542 (Thread-24): 23:08:28  Parsing macros/adapters/freshness.sql
2022-04-21 23:08:28.919349 (Thread-24): 23:08:28  Parsing macros/adapters/persist_docs.sql
2022-04-21 23:08:28.923532 (Thread-24): 23:08:28  Parsing macros/adapters/relation.sql
2022-04-21 23:08:28.932596 (Thread-24): 23:08:28  Parsing macros/adapters/schema.sql
2022-04-21 23:08:28.934705 (Thread-24): 23:08:28  Parsing macros/adapters/indexes.sql
2022-04-21 23:08:28.937271 (Thread-24): 23:08:28  Parsing macros/get_custom_name/get_custom_schema.sql
2022-04-21 23:08:28.939664 (Thread-24): 23:08:28  Parsing macros/get_custom_name/get_custom_alias.sql
2022-04-21 23:08:28.941095 (Thread-24): 23:08:28  Parsing macros/get_custom_name/get_custom_database.sql
2022-04-21 23:08:28.942628 (Thread-24): 23:08:28  Parsing macros/etc/datetime.sql
2022-04-21 23:08:28.950576 (Thread-24): 23:08:28  Parsing macros/etc/statement.sql
2022-04-21 23:08:28.954793 (Thread-24): 23:08:28  Parsing macros/generic_test_sql/unique.sql
2022-04-21 23:08:28.955497 (Thread-24): 23:08:28  Parsing macros/generic_test_sql/not_null.sql
2022-04-21 23:08:28.956095 (Thread-24): 23:08:28  Parsing macros/generic_test_sql/accepted_values.sql
2022-04-21 23:08:28.957424 (Thread-24): 23:08:28  Parsing macros/generic_test_sql/relationships.sql
2022-04-21 23:08:28.958301 (Thread-24): 23:08:28  Parsing macros/materializations/configs.sql
2022-04-21 23:08:28.960536 (Thread-24): 23:08:28  Parsing macros/materializations/hooks.sql
2022-04-21 23:08:28.964257 (Thread-24): 23:08:28  Parsing macros/materializations/models/table/table.sql
2022-04-21 23:08:28.971435 (Thread-24): 23:08:28  Parsing macros/materializations/models/table/create_table_as.sql
2022-04-21 23:08:28.974159 (Thread-24): 23:08:28  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-04-21 23:08:28.976719 (Thread-24): 23:08:28  Parsing macros/materializations/models/view/helpers.sql
2022-04-21 23:08:28.977990 (Thread-24): 23:08:28  Parsing macros/materializations/models/view/create_view_as.sql
2022-04-21 23:08:28.980244 (Thread-24): 23:08:28  Parsing macros/materializations/models/view/view.sql
2022-04-21 23:08:28.987104 (Thread-24): 23:08:28  Parsing macros/materializations/models/incremental/incremental.sql
2022-04-21 23:08:28.997013 (Thread-24): 23:08:28  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-04-21 23:08:29.012221 (Thread-24): 23:08:29  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-04-21 23:08:29.013695 (Thread-24): 23:08:29  Parsing macros/materializations/models/incremental/merge.sql
2022-04-21 23:08:29.024657 (Thread-24): 23:08:29  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-04-21 23:08:29.028937 (Thread-24): 23:08:29  Parsing macros/materializations/seeds/helpers.sql
2022-04-21 23:08:29.044558 (Thread-24): 23:08:29  Parsing macros/materializations/seeds/seed.sql
2022-04-21 23:08:29.050261 (Thread-24): 23:08:29  Parsing macros/materializations/tests/helpers.sql
2022-04-21 23:08:29.051998 (Thread-24): 23:08:29  Parsing macros/materializations/tests/test.sql
2022-04-21 23:08:29.056254 (Thread-24): 23:08:29  Parsing macros/materializations/tests/where_subquery.sql
2022-04-21 23:08:29.058003 (Thread-24): 23:08:29  Parsing macros/materializations/snapshots/helpers.sql
2022-04-21 23:08:29.068972 (Thread-24): 23:08:29  Parsing macros/materializations/snapshots/strategies.sql
2022-04-21 23:08:29.085177 (Thread-24): 23:08:29  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-04-21 23:08:29.086968 (Thread-24): 23:08:29  Parsing macros/materializations/snapshots/snapshot.sql
2022-04-21 23:08:29.098210 (Thread-24): 23:08:29  Parsing tests/generic/builtin.sql
2022-04-21 23:08:29.309228 (Thread-24): 23:08:29  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-04-21 23:08:29.312624 (Thread-24): 23:08:29  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-04-21 23:08:29.315340 (Thread-24): 23:08:29  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 23:08:29.318341 (Thread-24): 23:08:29  1699: static parser successfully parsed _archive/test_conn.sql
2022-04-21 23:08:29.321561 (Thread-24): 23:08:29  1603: static parser failed on _archive/test_loop.sql
2022-04-21 23:08:29.325868 (Thread-24): 23:08:29  1602: parser fallback to jinja rendering on _archive/test_loop.sql
2022-04-21 23:08:29.327413 (Thread-24): 23:08:29  1699: static parser successfully parsed _archive/orginal_query.sql
2022-04-21 23:08:29.461253 (Thread-24): 23:08:29  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab45e4400>]}
2022-04-21 23:08:29.502996 (Thread-25): handling status request
2022-04-21 23:08:29.503413 (Thread-25): 23:08:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab45310d0>]}
2022-04-21 23:08:29.504287 (Thread-25): sending response (<Response 17141 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:29.523423 (Thread-26): handling status request
2022-04-21 23:08:29.523757 (Thread-26): 23:08:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4531dc0>]}
2022-04-21 23:08:29.524575 (Thread-26): sending response (<Response 17141 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:31.673576 (Thread-27): handling status request
2022-04-21 23:08:31.673975 (Thread-27): 23:08:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4617340>]}
2022-04-21 23:08:31.674900 (Thread-27): sending response (<Response 17141 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:31.979619 (Thread-28): handling run_sql request
2022-04-21 23:08:31.980007 (Thread-28): 23:08:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab46174f0>]}
2022-04-21 23:08:34.487878 (Thread-28): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:34.511822 (MainThread): 23:08:34  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '595be687-5662-44f7-982f-1f2451ea1475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9abea424f0>]}
2022-04-21 23:08:34.512373 (MainThread): 23:08:34  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 23:08:34.512961 (Thread-1): 23:08:34  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 23:08:34.513099 (Thread-1): 23:08:34  Began compiling node rpc.my_new_project.request
2022-04-21 23:08:34.513192 (Thread-1): 23:08:34  Compiling rpc.my_new_project.request
2022-04-21 23:08:34.514464 (Thread-1): 23:08:34  finished collecting timing info
2022-04-21 23:08:34.514592 (Thread-1): 23:08:34  Began executing node rpc.my_new_project.request
2022-04-21 23:08:34.518222 (Thread-1): 23:08:34  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 23:08:34.518348 (Thread-1): 23:08:34  On rpc.my_new_project.request: -- import cte's
/*

step notes:

pull out source tables into cte's
create a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)
extract cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`

a couple of errors that were resolved in the set up:
  data type `int64` to `float`
  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`
  transform to lower case (using command pallet -- F1)
    
*/

-- logical cte's
-- final cte's
-- select statement


select
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

from (
    
    select
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status as order_status,
      case
        when o.status in (
          'paid',
          'completed',
          'shipped'
        ) then 'completed'
        else o.status
      end as order_status_category,
      case
        when oa.country_code is null then 'null country'
        when oa.country_code = 'us' then 'us'
        when oa.country_code != 'us' then 'international'
      end as country_type,
      o.shipping_method,
      case
        when d.device = 'web' then 'desktop'
        when d.device in ('ios-app', 'android-app') then 'mobile-app'
        when d.device in ('mobile', 'tablet') then 'mobile-web'
        when nullif(d.device, '') is null then 'unknown'
        else 'error'
      end as purchase_device_type,
      d.device as purchase_device,
      case
        when fo.first_order_id = o.order_id then 'new'
        else 'repeat'
      end as user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      case
        when o.currency = 'usd' then o.amount_total_cents
        else pa.gross_total_amount_cents
      end as total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    from raw.interview_sample_data.interview_orders o
    left join (
        select
          distinct cast(d.type_id as float) as order_id,
          first_value(d.device) over (
            partition by d.type_id
            order by
              d.created_at rows between unbounded preceding
              and unbounded following
          ) as device
        from raw.interview_sample_data.interview_devices d
        where d.type = 'order'
    ) d on d.order_id = o.order_id
    left join (
        select
          fo.user_id,
          min(fo.order_id) as first_order_id
        from raw.interview_sample_data.interview_orders as fo
        where
          fo.status != 'cancelled'
        group by
          fo.user_id
      ) fo on o.user_id = fo.user_id
    left join raw.interview_sample_data.interview_addresses oa 
      on oa.order_id = o.order_id
    left join (
        select
          order_id,
          sum(
            case
              when status = 'completed' then tax_amount_cents
              else 0
            end
          ) as gross_tax_amount_cents,
          sum(
            case
              when status = 'completed' then amount_cents
              else 0
            end
          ) as gross_amount_cents,
          sum(
            case
              when status = 'completed' then amount_shipping_cents
              else 0
            end
        ) as gross_shipping_amount_cents,
          sum(
            case
              when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents
              else 0
            end
          ) as gross_total_amount_cents
        from raw.interview_sample_data.interview_payments
        group by order_id
    ) pa on pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 23:08:34.518443 (Thread-1): 23:08:34  Opening a new connection, currently in state init
2022-04-21 23:08:34.828042 (Thread-29): handling poll request
2022-04-21 23:08:34.828492 (Thread-29): 23:08:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4533c70>]}
2022-04-21 23:08:34.829412 (Thread-29): sending response (<Response 8257 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:36.129006 (Thread-30): handling poll request
2022-04-21 23:08:36.129439 (Thread-30): 23:08:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4533880>]}
2022-04-21 23:08:36.129901 (Thread-30): sending response (<Response 391 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:37.438818 (Thread-31): handling poll request
2022-04-21 23:08:37.439305 (Thread-31): 23:08:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4533220>]}
2022-04-21 23:08:37.439830 (Thread-31): sending response (<Response 391 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:38.016187 (Thread-1): 23:08:38  SQL status: SUCCESS 500 in 3.5 seconds
2022-04-21 23:08:38.574387 (Thread-1): 23:08:38  finished collecting timing info
2022-04-21 23:08:38.574666 (Thread-1): 23:08:38  On rpc.my_new_project.request: Close
2022-04-21 23:08:38.748603 (Thread-32): handling poll request
2022-04-21 23:08:38.748989 (Thread-32): 23:08:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4533a90>]}
2022-04-21 23:08:38.749494 (Thread-32): sending response (<Response 1367 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:08:40.048512 (Thread-33): handling poll request
2022-04-21 23:08:40.048914 (Thread-33): 23:08:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4653460>]}
2022-04-21 23:08:40.057786 (Thread-33): sending response (<Response 152628 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:10:00.799065 (Thread-34): handling status request
2022-04-21 23:10:00.801022 (Thread-34): 23:10:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4653f10>]}
2022-04-21 23:10:00.801932 (Thread-34): sending response (<Response 17141 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:10:01.120626 (Thread-35): handling compile_sql request
2022-04-21 23:10:01.121016 (Thread-35): 23:10:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4617580>]}
2022-04-21 23:10:03.716329 (Thread-35): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:10:03.743626 (MainThread): 23:10:03  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c4d08e11-3a7d-495a-96d4-7c5268d8a0ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ffe7695e0>]}
2022-04-21 23:10:03.744157 (MainThread): 23:10:03  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 23:10:03.744742 (Thread-1): 23:10:03  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 23:10:03.744880 (Thread-1): 23:10:03  Began compiling node rpc.my_new_project.request
2022-04-21 23:10:03.744976 (Thread-1): 23:10:03  Compiling rpc.my_new_project.request
2022-04-21 23:10:03.747515 (Thread-1): 23:10:03  finished collecting timing info
2022-04-21 23:10:03.747644 (Thread-1): 23:10:03  Began executing node rpc.my_new_project.request
2022-04-21 23:10:03.747741 (Thread-1): 23:10:03  finished collecting timing info
2022-04-21 23:10:04.026094 (Thread-36): handling poll request
2022-04-21 23:10:04.026573 (Thread-36): 23:10:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6cb4160>]}
2022-04-21 23:10:04.027702 (Thread-36): sending response (<Response 7044 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:11:55.175339 (Thread-37): handling status request
2022-04-21 23:11:55.177156 (Thread-37): 23:11:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d12340>]}
2022-04-21 23:11:55.178224 (Thread-37): sending response (<Response 17141 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:11:55.505439 (Thread-38): handling compile_sql request
2022-04-21 23:11:55.505832 (Thread-38): 23:11:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d5adc0>]}
2022-04-21 23:11:57.972226 (Thread-38): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:11:57.986308 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 516, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 19, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 19
    {{t}} as select * from {{ source('interview_sample_data', 'interview_'{{t}}) }}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 590, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 543, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 519, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  expected token ',', got '{'
    line 19
      {{t}} as select * from {{ source('interview_sample_data', 'interview_'{{t}}) }}
2022-04-21 23:11:58.336736 (Thread-39): handling poll request
2022-04-21 23:11:58.337183 (Thread-39): 23:11:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d2ea30>]}
2022-04-21 23:11:58.360583 (Thread-39): sending response (<Response 4437 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:12:22.801213 (Thread-40): 23:12:22  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 23:12:22.801673 (Thread-40): 23:12:22  Partial parsing: updated file: my_new_project://models/_archive/test_loop.sql
2022-04-21 23:12:22.805878 (Thread-40): 23:12:22  1603: static parser failed on _archive/test_loop.sql
2022-04-21 23:12:22.810053 (Thread-40): 23:12:22  1602: parser fallback to jinja rendering on _archive/test_loop.sql
2022-04-21 23:12:22.851627 (Thread-40): 23:12:22  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab1d0f400>]}
2022-04-21 23:12:23.578768 (Thread-41): handling status request
2022-04-21 23:12:23.579149 (Thread-41): 23:12:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d02700>]}
2022-04-21 23:12:23.579634 (Thread-41): sending response (<Response 1859 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:12:23.820343 (Thread-42): handling status request
2022-04-21 23:12:23.820732 (Thread-42): 23:12:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6d02df0>]}
2022-04-21 23:12:23.821192 (Thread-42): sending response (<Response 1859 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:13:29.203091 (Thread-43): 23:13:29  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 23:13:29.204736 (Thread-43): 23:13:29  Partial parsing: updated file: my_new_project://models/_archive/test_loop.sql
2022-04-21 23:13:29.209086 (Thread-43): 23:13:29  1603: static parser failed on _archive/test_loop.sql
2022-04-21 23:13:29.212539 (Thread-43): 23:13:29  1602: parser fallback to jinja rendering on _archive/test_loop.sql
2022-04-21 23:13:29.254123 (Thread-43): 23:13:29  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf61d3a0>]}
2022-04-21 23:13:29.881429 (Thread-44): handling status request
2022-04-21 23:13:29.881830 (Thread-44): 23:13:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4648370>]}
2022-04-21 23:13:29.882358 (Thread-44): sending response (<Response 1859 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:13:29.957323 (Thread-45): handling status request
2022-04-21 23:13:29.957705 (Thread-45): 23:13:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab46485e0>]}
2022-04-21 23:13:29.958193 (Thread-45): sending response (<Response 1859 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:36:53.385181 (Thread-46): 23:36:53  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 23:36:53.387059 (Thread-46): 23:36:53  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 23:36:53.391208 (Thread-46): 23:36:53  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 23:36:53.436242 (Thread-46): 23:36:53  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf5fadf0>]}
2022-04-21 23:36:54.230210 (Thread-47): handling status request
2022-04-21 23:36:54.230631 (Thread-47): 23:36:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a9cf27a60>]}
2022-04-21 23:36:54.231114 (Thread-47): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:36:54.518331 (Thread-48): handling status request
2022-04-21 23:36:54.518738 (Thread-48): 23:36:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a9cf278b0>]}
2022-04-21 23:36:54.519215 (Thread-48): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:37:00.993415 (Thread-49): handling status request
2022-04-21 23:37:00.993811 (Thread-49): 23:37:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4659400>]}
2022-04-21 23:37:00.994300 (Thread-49): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:37:01.310014 (Thread-50): handling run_sql request
2022-04-21 23:37:01.310476 (Thread-50): 23:37:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4607b50>]}
2022-04-21 23:37:03.824083 (Thread-50): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:37:03.851241 (MainThread): 23:37:03  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f6f7ecb4-23c9-4cdb-9cb7-14ba417c1b1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41cb0a8ca0>]}
2022-04-21 23:37:03.851816 (MainThread): 23:37:03  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 23:37:03.852424 (Thread-1): 23:37:03  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 23:37:03.852559 (Thread-1): 23:37:03  Began compiling node rpc.my_new_project.request
2022-04-21 23:37:03.852650 (Thread-1): 23:37:03  Compiling rpc.my_new_project.request
2022-04-21 23:37:03.856202 (Thread-1): 23:37:03  finished collecting timing info
2022-04-21 23:37:03.856335 (Thread-1): 23:37:03  Began executing node rpc.my_new_project.request
2022-04-21 23:37:03.859886 (Thread-1): 23:37:03  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 23:37:03.859986 (Thread-1): 23:37:03  On rpc.my_new_project.request: -- import cte's

/*

step notes:

pull out source tables into cte's
create a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)
extract cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`

a couple of errors that were resolved in the set up:
  data type `int64` to `float`
  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`
  transform to lower case (using command pallet -- F1)
  changed `oa` to `a` for standarization
    
*/

with 
o as (select * from raw.interview_sample_data.interview_orders),
d as (select * from raw.interview_sample_data.interview_devices),
a as (select * from raw.interview_sample_data.interview_addresses),
p as (select * from raw.interview_sample_data.interview_payments),

-- logical cte's

/*

there are a lot of left join sub-queries, here is where we will try to simplify those

*/

d as (
  select distinct
    cast(d.type_id as float) as order_id,
    first_value(d.device) over (
      partition by d.type_id
      order by
      d.created_at rows between unbounded preceding
      and unbounded following
      ) as device
  from d
  where d.type = 'order'
),

fo as (
  select
    fo.user_id,
    min(fo.order_id) as first_order_id
  from o as fo
  where fo.status != 'cancelled'
  group by fo.user_id
),

pa as (
  select
    order_id,
  sum(case
        when status = 'completed' then tax_amount_cents else 0
      end
    ) as gross_tax_amount_cents,
  sum(case
        when status = 'completed' then amount_cents else 0
      end
    ) as gross_amount_cents,
  sum(case
        when status = 'completed' then amount_shipping_cents else 0
      end
    ) as gross_shipping_amount_cents,
  sum(case
        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0
      end
    ) as gross_total_amount_cents
  from p
  group by order_id
)





-- final cte's
-- select statement


select
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

from (
    
    select
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status as order_status,
      case
        when o.status in (
          'paid',
          'completed',
          'shipped'
        ) then 'completed'
        else o.status
      end as order_status_category,
      case
        when a.country_code is null then 'null country'
        when a.country_code = 'us' then 'us'
        when a.country_code != 'us' then 'international'
      end as country_type,
      o.shipping_method,
      case
        when d.device = 'web' then 'desktop'
        when d.device in ('ios-app', 'android-app') then 'mobile-app'
        when d.device in ('mobile', 'tablet') then 'mobile-web'
        when nullif(d.device, '') is null then 'unknown'
        else 'error'
      end as purchase_device_type,
      d.device as purchase_device,
      case
        when fo.first_order_id = o.order_id then 'new'
        else 'repeat'
      end as user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      case
        when o.currency = 'usd' then o.amount_total_cents
        else pa.gross_total_amount_cents
      end as total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    from o

    left join d
      on d.order_id = o.order_id

    left join fo
      on o.user_id = fo.user_id

    left join a 
      on a.order_id = o.order_id

    left join pa
      on pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 23:37:03.860066 (Thread-1): 23:37:03  Opening a new connection, currently in state init
2022-04-21 23:37:04.148073 (Thread-51): handling poll request
2022-04-21 23:37:04.148516 (Thread-51): 23:37:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab1cb8f10>]}
2022-04-21 23:37:04.149452 (Thread-51): sending response (<Response 7896 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:37:04.919144 (Thread-1): 23:37:04  Snowflake adapter: Snowflake query id: 01a3c3e9-0501-5fd8-0004-7d8304880916
2022-04-21 23:37:04.919376 (Thread-1): 23:37:04  Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 125 at position 9
invalid identifier 'D.ORDER_ID'
2022-04-21 23:37:04.919568 (Thread-1): 23:37:04  finished collecting timing info
2022-04-21 23:37:04.919771 (Thread-1): 23:37:04  On rpc.my_new_project.request: Close
2022-04-21 23:37:05.103428 (Thread-1): Got an exception: Database Error
  000904 (42000): SQL compilation error: error line 125 at position 9
  invalid identifier 'D.ORDER_ID'
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 125 at position 9
invalid identifier 'D.ORDER_ID'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  000904 (42000): SQL compilation error: error line 125 at position 9
  invalid identifier 'D.ORDER_ID'
2022-04-21 23:37:05.104513 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  000904 (42000): SQL compilation error: error line 125 at position 9\n  invalid identifier 'D.ORDER_ID'", 'raw_sql': "-- import cte's\r\n\r\n/*\r\n\r\nstep notes:\r\n\r\npull out source tables into cte's\r\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\r\nextract cte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n\r\na couple of errors that were resolved in the set up:\r\n  data type `int64` to `float`\r\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\r\n  transform to lower case (using command pallet -- F1)\r\n  changed `oa` to `a` for standarization\r\n    \r\n*/\r\n\r\nwith \r\no as (select * from {{ source('interview_sample_data', 'interview_orders') }}),\r\nd as (select * from {{ source('interview_sample_data', 'interview_devices') }}),\r\na as (select * from {{ source('interview_sample_data', 'interview_addresses')}}),\r\np as (select * from {{ source('interview_sample_data', 'interview_payments')}}),\r\n\r\n-- logical cte's\r\n\r\n/*\r\n\r\nthere are a lot of left join sub-queries, here is where we will try to simplify those\r\n\r\n*/\r\n\r\nd as (\r\n  select distinct\r\n    cast(d.type_id as float) as order_id,\r\n    first_value(d.device) over (\r\n      partition by d.type_id\r\n      order by\r\n      d.created_at rows between unbounded preceding\r\n      and unbounded following\r\n      ) as device\r\n  from d\r\n  where d.type = 'order'\r\n),\r\n\r\nfo as (\r\n  select\r\n    fo.user_id,\r\n    min(fo.order_id) as first_order_id\r\n  from o as fo\r\n  where fo.status != 'cancelled'\r\n  group by fo.user_id\r\n),\r\n\r\npa as (\r\n  select\r\n    order_id,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents else 0\r\n      end\r\n    ) as gross_tax_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_cents else 0\r\n      end\r\n    ) as gross_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_shipping_cents else 0\r\n      end\r\n    ) as gross_shipping_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\r\n      end\r\n    ) as gross_total_amount_cents\r\n  from p\r\n  group by order_id\r\n)\r\n\r\n\r\n\r\n\r\n\r\n-- final cte's\r\n-- select statement\r\n\r\n\r\nselect\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nfrom (\r\n    \r\n    select\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status as order_status,\r\n      case\r\n        when o.status in (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) then 'completed'\r\n        else o.status\r\n      end as order_status_category,\r\n      case\r\n        when a.country_code is null then 'null country'\r\n        when a.country_code = 'us' then 'us'\r\n        when a.country_code != 'us' then 'international'\r\n      end as country_type,\r\n      o.shipping_method,\r\n      case\r\n        when d.device = 'web' then 'desktop'\r\n        when d.device in ('ios-app', 'android-app') then 'mobile-app'\r\n        when d.device in ('mobile', 'tablet') then 'mobile-web'\r\n        when nullif(d.device, '') is null then 'unknown'\r\n        else 'error'\r\n      end as purchase_device_type,\r\n      d.device as purchase_device,\r\n      case\r\n        when fo.first_order_id = o.order_id then 'new'\r\n        else 'repeat'\r\n      end as user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      case\r\n        when o.currency = 'usd' then o.amount_total_cents\r\n        else pa.gross_total_amount_cents\r\n      end as total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    from o\r\n\r\n    left join d\r\n      on d.order_id = o.order_id\r\n\r\n    left join fo\r\n      on o.user_id = fo.user_id\r\n\r\n    left join a \r\n      on a.order_id = o.order_id\r\n\r\n    left join pa\r\n      on pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\n\n/*\n\nstep notes:\n\npull out source tables into cte's\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\nextract cte's we found in query:\n    `dbt-public.interview_task.orders` o\n    `dbt-public.interview_task.devices` d\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\n    `dbt-public.interview_task.addresses` oa \n    `dbt-public.interview_task.payments`\n\na couple of errors that were resolved in the set up:\n  data type `int64` to `float`\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\n  transform to lower case (using command pallet -- F1)\n  changed `oa` to `a` for standarization\n    \n*/\n\nwith \no as (select * from raw.interview_sample_data.interview_orders),\nd as (select * from raw.interview_sample_data.interview_devices),\na as (select * from raw.interview_sample_data.interview_addresses),\np as (select * from raw.interview_sample_data.interview_payments),\n\n-- logical cte's\n\n/*\n\nthere are a lot of left join sub-queries, here is where we will try to simplify those\n\n*/\n\nd as (\n  select distinct\n    cast(d.type_id as float) as order_id,\n    first_value(d.device) over (\n      partition by d.type_id\n      order by\n      d.created_at rows between unbounded preceding\n      and unbounded following\n      ) as device\n  from d\n  where d.type = 'order'\n),\n\nfo as (\n  select\n    fo.user_id,\n    min(fo.order_id) as first_order_id\n  from o as fo\n  where fo.status != 'cancelled'\n  group by fo.user_id\n),\n\npa as (\n  select\n    order_id,\n  sum(case\n        when status = 'completed' then tax_amount_cents else 0\n      end\n    ) as gross_tax_amount_cents,\n  sum(case\n        when status = 'completed' then amount_cents else 0\n      end\n    ) as gross_amount_cents,\n  sum(case\n        when status = 'completed' then amount_shipping_cents else 0\n      end\n    ) as gross_shipping_amount_cents,\n  sum(case\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\n      end\n    ) as gross_total_amount_cents\n  from p\n  group by order_id\n)\n\n\n\n\n\n-- final cte's\n-- select statement\n\n\nselect\n  *,\n  amount_total_cents / 100 as amount_total,\n  gross_total_amount_cents/ 100 as gross_total_amount,\n  total_amount_cents/ 100 as total_amount,\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\n  gross_amount_cents/ 100 as gross_amount,\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \n\nfrom (\n    \n    select\n      o.order_id,\n      o.user_id,\n      o.created_at,\n      o.updated_at,\n      o.shipped_at,\n      o.currency,\n      o.status as order_status,\n      case\n        when o.status in (\n          'paid',\n          'completed',\n          'shipped'\n        ) then 'completed'\n        else o.status\n      end as order_status_category,\n      case\n        when a.country_code is null then 'null country'\n        when a.country_code = 'us' then 'us'\n        when a.country_code != 'us' then 'international'\n      end as country_type,\n      o.shipping_method,\n      case\n        when d.device = 'web' then 'desktop'\n        when d.device in ('ios-app', 'android-app') then 'mobile-app'\n        when d.device in ('mobile', 'tablet') then 'mobile-web'\n        when nullif(d.device, '') is null then 'unknown'\n        else 'error'\n      end as purchase_device_type,\n      d.device as purchase_device,\n      case\n        when fo.first_order_id = o.order_id then 'new'\n        else 'repeat'\n      end as user_type,\n      o.amount_total_cents,\n      pa.gross_total_amount_cents,\n      case\n        when o.currency = 'usd' then o.amount_total_cents\n        else pa.gross_total_amount_cents\n      end as total_amount_cents,\n      pa.gross_tax_amount_cents,\n      pa.gross_amount_cents,\n      pa.gross_shipping_amount_cents\n    from o\n\n    left join d\n      on d.order_id = o.order_id\n\n    left join fo\n      on o.user_id = fo.user_id\n\n    left join a \n      on a.order_id = o.order_id\n\n    left join pa\n      on pa.order_id = o.order_id\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  000904 (42000): SQL compilation error: error line 125 at position 9\n  invalid identifier 'D.ORDER_ID'", 'raw_sql': "-- import cte's\r\n\r\n/*\r\n\r\nstep notes:\r\n\r\npull out source tables into cte's\r\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\r\nextract cte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n\r\na couple of errors that were resolved in the set up:\r\n  data type `int64` to `float`\r\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\r\n  transform to lower case (using command pallet -- F1)\r\n  changed `oa` to `a` for standarization\r\n    \r\n*/\r\n\r\nwith \r\no as (select * from {{ source('interview_sample_data', 'interview_orders') }}),\r\nd as (select * from {{ source('interview_sample_data', 'interview_devices') }}),\r\na as (select * from {{ source('interview_sample_data', 'interview_addresses')}}),\r\np as (select * from {{ source('interview_sample_data', 'interview_payments')}}),\r\n\r\n-- logical cte's\r\n\r\n/*\r\n\r\nthere are a lot of left join sub-queries, here is where we will try to simplify those\r\n\r\n*/\r\n\r\nd as (\r\n  select distinct\r\n    cast(d.type_id as float) as order_id,\r\n    first_value(d.device) over (\r\n      partition by d.type_id\r\n      order by\r\n      d.created_at rows between unbounded preceding\r\n      and unbounded following\r\n      ) as device\r\n  from d\r\n  where d.type = 'order'\r\n),\r\n\r\nfo as (\r\n  select\r\n    fo.user_id,\r\n    min(fo.order_id) as first_order_id\r\n  from o as fo\r\n  where fo.status != 'cancelled'\r\n  group by fo.user_id\r\n),\r\n\r\npa as (\r\n  select\r\n    order_id,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents else 0\r\n      end\r\n    ) as gross_tax_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_cents else 0\r\n      end\r\n    ) as gross_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_shipping_cents else 0\r\n      end\r\n    ) as gross_shipping_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\r\n      end\r\n    ) as gross_total_amount_cents\r\n  from p\r\n  group by order_id\r\n)\r\n\r\n\r\n\r\n\r\n\r\n-- final cte's\r\n-- select statement\r\n\r\n\r\nselect\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nfrom (\r\n    \r\n    select\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status as order_status,\r\n      case\r\n        when o.status in (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) then 'completed'\r\n        else o.status\r\n      end as order_status_category,\r\n      case\r\n        when a.country_code is null then 'null country'\r\n        when a.country_code = 'us' then 'us'\r\n        when a.country_code != 'us' then 'international'\r\n      end as country_type,\r\n      o.shipping_method,\r\n      case\r\n        when d.device = 'web' then 'desktop'\r\n        when d.device in ('ios-app', 'android-app') then 'mobile-app'\r\n        when d.device in ('mobile', 'tablet') then 'mobile-web'\r\n        when nullif(d.device, '') is null then 'unknown'\r\n        else 'error'\r\n      end as purchase_device_type,\r\n      d.device as purchase_device,\r\n      case\r\n        when fo.first_order_id = o.order_id then 'new'\r\n        else 'repeat'\r\n      end as user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      case\r\n        when o.currency = 'usd' then o.amount_total_cents\r\n        else pa.gross_total_amount_cents\r\n      end as total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    from o\r\n\r\n    left join d\r\n      on d.order_id = o.order_id\r\n\r\n    left join fo\r\n      on o.user_id = fo.user_id\r\n\r\n    left join a \r\n      on a.order_id = o.order_id\r\n\r\n    left join pa\r\n      on pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\n\n/*\n\nstep notes:\n\npull out source tables into cte's\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\nextract cte's we found in query:\n    `dbt-public.interview_task.orders` o\n    `dbt-public.interview_task.devices` d\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\n    `dbt-public.interview_task.addresses` oa \n    `dbt-public.interview_task.payments`\n\na couple of errors that were resolved in the set up:\n  data type `int64` to `float`\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\n  transform to lower case (using command pallet -- F1)\n  changed `oa` to `a` for standarization\n    \n*/\n\nwith \no as (select * from raw.interview_sample_data.interview_orders),\nd as (select * from raw.interview_sample_data.interview_devices),\na as (select * from raw.interview_sample_data.interview_addresses),\np as (select * from raw.interview_sample_data.interview_payments),\n\n-- logical cte's\n\n/*\n\nthere are a lot of left join sub-queries, here is where we will try to simplify those\n\n*/\n\nd as (\n  select distinct\n    cast(d.type_id as float) as order_id,\n    first_value(d.device) over (\n      partition by d.type_id\n      order by\n      d.created_at rows between unbounded preceding\n      and unbounded following\n      ) as device\n  from d\n  where d.type = 'order'\n),\n\nfo as (\n  select\n    fo.user_id,\n    min(fo.order_id) as first_order_id\n  from o as fo\n  where fo.status != 'cancelled'\n  group by fo.user_id\n),\n\npa as (\n  select\n    order_id,\n  sum(case\n        when status = 'completed' then tax_amount_cents else 0\n      end\n    ) as gross_tax_amount_cents,\n  sum(case\n        when status = 'completed' then amount_cents else 0\n      end\n    ) as gross_amount_cents,\n  sum(case\n        when status = 'completed' then amount_shipping_cents else 0\n      end\n    ) as gross_shipping_amount_cents,\n  sum(case\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\n      end\n    ) as gross_total_amount_cents\n  from p\n  group by order_id\n)\n\n\n\n\n\n-- final cte's\n-- select statement\n\n\nselect\n  *,\n  amount_total_cents / 100 as amount_total,\n  gross_total_amount_cents/ 100 as gross_total_amount,\n  total_amount_cents/ 100 as total_amount,\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\n  gross_amount_cents/ 100 as gross_amount,\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \n\nfrom (\n    \n    select\n      o.order_id,\n      o.user_id,\n      o.created_at,\n      o.updated_at,\n      o.shipped_at,\n      o.currency,\n      o.status as order_status,\n      case\n        when o.status in (\n          'paid',\n          'completed',\n          'shipped'\n        ) then 'completed'\n        else o.status\n      end as order_status_category,\n      case\n        when a.country_code is null then 'null country'\n        when a.country_code = 'us' then 'us'\n        when a.country_code != 'us' then 'international'\n      end as country_type,\n      o.shipping_method,\n      case\n        when d.device = 'web' then 'desktop'\n        when d.device in ('ios-app', 'android-app') then 'mobile-app'\n        when d.device in ('mobile', 'tablet') then 'mobile-web'\n        when nullif(d.device, '') is null then 'unknown'\n        else 'error'\n      end as purchase_device_type,\n      d.device as purchase_device,\n      case\n        when fo.first_order_id = o.order_id then 'new'\n        else 'repeat'\n      end as user_type,\n      o.amount_total_cents,\n      pa.gross_total_amount_cents,\n      case\n        when o.currency = 'usd' then o.amount_total_cents\n        else pa.gross_total_amount_cents\n      end as total_amount_cents,\n      pa.gross_tax_amount_cents,\n      pa.gross_amount_cents,\n      pa.gross_shipping_amount_cents\n    from o\n\n    left join d\n      on d.order_id = o.order_id\n\n    left join fo\n      on o.user_id = fo.user_id\n\n    left join a \n      on a.order_id = o.order_id\n\n    left join pa\n      on pa.order_id = o.order_id\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 23:37:05.453768 (Thread-52): handling poll request
2022-04-21 23:37:05.454160 (Thread-52): 23:37:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab1cb86a0>]}
2022-04-21 23:37:05.454956 (Thread-52): sending response (<Response 41283 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:38:35.127374 (Thread-53): handling status request
2022-04-21 23:38:35.129171 (Thread-53): 23:38:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab1cbf6d0>]}
2022-04-21 23:38:35.129699 (Thread-53): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:38:35.487135 (Thread-54): handling compile_sql request
2022-04-21 23:38:35.487549 (Thread-54): 23:38:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab1cbfc70>]}
2022-04-21 23:38:37.997187 (Thread-54): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:38:38.026612 (MainThread): 23:38:38  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '71f22049-adf9-4ea4-a3c0-6f58af78ac40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c009abc40>]}
2022-04-21 23:38:38.027138 (MainThread): 23:38:38  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 23:38:38.027712 (Thread-1): 23:38:38  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 23:38:38.027843 (Thread-1): 23:38:38  Began compiling node rpc.my_new_project.request
2022-04-21 23:38:38.027933 (Thread-1): 23:38:38  Compiling rpc.my_new_project.request
2022-04-21 23:38:38.031347 (Thread-1): 23:38:38  finished collecting timing info
2022-04-21 23:38:38.031493 (Thread-1): 23:38:38  Began executing node rpc.my_new_project.request
2022-04-21 23:38:38.031595 (Thread-1): 23:38:38  finished collecting timing info
2022-04-21 23:38:38.360759 (Thread-55): handling poll request
2022-04-21 23:38:38.361230 (Thread-55): 23:38:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6cefaf0>]}
2022-04-21 23:38:38.362517 (Thread-55): sending response (<Response 23032 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:57:42.640597 (Thread-56): 23:57:42  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-21 23:57:42.642543 (Thread-56): 23:57:42  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-21 23:57:42.646919 (Thread-56): 23:57:42  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-21 23:57:42.693653 (Thread-56): 23:57:42  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf55d670>]}
2022-04-21 23:57:43.290161 (Thread-57): handling status request
2022-04-21 23:57:43.290597 (Thread-57): 23:57:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf532c70>]}
2022-04-21 23:57:43.291098 (Thread-57): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:57:43.480137 (Thread-58): handling status request
2022-04-21 23:57:43.480524 (Thread-58): 23:57:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf532f40>]}
2022-04-21 23:57:43.480976 (Thread-58): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:57:44.856139 (Thread-59): handling status request
2022-04-21 23:57:44.856574 (Thread-59): 23:57:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6cbf940>]}
2022-04-21 23:57:44.857028 (Thread-59): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:57:45.205225 (Thread-60): handling run_sql request
2022-04-21 23:57:45.205622 (Thread-60): 23:57:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf532af0>]}
2022-04-21 23:57:47.688048 (Thread-60): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:57:47.714800 (MainThread): 23:57:47  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8146f5ea-f0de-4981-a0a1-c086316ebdf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16534a4d30>]}
2022-04-21 23:57:47.715341 (MainThread): 23:57:47  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 23:57:47.715928 (Thread-1): 23:57:47  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 23:57:47.716060 (Thread-1): 23:57:47  Began compiling node rpc.my_new_project.request
2022-04-21 23:57:47.716152 (Thread-1): 23:57:47  Compiling rpc.my_new_project.request
2022-04-21 23:57:47.719595 (Thread-1): 23:57:47  finished collecting timing info
2022-04-21 23:57:47.719724 (Thread-1): 23:57:47  Began executing node rpc.my_new_project.request
2022-04-21 23:57:47.723236 (Thread-1): 23:57:47  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 23:57:47.723334 (Thread-1): 23:57:47  On rpc.my_new_project.request: -- import cte's

/*

step notes:

pull out source tables into cte's
create a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)
extract cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`

a couple of errors that were resolved in the set up:
  data type `int64` to `float`
  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`
  transform to lower case (using command pallet -- F1)
  changed `oa` to `a` for standarization
    
*/

with 
o as (select * from raw.interview_sample_data.interview_orders),
d as (select * from raw.interview_sample_data.interview_devices),
a as (select * from raw.interview_sample_data.interview_addresses),
p as (select * from raw.interview_sample_data.interview_payments),

-- logical cte's

/*

there are a lot of left join sub-queries, here is where we will try to simplify those

*/

do as (
  select distinct
    cast(d.type_id as float) as order_id,
    first_value(d.device) over (
      partition by d.type_id
      order by
      d.created_at rows between unbounded preceding
      and unbounded following
      ) as device
  from d
  where d.type = 'order'
),

fo as (
  select
    fo.user_id,
    min(fo.order_id) as first_order_id
  from o as fo
  where fo.status != 'cancelled'
  group by fo.user_id
),

pa as (
  select
    order_id,
  sum(case
        when status = 'completed' then tax_amount_cents else 0
      end
    ) as gross_tax_amount_cents,
  sum(case
        when status = 'completed' then amount_cents else 0
      end
    ) as gross_amount_cents,
  sum(case
        when status = 'completed' then amount_shipping_cents else 0
      end
    ) as gross_shipping_amount_cents,
  sum(case
        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0
      end
    ) as gross_total_amount_cents
  from p
  group by order_id
)





-- final cte's
-- select statement


select
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

from (
    
    select
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status as order_status,
      case
        when o.status in (
          'paid',
          'completed',
          'shipped'
        ) then 'completed'
        else o.status
      end as order_status_category,
      case
        when a.country_code is null then 'null country'
        when a.country_code = 'us' then 'us'
        when a.country_code != 'us' then 'international'
      end as country_type,
      o.shipping_method,
      case
        when d.device = 'web' then 'desktop'
        when d.device in ('ios-app', 'android-app') then 'mobile-app'
        when d.device in ('mobile', 'tablet') then 'mobile-web'
        when nullif(d.device, '') is null then 'unknown'
        else 'error'
      end as purchase_device_type,
      d.device as purchase_device,
      case
        when fo.first_order_id = o.order_id then 'new'
        else 'repeat'
      end as user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      case
        when o.currency = 'usd' then o.amount_total_cents
        else pa.gross_total_amount_cents
      end as total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    from o

    left join d
      on d.order_id = o.order_id

    left join fo
      on o.user_id = fo.user_id

    left join a 
      on a.order_id = o.order_id

    left join pa
      on pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 23:57:47.723415 (Thread-1): 23:57:47  Opening a new connection, currently in state init
2022-04-21 23:57:48.022239 (Thread-61): handling poll request
2022-04-21 23:57:48.022722 (Thread-61): 23:57:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf5ad3d0>]}
2022-04-21 23:57:48.023845 (Thread-61): sending response (<Response 7897 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:57:48.684092 (Thread-1): 23:57:48  Snowflake adapter: Snowflake query id: 01a3c3fd-0501-6083-0004-7d8304883686
2022-04-21 23:57:48.684317 (Thread-1): 23:57:48  Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 125 at position 9
invalid identifier 'D.ORDER_ID'
2022-04-21 23:57:48.684514 (Thread-1): 23:57:48  finished collecting timing info
2022-04-21 23:57:48.684713 (Thread-1): 23:57:48  On rpc.my_new_project.request: Close
2022-04-21 23:57:48.878098 (Thread-1): Got an exception: Database Error
  000904 (42000): SQL compilation error: error line 125 at position 9
  invalid identifier 'D.ORDER_ID'
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 125 at position 9
invalid identifier 'D.ORDER_ID'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  000904 (42000): SQL compilation error: error line 125 at position 9
  invalid identifier 'D.ORDER_ID'
2022-04-21 23:57:48.879214 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  000904 (42000): SQL compilation error: error line 125 at position 9\n  invalid identifier 'D.ORDER_ID'", 'raw_sql': "-- import cte's\r\n\r\n/*\r\n\r\nstep notes:\r\n\r\npull out source tables into cte's\r\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\r\nextract cte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n\r\na couple of errors that were resolved in the set up:\r\n  data type `int64` to `float`\r\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\r\n  transform to lower case (using command pallet -- F1)\r\n  changed `oa` to `a` for standarization\r\n    \r\n*/\r\n\r\nwith \r\no as (select * from {{ source('interview_sample_data', 'interview_orders') }}),\r\nd as (select * from {{ source('interview_sample_data', 'interview_devices') }}),\r\na as (select * from {{ source('interview_sample_data', 'interview_addresses')}}),\r\np as (select * from {{ source('interview_sample_data', 'interview_payments')}}),\r\n\r\n-- logical cte's\r\n\r\n/*\r\n\r\nthere are a lot of left join sub-queries, here is where we will try to simplify those\r\n\r\n*/\r\n\r\ndo as (\r\n  select distinct\r\n    cast(d.type_id as float) as order_id,\r\n    first_value(d.device) over (\r\n      partition by d.type_id\r\n      order by\r\n      d.created_at rows between unbounded preceding\r\n      and unbounded following\r\n      ) as device\r\n  from d\r\n  where d.type = 'order'\r\n),\r\n\r\nfo as (\r\n  select\r\n    fo.user_id,\r\n    min(fo.order_id) as first_order_id\r\n  from o as fo\r\n  where fo.status != 'cancelled'\r\n  group by fo.user_id\r\n),\r\n\r\npa as (\r\n  select\r\n    order_id,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents else 0\r\n      end\r\n    ) as gross_tax_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_cents else 0\r\n      end\r\n    ) as gross_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_shipping_cents else 0\r\n      end\r\n    ) as gross_shipping_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\r\n      end\r\n    ) as gross_total_amount_cents\r\n  from p\r\n  group by order_id\r\n)\r\n\r\n\r\n\r\n\r\n\r\n-- final cte's\r\n-- select statement\r\n\r\n\r\nselect\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nfrom (\r\n    \r\n    select\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status as order_status,\r\n      case\r\n        when o.status in (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) then 'completed'\r\n        else o.status\r\n      end as order_status_category,\r\n      case\r\n        when a.country_code is null then 'null country'\r\n        when a.country_code = 'us' then 'us'\r\n        when a.country_code != 'us' then 'international'\r\n      end as country_type,\r\n      o.shipping_method,\r\n      case\r\n        when d.device = 'web' then 'desktop'\r\n        when d.device in ('ios-app', 'android-app') then 'mobile-app'\r\n        when d.device in ('mobile', 'tablet') then 'mobile-web'\r\n        when nullif(d.device, '') is null then 'unknown'\r\n        else 'error'\r\n      end as purchase_device_type,\r\n      d.device as purchase_device,\r\n      case\r\n        when fo.first_order_id = o.order_id then 'new'\r\n        else 'repeat'\r\n      end as user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      case\r\n        when o.currency = 'usd' then o.amount_total_cents\r\n        else pa.gross_total_amount_cents\r\n      end as total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    from o\r\n\r\n    left join d\r\n      on d.order_id = o.order_id\r\n\r\n    left join fo\r\n      on o.user_id = fo.user_id\r\n\r\n    left join a \r\n      on a.order_id = o.order_id\r\n\r\n    left join pa\r\n      on pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\n\n/*\n\nstep notes:\n\npull out source tables into cte's\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\nextract cte's we found in query:\n    `dbt-public.interview_task.orders` o\n    `dbt-public.interview_task.devices` d\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\n    `dbt-public.interview_task.addresses` oa \n    `dbt-public.interview_task.payments`\n\na couple of errors that were resolved in the set up:\n  data type `int64` to `float`\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\n  transform to lower case (using command pallet -- F1)\n  changed `oa` to `a` for standarization\n    \n*/\n\nwith \no as (select * from raw.interview_sample_data.interview_orders),\nd as (select * from raw.interview_sample_data.interview_devices),\na as (select * from raw.interview_sample_data.interview_addresses),\np as (select * from raw.interview_sample_data.interview_payments),\n\n-- logical cte's\n\n/*\n\nthere are a lot of left join sub-queries, here is where we will try to simplify those\n\n*/\n\ndo as (\n  select distinct\n    cast(d.type_id as float) as order_id,\n    first_value(d.device) over (\n      partition by d.type_id\n      order by\n      d.created_at rows between unbounded preceding\n      and unbounded following\n      ) as device\n  from d\n  where d.type = 'order'\n),\n\nfo as (\n  select\n    fo.user_id,\n    min(fo.order_id) as first_order_id\n  from o as fo\n  where fo.status != 'cancelled'\n  group by fo.user_id\n),\n\npa as (\n  select\n    order_id,\n  sum(case\n        when status = 'completed' then tax_amount_cents else 0\n      end\n    ) as gross_tax_amount_cents,\n  sum(case\n        when status = 'completed' then amount_cents else 0\n      end\n    ) as gross_amount_cents,\n  sum(case\n        when status = 'completed' then amount_shipping_cents else 0\n      end\n    ) as gross_shipping_amount_cents,\n  sum(case\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\n      end\n    ) as gross_total_amount_cents\n  from p\n  group by order_id\n)\n\n\n\n\n\n-- final cte's\n-- select statement\n\n\nselect\n  *,\n  amount_total_cents / 100 as amount_total,\n  gross_total_amount_cents/ 100 as gross_total_amount,\n  total_amount_cents/ 100 as total_amount,\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\n  gross_amount_cents/ 100 as gross_amount,\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \n\nfrom (\n    \n    select\n      o.order_id,\n      o.user_id,\n      o.created_at,\n      o.updated_at,\n      o.shipped_at,\n      o.currency,\n      o.status as order_status,\n      case\n        when o.status in (\n          'paid',\n          'completed',\n          'shipped'\n        ) then 'completed'\n        else o.status\n      end as order_status_category,\n      case\n        when a.country_code is null then 'null country'\n        when a.country_code = 'us' then 'us'\n        when a.country_code != 'us' then 'international'\n      end as country_type,\n      o.shipping_method,\n      case\n        when d.device = 'web' then 'desktop'\n        when d.device in ('ios-app', 'android-app') then 'mobile-app'\n        when d.device in ('mobile', 'tablet') then 'mobile-web'\n        when nullif(d.device, '') is null then 'unknown'\n        else 'error'\n      end as purchase_device_type,\n      d.device as purchase_device,\n      case\n        when fo.first_order_id = o.order_id then 'new'\n        else 'repeat'\n      end as user_type,\n      o.amount_total_cents,\n      pa.gross_total_amount_cents,\n      case\n        when o.currency = 'usd' then o.amount_total_cents\n        else pa.gross_total_amount_cents\n      end as total_amount_cents,\n      pa.gross_tax_amount_cents,\n      pa.gross_amount_cents,\n      pa.gross_shipping_amount_cents\n    from o\n\n    left join d\n      on d.order_id = o.order_id\n\n    left join fo\n      on o.user_id = fo.user_id\n\n    left join a \n      on a.order_id = o.order_id\n\n    left join pa\n      on pa.order_id = o.order_id\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  000904 (42000): SQL compilation error: error line 125 at position 9\n  invalid identifier 'D.ORDER_ID'", 'raw_sql': "-- import cte's\r\n\r\n/*\r\n\r\nstep notes:\r\n\r\npull out source tables into cte's\r\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\r\nextract cte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n\r\na couple of errors that were resolved in the set up:\r\n  data type `int64` to `float`\r\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\r\n  transform to lower case (using command pallet -- F1)\r\n  changed `oa` to `a` for standarization\r\n    \r\n*/\r\n\r\nwith \r\no as (select * from {{ source('interview_sample_data', 'interview_orders') }}),\r\nd as (select * from {{ source('interview_sample_data', 'interview_devices') }}),\r\na as (select * from {{ source('interview_sample_data', 'interview_addresses')}}),\r\np as (select * from {{ source('interview_sample_data', 'interview_payments')}}),\r\n\r\n-- logical cte's\r\n\r\n/*\r\n\r\nthere are a lot of left join sub-queries, here is where we will try to simplify those\r\n\r\n*/\r\n\r\ndo as (\r\n  select distinct\r\n    cast(d.type_id as float) as order_id,\r\n    first_value(d.device) over (\r\n      partition by d.type_id\r\n      order by\r\n      d.created_at rows between unbounded preceding\r\n      and unbounded following\r\n      ) as device\r\n  from d\r\n  where d.type = 'order'\r\n),\r\n\r\nfo as (\r\n  select\r\n    fo.user_id,\r\n    min(fo.order_id) as first_order_id\r\n  from o as fo\r\n  where fo.status != 'cancelled'\r\n  group by fo.user_id\r\n),\r\n\r\npa as (\r\n  select\r\n    order_id,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents else 0\r\n      end\r\n    ) as gross_tax_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_cents else 0\r\n      end\r\n    ) as gross_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_shipping_cents else 0\r\n      end\r\n    ) as gross_shipping_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\r\n      end\r\n    ) as gross_total_amount_cents\r\n  from p\r\n  group by order_id\r\n)\r\n\r\n\r\n\r\n\r\n\r\n-- final cte's\r\n-- select statement\r\n\r\n\r\nselect\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nfrom (\r\n    \r\n    select\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status as order_status,\r\n      case\r\n        when o.status in (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) then 'completed'\r\n        else o.status\r\n      end as order_status_category,\r\n      case\r\n        when a.country_code is null then 'null country'\r\n        when a.country_code = 'us' then 'us'\r\n        when a.country_code != 'us' then 'international'\r\n      end as country_type,\r\n      o.shipping_method,\r\n      case\r\n        when d.device = 'web' then 'desktop'\r\n        when d.device in ('ios-app', 'android-app') then 'mobile-app'\r\n        when d.device in ('mobile', 'tablet') then 'mobile-web'\r\n        when nullif(d.device, '') is null then 'unknown'\r\n        else 'error'\r\n      end as purchase_device_type,\r\n      d.device as purchase_device,\r\n      case\r\n        when fo.first_order_id = o.order_id then 'new'\r\n        else 'repeat'\r\n      end as user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      case\r\n        when o.currency = 'usd' then o.amount_total_cents\r\n        else pa.gross_total_amount_cents\r\n      end as total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    from o\r\n\r\n    left join d\r\n      on d.order_id = o.order_id\r\n\r\n    left join fo\r\n      on o.user_id = fo.user_id\r\n\r\n    left join a \r\n      on a.order_id = o.order_id\r\n\r\n    left join pa\r\n      on pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\n\n/*\n\nstep notes:\n\npull out source tables into cte's\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\nextract cte's we found in query:\n    `dbt-public.interview_task.orders` o\n    `dbt-public.interview_task.devices` d\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\n    `dbt-public.interview_task.addresses` oa \n    `dbt-public.interview_task.payments`\n\na couple of errors that were resolved in the set up:\n  data type `int64` to `float`\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\n  transform to lower case (using command pallet -- F1)\n  changed `oa` to `a` for standarization\n    \n*/\n\nwith \no as (select * from raw.interview_sample_data.interview_orders),\nd as (select * from raw.interview_sample_data.interview_devices),\na as (select * from raw.interview_sample_data.interview_addresses),\np as (select * from raw.interview_sample_data.interview_payments),\n\n-- logical cte's\n\n/*\n\nthere are a lot of left join sub-queries, here is where we will try to simplify those\n\n*/\n\ndo as (\n  select distinct\n    cast(d.type_id as float) as order_id,\n    first_value(d.device) over (\n      partition by d.type_id\n      order by\n      d.created_at rows between unbounded preceding\n      and unbounded following\n      ) as device\n  from d\n  where d.type = 'order'\n),\n\nfo as (\n  select\n    fo.user_id,\n    min(fo.order_id) as first_order_id\n  from o as fo\n  where fo.status != 'cancelled'\n  group by fo.user_id\n),\n\npa as (\n  select\n    order_id,\n  sum(case\n        when status = 'completed' then tax_amount_cents else 0\n      end\n    ) as gross_tax_amount_cents,\n  sum(case\n        when status = 'completed' then amount_cents else 0\n      end\n    ) as gross_amount_cents,\n  sum(case\n        when status = 'completed' then amount_shipping_cents else 0\n      end\n    ) as gross_shipping_amount_cents,\n  sum(case\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\n      end\n    ) as gross_total_amount_cents\n  from p\n  group by order_id\n)\n\n\n\n\n\n-- final cte's\n-- select statement\n\n\nselect\n  *,\n  amount_total_cents / 100 as amount_total,\n  gross_total_amount_cents/ 100 as gross_total_amount,\n  total_amount_cents/ 100 as total_amount,\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\n  gross_amount_cents/ 100 as gross_amount,\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \n\nfrom (\n    \n    select\n      o.order_id,\n      o.user_id,\n      o.created_at,\n      o.updated_at,\n      o.shipped_at,\n      o.currency,\n      o.status as order_status,\n      case\n        when o.status in (\n          'paid',\n          'completed',\n          'shipped'\n        ) then 'completed'\n        else o.status\n      end as order_status_category,\n      case\n        when a.country_code is null then 'null country'\n        when a.country_code = 'us' then 'us'\n        when a.country_code != 'us' then 'international'\n      end as country_type,\n      o.shipping_method,\n      case\n        when d.device = 'web' then 'desktop'\n        when d.device in ('ios-app', 'android-app') then 'mobile-app'\n        when d.device in ('mobile', 'tablet') then 'mobile-web'\n        when nullif(d.device, '') is null then 'unknown'\n        else 'error'\n      end as purchase_device_type,\n      d.device as purchase_device,\n      case\n        when fo.first_order_id = o.order_id then 'new'\n        else 'repeat'\n      end as user_type,\n      o.amount_total_cents,\n      pa.gross_total_amount_cents,\n      case\n        when o.currency = 'usd' then o.amount_total_cents\n        else pa.gross_total_amount_cents\n      end as total_amount_cents,\n      pa.gross_tax_amount_cents,\n      pa.gross_amount_cents,\n      pa.gross_shipping_amount_cents\n    from o\n\n    left join d\n      on d.order_id = o.order_id\n\n    left join fo\n      on o.user_id = fo.user_id\n\n    left join a \n      on a.order_id = o.order_id\n\n    left join pa\n      on pa.order_id = o.order_id\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 23:57:49.337686 (Thread-62): handling poll request
2022-04-21 23:57:49.338104 (Thread-62): 23:57:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6cb6cd0>]}
2022-04-21 23:57:49.338877 (Thread-62): sending response (<Response 41290 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:59:20.818012 (Thread-63): handling status request
2022-04-21 23:59:20.820038 (Thread-63): 23:59:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab453fc70>]}
2022-04-21 23:59:20.820539 (Thread-63): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:59:21.137025 (Thread-64): handling run_sql request
2022-04-21 23:59:21.137419 (Thread-64): 23:59:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab453f250>]}
2022-04-21 23:59:23.598250 (Thread-64): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:59:23.626949 (MainThread): 23:59:23  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e12f91b-c8ac-4a11-811b-9da8899fe9c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f950e0e0ca0>]}
2022-04-21 23:59:23.627667 (MainThread): 23:59:23  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 23:59:23.628112 (Thread-1): 23:59:23  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 23:59:23.628243 (Thread-1): 23:59:23  Began compiling node rpc.my_new_project.request
2022-04-21 23:59:23.628350 (Thread-1): 23:59:23  Compiling rpc.my_new_project.request
2022-04-21 23:59:23.630943 (Thread-1): 23:59:23  finished collecting timing info
2022-04-21 23:59:23.631072 (Thread-1): 23:59:23  Began executing node rpc.my_new_project.request
2022-04-21 23:59:23.631885 (Thread-1): 23:59:23  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 23:59:23.631973 (Thread-1): 23:59:23  On rpc.my_new_project.request: -- list tables




d as (select * from raw.interview_sample_data.interview_devices),


do as (
  select distinct
    cast(d.type_id as float) as order_id,
    first_value(d.device) over (
      partition by d.type_id
      order by
      d.created_at rows between unbounded preceding
      and unbounded following
      ) as device
  from d
  where d.type = 'order'
)

select * from do
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 23:59:23.632053 (Thread-1): 23:59:23  Opening a new connection, currently in state init
2022-04-21 23:59:23.922000 (Thread-65): handling poll request
2022-04-21 23:59:23.922472 (Thread-65): 23:59:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf55a6a0>]}
2022-04-21 23:59:23.923340 (Thread-65): sending response (<Response 4118 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:59:24.532477 (Thread-1): 23:59:24  Snowflake adapter: Snowflake query id: 01a3c3ff-0501-5fd8-0004-7d8304880d06
2022-04-21 23:59:24.532724 (Thread-1): 23:59:24  Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 0 unexpected 'd'.
2022-04-21 23:59:24.532930 (Thread-1): 23:59:24  finished collecting timing info
2022-04-21 23:59:24.533128 (Thread-1): 23:59:24  On rpc.my_new_project.request: Close
2022-04-21 23:59:24.724096 (Thread-1): Got an exception: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 0 unexpected 'd'.
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 001003 (42000): SQL compilation error:
syntax error line 1 at position 0 unexpected 'd'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 0 unexpected 'd'.
2022-04-21 23:59:24.725104 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  001003 (42000): SQL compilation error:\n  syntax error line 1 at position 0 unexpected 'd'.", 'raw_sql': "-- list tables\r\n{% set tables = ['orders', 'devices', 'orders', 'addresses', 'payments'] %}\r\n\r\n{#\r\n\r\n-- basic test\r\n{% for t in tables %}\r\n    table name is: raw.interview_sample_data.interview_{{t}}\r\n{% endfor %}\r\n\r\n-- testing tables\r\n{%- for t in tables %}\r\n    {{t}} as ( select * from raw.interview_sample_data.interview_{{t}} ),\r\n{%- endfor %}\r\n\r\n\r\n\r\n{%- for t in tables %}\r\n    {{t}} as select * from { source('interview_sample_data', 'interview_'{{t}}) }\r\n{%- endfor %}\r\n\r\n#}\r\n\r\nd as (select * from {{ source('interview_sample_data', 'interview_devices') }}),\r\n\r\n\r\ndo as (\r\n  select distinct\r\n    cast(d.type_id as float) as order_id,\r\n    first_value(d.device) over (\r\n      partition by d.type_id\r\n      order by\r\n      d.created_at rows between unbounded preceding\r\n      and unbounded following\r\n      ) as device\r\n  from d\r\n  where d.type = 'order'\r\n)\r\n\r\nselect * from do\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- list tables\n\n\n\n\nd as (select * from raw.interview_sample_data.interview_devices),\n\n\ndo as (\n  select distinct\n    cast(d.type_id as float) as order_id,\n    first_value(d.device) over (\n      partition by d.type_id\n      order by\n      d.created_at rows between unbounded preceding\n      and unbounded following\n      ) as device\n  from d\n  where d.type = 'order'\n)\n\nselect * from do\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  001003 (42000): SQL compilation error:\n  syntax error line 1 at position 0 unexpected 'd'.", 'raw_sql': "-- list tables\r\n{% set tables = ['orders', 'devices', 'orders', 'addresses', 'payments'] %}\r\n\r\n{#\r\n\r\n-- basic test\r\n{% for t in tables %}\r\n    table name is: raw.interview_sample_data.interview_{{t}}\r\n{% endfor %}\r\n\r\n-- testing tables\r\n{%- for t in tables %}\r\n    {{t}} as ( select * from raw.interview_sample_data.interview_{{t}} ),\r\n{%- endfor %}\r\n\r\n\r\n\r\n{%- for t in tables %}\r\n    {{t}} as select * from { source('interview_sample_data', 'interview_'{{t}}) }\r\n{%- endfor %}\r\n\r\n#}\r\n\r\nd as (select * from {{ source('interview_sample_data', 'interview_devices') }}),\r\n\r\n\r\ndo as (\r\n  select distinct\r\n    cast(d.type_id as float) as order_id,\r\n    first_value(d.device) over (\r\n      partition by d.type_id\r\n      order by\r\n      d.created_at rows between unbounded preceding\r\n      and unbounded following\r\n      ) as device\r\n  from d\r\n  where d.type = 'order'\r\n)\r\n\r\nselect * from do\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- list tables\n\n\n\n\nd as (select * from raw.interview_sample_data.interview_devices),\n\n\ndo as (\n  select distinct\n    cast(d.type_id as float) as order_id,\n    first_value(d.device) over (\n      partition by d.type_id\n      order by\n      d.created_at rows between unbounded preceding\n      and unbounded following\n      ) as device\n  from d\n  where d.type = 'order'\n)\n\nselect * from do\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-21 23:59:25.274434 (Thread-66): handling poll request
2022-04-21 23:59:25.274838 (Thread-66): 23:59:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf55a7c0>]}
2022-04-21 23:59:25.275465 (Thread-66): sending response (<Response 14565 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:59:32.602590 (Thread-67): handling status request
2022-04-21 23:59:32.603000 (Thread-67): 23:59:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf55ad60>]}
2022-04-21 23:59:32.603516 (Thread-67): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:59:33.101581 (Thread-68): handling run_sql request
2022-04-21 23:59:33.101977 (Thread-68): 23:59:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf55af40>]}
2022-04-21 23:59:35.599776 (Thread-68): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:59:35.626048 (MainThread): 23:59:35  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b022402b-a109-4041-8e79-fd09abf0b47a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadd6a29c70>]}
2022-04-21 23:59:35.626707 (MainThread): 23:59:35  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-21 23:59:35.627342 (Thread-1): 23:59:35  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-21 23:59:35.627471 (Thread-1): 23:59:35  Began compiling node rpc.my_new_project.request
2022-04-21 23:59:35.627620 (Thread-1): 23:59:35  Compiling rpc.my_new_project.request
2022-04-21 23:59:35.630241 (Thread-1): 23:59:35  finished collecting timing info
2022-04-21 23:59:35.630396 (Thread-1): 23:59:35  Began executing node rpc.my_new_project.request
2022-04-21 23:59:35.631272 (Thread-1): 23:59:35  Using snowflake connection "rpc.my_new_project.request"
2022-04-21 23:59:35.631364 (Thread-1): 23:59:35  On rpc.my_new_project.request: -- list tables



with 
d as (select * from raw.interview_sample_data.interview_devices),


do as (
  select distinct
    cast(d.type_id as float) as order_id,
    first_value(d.device) over (
      partition by d.type_id
      order by
      d.created_at rows between unbounded preceding
      and unbounded following
      ) as device
  from d
  where d.type = 'order'
)

select * from do
limit 500
/* limit added automatically by dbt cloud */
2022-04-21 23:59:35.631444 (Thread-1): 23:59:35  Opening a new connection, currently in state init
2022-04-21 23:59:35.903266 (Thread-69): handling poll request
2022-04-21 23:59:35.903746 (Thread-69): 23:59:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf55d8e0>]}
2022-04-21 23:59:35.928406 (Thread-69): sending response (<Response 4123 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:59:37.235279 (Thread-70): handling poll request
2022-04-21 23:59:37.235667 (Thread-70): 23:59:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf55dd00>]}
2022-04-21 23:59:37.236131 (Thread-70): sending response (<Response 391 bytes [200 OK]>) to 10.0.2.37
2022-04-21 23:59:37.316883 (Thread-1): 23:59:37  SQL status: SUCCESS 500 in 1.69 seconds
2022-04-21 23:59:37.323810 (Thread-1): 23:59:37  finished collecting timing info
2022-04-21 23:59:37.324070 (Thread-1): 23:59:37  On rpc.my_new_project.request: Close
2022-04-21 23:59:38.560162 (Thread-71): handling poll request
2022-04-21 23:59:38.560587 (Thread-71): 23:59:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf5ad190>]}
2022-04-21 23:59:38.562114 (Thread-71): sending response (<Response 16296 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:00:37.596411 (Thread-72): handling status request
2022-04-22 00:00:37.596817 (Thread-72): 00:00:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf4fcf10>]}
2022-04-22 00:00:37.597328 (Thread-72): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:00:37.934612 (Thread-73): handling run_sql request
2022-04-22 00:00:37.935024 (Thread-73): 00:00:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf501130>]}
2022-04-22 00:00:40.487216 (Thread-73): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:00:40.515591 (MainThread): 00:00:40  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9412c393-02bb-4880-b47f-9b0977f8bb4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf6311ad60>]}
2022-04-22 00:00:40.516130 (MainThread): 00:00:40  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-22 00:00:40.516735 (Thread-1): 00:00:40  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-22 00:00:40.516869 (Thread-1): 00:00:40  Began compiling node rpc.my_new_project.request
2022-04-22 00:00:40.516963 (Thread-1): 00:00:40  Compiling rpc.my_new_project.request
2022-04-22 00:00:40.520419 (Thread-1): 00:00:40  finished collecting timing info
2022-04-22 00:00:40.520553 (Thread-1): 00:00:40  Began executing node rpc.my_new_project.request
2022-04-22 00:00:40.524195 (Thread-1): 00:00:40  Using snowflake connection "rpc.my_new_project.request"
2022-04-22 00:00:40.524297 (Thread-1): 00:00:40  On rpc.my_new_project.request: -- import cte's

/*

step notes:

pull out source tables into cte's
create a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)
extract cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`

a couple of errors that were resolved in the set up:
  data type `int64` to `float`
  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`
  transform to lower case (using command pallet -- F1)
  changed `oa` to `a` for standarization
    
*/

with 
o as (select * from raw.interview_sample_data.interview_orders),
d as (select * from raw.interview_sample_data.interview_devices),
a as (select * from raw.interview_sample_data.interview_addresses),
p as (select * from raw.interview_sample_data.interview_payments),

-- logical cte's

/*

there are a lot of left join sub-queries, here is where we will try to simplify those

*/

do as (
  select distinct
    cast(d.type_id as float) as order_id,
    first_value(d.device) over (
      partition by d.type_id
      order by
      d.created_at rows between unbounded preceding
      and unbounded following
      ) as device
  from d
  where d.type = 'order'
),

fo as (
  select
    fo.user_id,
    min(fo.order_id) as first_order_id
  from o as fo
  where fo.status != 'cancelled'
  group by fo.user_id
),

pa as (
  select
    order_id,
  sum(case
        when status = 'completed' then tax_amount_cents else 0
      end
    ) as gross_tax_amount_cents,
  sum(case
        when status = 'completed' then amount_cents else 0
      end
    ) as gross_amount_cents,
  sum(case
        when status = 'completed' then amount_shipping_cents else 0
      end
    ) as gross_shipping_amount_cents,
  sum(case
        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0
      end
    ) as gross_total_amount_cents
  from p
  group by order_id
)





-- final cte's
-- select statement


select
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

from (
    
    select
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status as order_status,
      case
        when o.status in (
          'paid',
          'completed',
          'shipped'
        ) then 'completed'
        else o.status
      end as order_status_category,
      case
        when a.country_code is null then 'null country'
        when a.country_code = 'us' then 'us'
        when a.country_code != 'us' then 'international'
      end as country_type,
      o.shipping_method,
      case
        when do.device = 'web' then 'desktop'
        when do.device in ('ios-app', 'android-app') then 'mobile-app'
        when do.device in ('mobile', 'tablet') then 'mobile-web'
        when nullif(d.device, '') is null then 'unknown'
        else 'error'
      end as purchase_device_type,
      do.device as purchase_device,
      case
        when fo.first_order_id = o.order_id then 'new'
        else 'repeat'
      end as user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      case
        when o.currency = 'usd' then o.amount_total_cents
        else pa.gross_total_amount_cents
      end as total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    from o

    left join do
      on do.order_id = o.order_id

    left join fo
      on o.user_id = fo.user_id

    left join a 
      on a.order_id = o.order_id

    left join pa
      on pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-22 00:00:40.524377 (Thread-1): 00:00:40  Opening a new connection, currently in state init
2022-04-22 00:00:40.800440 (Thread-74): handling poll request
2022-04-22 00:00:40.800906 (Thread-74): 00:00:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf540520>]}
2022-04-22 00:00:40.801790 (Thread-74): sending response (<Response 7902 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:00:41.610235 (Thread-1): 00:00:41  Snowflake adapter: Snowflake query id: 01a3c400-0501-6083-0004-7d83048836c2
2022-04-22 00:00:41.610509 (Thread-1): 00:00:41  Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 105 at position 20
invalid identifier 'D.DEVICE'
2022-04-22 00:00:41.610703 (Thread-1): 00:00:41  finished collecting timing info
2022-04-22 00:00:41.610903 (Thread-1): 00:00:41  On rpc.my_new_project.request: Close
2022-04-22 00:00:41.847899 (Thread-1): Got an exception: Database Error
  000904 (42000): SQL compilation error: error line 105 at position 20
  invalid identifier 'D.DEVICE'
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 206, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/cursor.py", line 789, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 273, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 328, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/lib/python3.8/dist-packages/snowflake/connector/errors.py", line 207, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 105 at position 20
invalid identifier 'D.DEVICE'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 433, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/snowflake/connections.py", line 223, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  000904 (42000): SQL compilation error: error line 105 at position 20
  invalid identifier 'D.DEVICE'
2022-04-22 00:00:41.848948 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  000904 (42000): SQL compilation error: error line 105 at position 20\n  invalid identifier 'D.DEVICE'", 'raw_sql': "-- import cte's\r\n\r\n/*\r\n\r\nstep notes:\r\n\r\npull out source tables into cte's\r\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\r\nextract cte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n\r\na couple of errors that were resolved in the set up:\r\n  data type `int64` to `float`\r\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\r\n  transform to lower case (using command pallet -- F1)\r\n  changed `oa` to `a` for standarization\r\n    \r\n*/\r\n\r\nwith \r\no as (select * from {{ source('interview_sample_data', 'interview_orders') }}),\r\nd as (select * from {{ source('interview_sample_data', 'interview_devices') }}),\r\na as (select * from {{ source('interview_sample_data', 'interview_addresses')}}),\r\np as (select * from {{ source('interview_sample_data', 'interview_payments')}}),\r\n\r\n-- logical cte's\r\n\r\n/*\r\n\r\nthere are a lot of left join sub-queries, here is where we will try to simplify those\r\n\r\n*/\r\n\r\ndo as (\r\n  select distinct\r\n    cast(d.type_id as float) as order_id,\r\n    first_value(d.device) over (\r\n      partition by d.type_id\r\n      order by\r\n      d.created_at rows between unbounded preceding\r\n      and unbounded following\r\n      ) as device\r\n  from d\r\n  where d.type = 'order'\r\n),\r\n\r\nfo as (\r\n  select\r\n    fo.user_id,\r\n    min(fo.order_id) as first_order_id\r\n  from o as fo\r\n  where fo.status != 'cancelled'\r\n  group by fo.user_id\r\n),\r\n\r\npa as (\r\n  select\r\n    order_id,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents else 0\r\n      end\r\n    ) as gross_tax_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_cents else 0\r\n      end\r\n    ) as gross_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_shipping_cents else 0\r\n      end\r\n    ) as gross_shipping_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\r\n      end\r\n    ) as gross_total_amount_cents\r\n  from p\r\n  group by order_id\r\n)\r\n\r\n\r\n\r\n\r\n\r\n-- final cte's\r\n-- select statement\r\n\r\n\r\nselect\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nfrom (\r\n    \r\n    select\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status as order_status,\r\n      case\r\n        when o.status in (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) then 'completed'\r\n        else o.status\r\n      end as order_status_category,\r\n      case\r\n        when a.country_code is null then 'null country'\r\n        when a.country_code = 'us' then 'us'\r\n        when a.country_code != 'us' then 'international'\r\n      end as country_type,\r\n      o.shipping_method,\r\n      case\r\n        when do.device = 'web' then 'desktop'\r\n        when do.device in ('ios-app', 'android-app') then 'mobile-app'\r\n        when do.device in ('mobile', 'tablet') then 'mobile-web'\r\n        when nullif(d.device, '') is null then 'unknown'\r\n        else 'error'\r\n      end as purchase_device_type,\r\n      do.device as purchase_device,\r\n      case\r\n        when fo.first_order_id = o.order_id then 'new'\r\n        else 'repeat'\r\n      end as user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      case\r\n        when o.currency = 'usd' then o.amount_total_cents\r\n        else pa.gross_total_amount_cents\r\n      end as total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    from o\r\n\r\n    left join do\r\n      on do.order_id = o.order_id\r\n\r\n    left join fo\r\n      on o.user_id = fo.user_id\r\n\r\n    left join a \r\n      on a.order_id = o.order_id\r\n\r\n    left join pa\r\n      on pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\n\n/*\n\nstep notes:\n\npull out source tables into cte's\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\nextract cte's we found in query:\n    `dbt-public.interview_task.orders` o\n    `dbt-public.interview_task.devices` d\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\n    `dbt-public.interview_task.addresses` oa \n    `dbt-public.interview_task.payments`\n\na couple of errors that were resolved in the set up:\n  data type `int64` to `float`\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\n  transform to lower case (using command pallet -- F1)\n  changed `oa` to `a` for standarization\n    \n*/\n\nwith \no as (select * from raw.interview_sample_data.interview_orders),\nd as (select * from raw.interview_sample_data.interview_devices),\na as (select * from raw.interview_sample_data.interview_addresses),\np as (select * from raw.interview_sample_data.interview_payments),\n\n-- logical cte's\n\n/*\n\nthere are a lot of left join sub-queries, here is where we will try to simplify those\n\n*/\n\ndo as (\n  select distinct\n    cast(d.type_id as float) as order_id,\n    first_value(d.device) over (\n      partition by d.type_id\n      order by\n      d.created_at rows between unbounded preceding\n      and unbounded following\n      ) as device\n  from d\n  where d.type = 'order'\n),\n\nfo as (\n  select\n    fo.user_id,\n    min(fo.order_id) as first_order_id\n  from o as fo\n  where fo.status != 'cancelled'\n  group by fo.user_id\n),\n\npa as (\n  select\n    order_id,\n  sum(case\n        when status = 'completed' then tax_amount_cents else 0\n      end\n    ) as gross_tax_amount_cents,\n  sum(case\n        when status = 'completed' then amount_cents else 0\n      end\n    ) as gross_amount_cents,\n  sum(case\n        when status = 'completed' then amount_shipping_cents else 0\n      end\n    ) as gross_shipping_amount_cents,\n  sum(case\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\n      end\n    ) as gross_total_amount_cents\n  from p\n  group by order_id\n)\n\n\n\n\n\n-- final cte's\n-- select statement\n\n\nselect\n  *,\n  amount_total_cents / 100 as amount_total,\n  gross_total_amount_cents/ 100 as gross_total_amount,\n  total_amount_cents/ 100 as total_amount,\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\n  gross_amount_cents/ 100 as gross_amount,\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \n\nfrom (\n    \n    select\n      o.order_id,\n      o.user_id,\n      o.created_at,\n      o.updated_at,\n      o.shipped_at,\n      o.currency,\n      o.status as order_status,\n      case\n        when o.status in (\n          'paid',\n          'completed',\n          'shipped'\n        ) then 'completed'\n        else o.status\n      end as order_status_category,\n      case\n        when a.country_code is null then 'null country'\n        when a.country_code = 'us' then 'us'\n        when a.country_code != 'us' then 'international'\n      end as country_type,\n      o.shipping_method,\n      case\n        when do.device = 'web' then 'desktop'\n        when do.device in ('ios-app', 'android-app') then 'mobile-app'\n        when do.device in ('mobile', 'tablet') then 'mobile-web'\n        when nullif(d.device, '') is null then 'unknown'\n        else 'error'\n      end as purchase_device_type,\n      do.device as purchase_device,\n      case\n        when fo.first_order_id = o.order_id then 'new'\n        else 'repeat'\n      end as user_type,\n      o.amount_total_cents,\n      pa.gross_total_amount_cents,\n      case\n        when o.currency = 'usd' then o.amount_total_cents\n        else pa.gross_total_amount_cents\n      end as total_amount_cents,\n      pa.gross_tax_amount_cents,\n      pa.gross_amount_cents,\n      pa.gross_shipping_amount_cents\n    from o\n\n    left join do\n      on do.order_id = o.order_id\n\n    left join fo\n      on o.user_id = fo.user_id\n\n    left join a \n      on a.order_id = o.order_id\n\n    left join pa\n      on pa.order_id = o.order_id\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': "Database Error in rpc request (from remote system)\n  000904 (42000): SQL compilation error: error line 105 at position 20\n  invalid identifier 'D.DEVICE'", 'raw_sql': "-- import cte's\r\n\r\n/*\r\n\r\nstep notes:\r\n\r\npull out source tables into cte's\r\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\r\nextract cte's we found in query:\r\n    `dbt-public.interview_task.orders` o\r\n    `dbt-public.interview_task.devices` d\r\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\r\n    `dbt-public.interview_task.addresses` oa \r\n    `dbt-public.interview_task.payments`\r\n\r\na couple of errors that were resolved in the set up:\r\n  data type `int64` to `float`\r\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\r\n  transform to lower case (using command pallet -- F1)\r\n  changed `oa` to `a` for standarization\r\n    \r\n*/\r\n\r\nwith \r\no as (select * from {{ source('interview_sample_data', 'interview_orders') }}),\r\nd as (select * from {{ source('interview_sample_data', 'interview_devices') }}),\r\na as (select * from {{ source('interview_sample_data', 'interview_addresses')}}),\r\np as (select * from {{ source('interview_sample_data', 'interview_payments')}}),\r\n\r\n-- logical cte's\r\n\r\n/*\r\n\r\nthere are a lot of left join sub-queries, here is where we will try to simplify those\r\n\r\n*/\r\n\r\ndo as (\r\n  select distinct\r\n    cast(d.type_id as float) as order_id,\r\n    first_value(d.device) over (\r\n      partition by d.type_id\r\n      order by\r\n      d.created_at rows between unbounded preceding\r\n      and unbounded following\r\n      ) as device\r\n  from d\r\n  where d.type = 'order'\r\n),\r\n\r\nfo as (\r\n  select\r\n    fo.user_id,\r\n    min(fo.order_id) as first_order_id\r\n  from o as fo\r\n  where fo.status != 'cancelled'\r\n  group by fo.user_id\r\n),\r\n\r\npa as (\r\n  select\r\n    order_id,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents else 0\r\n      end\r\n    ) as gross_tax_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_cents else 0\r\n      end\r\n    ) as gross_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then amount_shipping_cents else 0\r\n      end\r\n    ) as gross_shipping_amount_cents,\r\n  sum(case\r\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\r\n      end\r\n    ) as gross_total_amount_cents\r\n  from p\r\n  group by order_id\r\n)\r\n\r\n\r\n\r\n\r\n\r\n-- final cte's\r\n-- select statement\r\n\r\n\r\nselect\r\n  *,\r\n  amount_total_cents / 100 as amount_total,\r\n  gross_total_amount_cents/ 100 as gross_total_amount,\r\n  total_amount_cents/ 100 as total_amount,\r\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\r\n  gross_amount_cents/ 100 as gross_amount,\r\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \r\n\r\nfrom (\r\n    \r\n    select\r\n      o.order_id,\r\n      o.user_id,\r\n      o.created_at,\r\n      o.updated_at,\r\n      o.shipped_at,\r\n      o.currency,\r\n      o.status as order_status,\r\n      case\r\n        when o.status in (\r\n          'paid',\r\n          'completed',\r\n          'shipped'\r\n        ) then 'completed'\r\n        else o.status\r\n      end as order_status_category,\r\n      case\r\n        when a.country_code is null then 'null country'\r\n        when a.country_code = 'us' then 'us'\r\n        when a.country_code != 'us' then 'international'\r\n      end as country_type,\r\n      o.shipping_method,\r\n      case\r\n        when do.device = 'web' then 'desktop'\r\n        when do.device in ('ios-app', 'android-app') then 'mobile-app'\r\n        when do.device in ('mobile', 'tablet') then 'mobile-web'\r\n        when nullif(d.device, '') is null then 'unknown'\r\n        else 'error'\r\n      end as purchase_device_type,\r\n      do.device as purchase_device,\r\n      case\r\n        when fo.first_order_id = o.order_id then 'new'\r\n        else 'repeat'\r\n      end as user_type,\r\n      o.amount_total_cents,\r\n      pa.gross_total_amount_cents,\r\n      case\r\n        when o.currency = 'usd' then o.amount_total_cents\r\n        else pa.gross_total_amount_cents\r\n      end as total_amount_cents,\r\n      pa.gross_tax_amount_cents,\r\n      pa.gross_amount_cents,\r\n      pa.gross_shipping_amount_cents\r\n    from o\r\n\r\n    left join do\r\n      on do.order_id = o.order_id\r\n\r\n    left join fo\r\n      on o.user_id = fo.user_id\r\n\r\n    left join a \r\n      on a.order_id = o.order_id\r\n\r\n    left join pa\r\n      on pa.order_id = o.order_id\r\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "-- import cte's\n\n/*\n\nstep notes:\n\npull out source tables into cte's\ncreate a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)\nextract cte's we found in query:\n    `dbt-public.interview_task.orders` o\n    `dbt-public.interview_task.devices` d\n    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order\n    `dbt-public.interview_task.addresses` oa \n    `dbt-public.interview_task.payments`\n\na couple of errors that were resolved in the set up:\n  data type `int64` to `float`\n  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`\n  transform to lower case (using command pallet -- F1)\n  changed `oa` to `a` for standarization\n    \n*/\n\nwith \no as (select * from raw.interview_sample_data.interview_orders),\nd as (select * from raw.interview_sample_data.interview_devices),\na as (select * from raw.interview_sample_data.interview_addresses),\np as (select * from raw.interview_sample_data.interview_payments),\n\n-- logical cte's\n\n/*\n\nthere are a lot of left join sub-queries, here is where we will try to simplify those\n\n*/\n\ndo as (\n  select distinct\n    cast(d.type_id as float) as order_id,\n    first_value(d.device) over (\n      partition by d.type_id\n      order by\n      d.created_at rows between unbounded preceding\n      and unbounded following\n      ) as device\n  from d\n  where d.type = 'order'\n),\n\nfo as (\n  select\n    fo.user_id,\n    min(fo.order_id) as first_order_id\n  from o as fo\n  where fo.status != 'cancelled'\n  group by fo.user_id\n),\n\npa as (\n  select\n    order_id,\n  sum(case\n        when status = 'completed' then tax_amount_cents else 0\n      end\n    ) as gross_tax_amount_cents,\n  sum(case\n        when status = 'completed' then amount_cents else 0\n      end\n    ) as gross_amount_cents,\n  sum(case\n        when status = 'completed' then amount_shipping_cents else 0\n      end\n    ) as gross_shipping_amount_cents,\n  sum(case\n        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0\n      end\n    ) as gross_total_amount_cents\n  from p\n  group by order_id\n)\n\n\n\n\n\n-- final cte's\n-- select statement\n\n\nselect\n  *,\n  amount_total_cents / 100 as amount_total,\n  gross_total_amount_cents/ 100 as gross_total_amount,\n  total_amount_cents/ 100 as total_amount,\n  gross_tax_amount_cents/ 100 as gross_tax_amount,\n  gross_amount_cents/ 100 as gross_amount,\n  gross_shipping_amount_cents/ 100 as gross_shipping_amount \n\nfrom (\n    \n    select\n      o.order_id,\n      o.user_id,\n      o.created_at,\n      o.updated_at,\n      o.shipped_at,\n      o.currency,\n      o.status as order_status,\n      case\n        when o.status in (\n          'paid',\n          'completed',\n          'shipped'\n        ) then 'completed'\n        else o.status\n      end as order_status_category,\n      case\n        when a.country_code is null then 'null country'\n        when a.country_code = 'us' then 'us'\n        when a.country_code != 'us' then 'international'\n      end as country_type,\n      o.shipping_method,\n      case\n        when do.device = 'web' then 'desktop'\n        when do.device in ('ios-app', 'android-app') then 'mobile-app'\n        when do.device in ('mobile', 'tablet') then 'mobile-web'\n        when nullif(d.device, '') is null then 'unknown'\n        else 'error'\n      end as purchase_device_type,\n      do.device as purchase_device,\n      case\n        when fo.first_order_id = o.order_id then 'new'\n        else 'repeat'\n      end as user_type,\n      o.amount_total_cents,\n      pa.gross_total_amount_cents,\n      case\n        when o.currency = 'usd' then o.amount_total_cents\n        else pa.gross_total_amount_cents\n      end as total_amount_cents,\n      pa.gross_tax_amount_cents,\n      pa.gross_amount_cents,\n      pa.gross_shipping_amount_cents\n    from o\n\n    left join do\n      on do.order_id = o.order_id\n\n    left join fo\n      on o.user_id = fo.user_id\n\n    left join a \n      on a.order_id = o.order_id\n\n    left join pa\n      on pa.order_id = o.order_id\n  )\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-04-22 00:00:42.130940 (Thread-75): handling poll request
2022-04-22 00:00:42.131357 (Thread-75): 00:00:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf540700>]}
2022-04-22 00:00:42.132099 (Thread-75): sending response (<Response 41325 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:01:27.917691 (Thread-76): handling status request
2022-04-22 00:01:27.918115 (Thread-76): 00:01:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf53bb80>]}
2022-04-22 00:01:27.918675 (Thread-76): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:01:28.263894 (Thread-77): handling run_sql request
2022-04-22 00:01:28.264283 (Thread-77): 00:01:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf53b040>]}
2022-04-22 00:01:30.769536 (Thread-77): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:01:30.796455 (MainThread): 00:01:30  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c9b542c0-2e8b-4431-93b9-b8270a85d3c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e74096d00>]}
2022-04-22 00:01:30.796991 (MainThread): 00:01:30  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-22 00:01:30.797584 (Thread-1): 00:01:30  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-22 00:01:30.797731 (Thread-1): 00:01:30  Began compiling node rpc.my_new_project.request
2022-04-22 00:01:30.797824 (Thread-1): 00:01:30  Compiling rpc.my_new_project.request
2022-04-22 00:01:30.801312 (Thread-1): 00:01:30  finished collecting timing info
2022-04-22 00:01:30.801445 (Thread-1): 00:01:30  Began executing node rpc.my_new_project.request
2022-04-22 00:01:30.804935 (Thread-1): 00:01:30  Using snowflake connection "rpc.my_new_project.request"
2022-04-22 00:01:30.805057 (Thread-1): 00:01:30  On rpc.my_new_project.request: -- import cte's

/*

step notes:

pull out source tables into cte's
create a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)
extract cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`

a couple of errors that were resolved in the set up:
  data type `int64` to `float`
  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`
  transform to lower case (using command pallet -- F1)
  changed `oa` to `a` for standarization
    
*/

with 
o as (select * from raw.interview_sample_data.interview_orders),
d as (select * from raw.interview_sample_data.interview_devices),
a as (select * from raw.interview_sample_data.interview_addresses),
p as (select * from raw.interview_sample_data.interview_payments),

-- logical cte's

/*

there are a lot of left join sub-queries, here is where we will try to simplify those

*/

do as (
  select distinct
    cast(d.type_id as float) as order_id,
    first_value(d.device) over (
      partition by d.type_id
      order by
      d.created_at rows between unbounded preceding
      and unbounded following
      ) as device
  from d
  where d.type = 'order'
),

fo as (
  select
    fo.user_id,
    min(fo.order_id) as first_order_id
  from o as fo
  where fo.status != 'cancelled'
  group by fo.user_id
),

pa as (
  select
    order_id,
  sum(case
        when status = 'completed' then tax_amount_cents else 0
      end
    ) as gross_tax_amount_cents,
  sum(case
        when status = 'completed' then amount_cents else 0
      end
    ) as gross_amount_cents,
  sum(case
        when status = 'completed' then amount_shipping_cents else 0
      end
    ) as gross_shipping_amount_cents,
  sum(case
        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0
      end
    ) as gross_total_amount_cents
  from p
  group by order_id
)





-- final cte's
-- select statement


select
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

from (
    
    select
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status as order_status,
      case
        when o.status in (
          'paid',
          'completed',
          'shipped'
        ) then 'completed'
        else o.status
      end as order_status_category,
      case
        when a.country_code is null then 'null country'
        when a.country_code = 'us' then 'us'
        when a.country_code != 'us' then 'international'
      end as country_type,
      o.shipping_method,
      case
        when do.device = 'web' then 'desktop'
        when do.device in ('ios-app', 'android-app') then 'mobile-app'
        when do.device in ('mobile', 'tablet') then 'mobile-web'
        when nullif(do.device, '') is null then 'unknown'
        else 'error'
      end as purchase_device_type,
      do.device as purchase_device,
      case
        when fo.first_order_id = o.order_id then 'new'
        else 'repeat'
      end as user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      case
        when o.currency = 'usd' then o.amount_total_cents
        else pa.gross_total_amount_cents
      end as total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    from o

    left join do
      on do.order_id = o.order_id

    left join fo
      on o.user_id = fo.user_id

    left join a 
      on a.order_id = o.order_id

    left join pa
      on pa.order_id = o.order_id
  )
limit 500
/* limit added automatically by dbt cloud */
2022-04-22 00:01:30.805160 (Thread-1): 00:01:30  Opening a new connection, currently in state init
2022-04-22 00:01:31.188940 (Thread-78): handling poll request
2022-04-22 00:01:31.189459 (Thread-78): 00:01:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf5365b0>]}
2022-04-22 00:01:31.190388 (Thread-78): sending response (<Response 7904 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:01:32.661348 (Thread-79): handling poll request
2022-04-22 00:01:32.661732 (Thread-79): 00:01:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf536160>]}
2022-04-22 00:01:32.662186 (Thread-79): sending response (<Response 391 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:01:33.396596 (Thread-1): 00:01:33  SQL status: SUCCESS 500 in 2.59 seconds
2022-04-22 00:01:33.961517 (Thread-80): handling poll request
2022-04-22 00:01:33.961950 (Thread-80): 00:01:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf536ca0>]}
2022-04-22 00:01:33.962467 (Thread-80): sending response (<Response 670 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:01:33.964315 (Thread-1): 00:01:33  finished collecting timing info
2022-04-22 00:01:33.964596 (Thread-1): 00:01:33  On rpc.my_new_project.request: Close
2022-04-22 00:01:35.256522 (Thread-81): handling poll request
2022-04-22 00:01:35.256951 (Thread-81): 00:01:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf5fb730>]}
2022-04-22 00:01:35.265888 (Thread-81): sending response (<Response 154383 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:01:40.441298 (Thread-82): 00:01:40  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-22 00:01:40.441768 (Thread-82): 00:01:40  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-22 00:01:40.446470 (Thread-82): 00:01:40  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-22 00:01:40.489008 (Thread-82): 00:01:40  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aacce2490>]}
2022-04-22 00:01:41.337202 (Thread-83): handling status request
2022-04-22 00:01:41.337795 (Thread-83): 00:01:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaccd0a00>]}
2022-04-22 00:01:41.338253 (Thread-84): handling status request
2022-04-22 00:01:41.338864 (Thread-83): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:01:41.339169 (Thread-84): 00:01:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaf540190>]}
2022-04-22 00:01:41.339886 (Thread-84): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:29:32.916725 (Thread-85): handling status request
2022-04-22 00:29:32.918419 (Thread-85): 00:29:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaccd0fa0>]}
2022-04-22 00:29:32.918908 (Thread-85): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:29:33.301865 (Thread-86): handling run_sql request
2022-04-22 00:29:33.302244 (Thread-86): 00:29:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aaccd0b80>]}
2022-04-22 00:29:35.789685 (Thread-86): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:29:35.819314 (MainThread): 00:29:35  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '525a3076-7fb3-47db-bcf0-00e8cd7e8178', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a48bdcd60>]}
2022-04-22 00:29:35.819825 (MainThread): 00:29:35  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-22 00:29:35.820398 (Thread-1): 00:29:35  Acquiring new snowflake connection "rpc.my_new_project.request"
2022-04-22 00:29:35.820583 (Thread-1): 00:29:35  Began compiling node rpc.my_new_project.request
2022-04-22 00:29:35.820683 (Thread-1): 00:29:35  Compiling rpc.my_new_project.request
2022-04-22 00:29:35.824117 (Thread-1): 00:29:35  finished collecting timing info
2022-04-22 00:29:35.824245 (Thread-1): 00:29:35  Began executing node rpc.my_new_project.request
2022-04-22 00:29:35.827726 (Thread-1): 00:29:35  Using snowflake connection "rpc.my_new_project.request"
2022-04-22 00:29:35.827825 (Thread-1): 00:29:35  On rpc.my_new_project.request: -- import cte's

/*

step notes:

pull out source tables into cte's
create a _source.yml file in order to source those tables (which makes a pretty, more inuitive dag)
extract cte's we found in query:
    `dbt-public.interview_task.orders` o
    `dbt-public.interview_task.devices` d
    `dbt-public.interview_task.orders` as fo -- potentially redunant -- first order
    `dbt-public.interview_task.addresses` oa 
    `dbt-public.interview_task.payments`

a couple of errors that were resolved in the set up:
  data type `int64` to `float`
  rename raw source tables from `dbt-public.interview_` to: `raw.interview_sample_data.interview_`
  transform to lower case (using command pallet -- F1)
  changed `oa` to `a` for standarization
    
*/

with 
o as (select * from raw.interview_sample_data.interview_orders),
d as (select * from raw.interview_sample_data.interview_devices),
a as (select * from raw.interview_sample_data.interview_addresses),
p as (select * from raw.interview_sample_data.interview_payments),

-- logical cte's

/*

there are a lot of left join sub-queries, here is where we will try to simplify those

*/

do as (
  select distinct
    cast(d.type_id as float) as order_id,
    first_value(d.device) over (
      partition by d.type_id
      order by
      d.created_at rows between unbounded preceding
      and unbounded following
      ) as device
  from d
  where d.type = 'order'
),

fo as (
  select
    fo.user_id,
    min(fo.order_id) as first_order_id
  from o as fo
  where fo.status != 'cancelled'
  group by fo.user_id
),

pa as (
  select
    order_id,
  sum(case
        when status = 'completed' then tax_amount_cents else 0
      end
    ) as gross_tax_amount_cents,
  sum(case
        when status = 'completed' then amount_cents else 0
      end
    ) as gross_amount_cents,
  sum(case
        when status = 'completed' then amount_shipping_cents else 0
      end
    ) as gross_shipping_amount_cents,
  sum(case
        when status = 'completed' then tax_amount_cents + amount_cents + amount_shipping_cents else 0
      end
    ) as gross_total_amount_cents
  from p
  group by order_id
),

-- final cte's

final as (

  select
      o.order_id,
      o.user_id,
      o.created_at,
      o.updated_at,
      o.shipped_at,
      o.currency,
      o.status as order_status,
      case
        when o.status in (
          'paid',
          'completed',
          'shipped'
        ) then 'completed'
        else o.status
      end as order_status_category,

      case
        when a.country_code is null then 'null country'
        when a.country_code = 'us' then 'us'
        when a.country_code != 'us' then 'international'
      end as country_type,
      o.shipping_method,
      case
        when do.device = 'web' then 'desktop'
        when do.device in ('ios-app', 'android-app') then 'mobile-app'
        when do.device in ('mobile', 'tablet') then 'mobile-web'
        when nullif(do.device, '') is null then 'unknown'
        else 'error'
      end as purchase_device_type,
      do.device as purchase_device,
      case
        when fo.first_order_id = o.order_id then 'new'
        else 'repeat'
      end as user_type,
      o.amount_total_cents,
      pa.gross_total_amount_cents,
      case
        when o.currency = 'usd' then o.amount_total_cents
        else pa.gross_total_amount_cents
      end as total_amount_cents,
      pa.gross_tax_amount_cents,
      pa.gross_amount_cents,
      pa.gross_shipping_amount_cents
    from o

    left join do
      on do.order_id = o.order_id

    left join fo
      on o.user_id = fo.user_id

    left join a 
      on a.order_id = o.order_id

    left join pa
      on pa.order_id = o.order_id
)

-- select statement


select
  *,
  amount_total_cents / 100 as amount_total,
  gross_total_amount_cents/ 100 as gross_total_amount,
  total_amount_cents/ 100 as total_amount,
  gross_tax_amount_cents/ 100 as gross_tax_amount,
  gross_amount_cents/ 100 as gross_amount,
  gross_shipping_amount_cents/ 100 as gross_shipping_amount 

from final
limit 500
/* limit added automatically by dbt cloud */
2022-04-22 00:29:35.827907 (Thread-1): 00:29:35  Opening a new connection, currently in state init
2022-04-22 00:29:36.135547 (Thread-87): handling poll request
2022-04-22 00:29:36.136017 (Thread-87): 00:29:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab1de1e50>]}
2022-04-22 00:29:36.136967 (Thread-87): sending response (<Response 7911 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:29:37.440787 (Thread-88): handling poll request
2022-04-22 00:29:37.441213 (Thread-88): 00:29:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab1de1910>]}
2022-04-22 00:29:37.441707 (Thread-88): sending response (<Response 390 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:29:38.792410 (Thread-89): handling poll request
2022-04-22 00:29:38.792846 (Thread-89): 00:29:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab1de1eb0>]}
2022-04-22 00:29:38.793364 (Thread-89): sending response (<Response 391 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:29:38.867715 (Thread-1): 00:29:38  SQL status: SUCCESS 500 in 3.04 seconds
2022-04-22 00:29:39.404786 (Thread-1): 00:29:39  finished collecting timing info
2022-04-22 00:29:39.405076 (Thread-1): 00:29:39  On rpc.my_new_project.request: Close
2022-04-22 00:29:40.185709 (Thread-90): handling poll request
2022-04-22 00:29:40.186096 (Thread-90): 00:29:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aacca6460>]}
2022-04-22 00:29:40.195102 (Thread-90): sending response (<Response 153907 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:29:44.815759 (Thread-91): 00:29:44  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-22 00:29:44.816200 (Thread-91): 00:29:44  Partial parsing: updated file: my_new_project://models/_archive/stg_query.sql
2022-04-22 00:29:44.820601 (Thread-91): 00:29:44  1699: static parser successfully parsed _archive/stg_query.sql
2022-04-22 00:29:44.861030 (Thread-91): 00:29:44  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a9409bac0>]}
2022-04-22 00:29:45.869694 (Thread-92): handling status request
2022-04-22 00:29:45.870079 (Thread-92): 00:29:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a9408a760>]}
2022-04-22 00:29:45.870613 (Thread-92): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:29:46.275665 (Thread-93): handling status request
2022-04-22 00:29:46.276055 (Thread-93): 00:29:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab6cefd90>]}
2022-04-22 00:29:46.276512 (Thread-93): sending response (<Response 1562 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:29:55.114261 (Thread-94): 00:29:55  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-04-22 00:29:55.114685 (Thread-94): 00:29:55  Partial parsing: updated file: my_new_project://models/_archive/test_loop.sql
2022-04-22 00:29:55.118350 (Thread-94): 00:29:55  1603: static parser failed on _archive/test_loop.sql
2022-04-22 00:29:55.121629 (Thread-94): 00:29:55  1602: parser fallback to jinja rendering on _archive/test_loop.sql
2022-04-22 00:29:55.168207 (Thread-94): 00:29:55  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a741907c0>]}
2022-04-22 00:29:55.814094 (Thread-95): handling status request
2022-04-22 00:29:55.814508 (Thread-95): 00:29:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a9408a430>]}
2022-04-22 00:29:55.814997 (Thread-95): sending response (<Response 1859 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:29:56.171432 (Thread-96): handling status request
2022-04-22 00:29:56.171856 (Thread-96): 00:29:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a9408a070>]}
2022-04-22 00:29:56.172355 (Thread-96): sending response (<Response 1859 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:30:45.506883 (Thread-97): 00:30:45  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-22 00:30:45.507103 (Thread-97): 00:30:45  Partial parsing enabled, no changes found, skipping parsing
2022-04-22 00:30:45.512196 (Thread-97): 00:30:45  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a740d88b0>]}
2022-04-22 00:30:46.286894 (Thread-98): handling status request
2022-04-22 00:30:46.287338 (Thread-98): 00:30:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a74169220>]}
2022-04-22 00:30:46.287816 (Thread-98): sending response (<Response 1241 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:30:46.523301 (Thread-99): handling status request
2022-04-22 00:30:46.523692 (Thread-99): 00:30:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a7415ed60>]}
2022-04-22 00:30:46.547753 (Thread-99): sending response (<Response 1241 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:32:54.013343 (Thread-100): handling status request
2022-04-22 00:32:54.015138 (Thread-100): 00:32:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a7415ec70>]}
2022-04-22 00:32:54.015633 (Thread-100): sending response (<Response 1219 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:32:54.022244 (Thread-101): handling list request
2022-04-22 00:32:54.022543 (Thread-101): 00:32:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a7415e9a0>]}
2022-04-22 00:32:54.025893 (Thread-102): handling status request
2022-04-22 00:32:54.026613 (Thread-102): 00:32:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a9408d640>]}
2022-04-22 00:32:54.027810 (Thread-102): sending response (<Response 1219 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:32:54.062512 (Thread-101): 00:32:54  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a9408de50>]}
2022-04-22 00:32:54.035901 (Thread-103): handling list request
2022-04-22 00:32:54.062808 (Thread-101): 00:32:54  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-22 00:32:54.036067 (Thread-103): 00:32:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a7417f100>]}
2022-04-22 00:32:54.063670 (Thread-103): 00:32:54  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a94091bb0>]}
2022-04-22 00:32:54.074368 (Thread-101): sending response (<Response 4003 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:32:54.063928 (Thread-103): 00:32:54  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
2022-04-22 00:32:54.075278 (Thread-103): sending response (<Response 2952 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:33:44.131920 (Thread-104): 00:33:44  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-04-22 00:33:44.132165 (Thread-104): 00:33:44  Partial parsing enabled, no changes found, skipping parsing
2022-04-22 00:33:44.138030 (Thread-104): 00:33:44  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a7406d7f0>]}
2022-04-22 00:33:44.905512 (Thread-105): handling status request
2022-04-22 00:33:44.905916 (Thread-105): 00:33:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a740a9310>]}
2022-04-22 00:33:44.906416 (Thread-105): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:33:45.344054 (Thread-106): handling status request
2022-04-22 00:33:45.344440 (Thread-106): 00:33:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a740a9460>]}
2022-04-22 00:33:45.344910 (Thread-106): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.37
2022-04-22 00:34:06.086198 (Thread-107): handling status request
2022-04-22 00:34:06.086613 (Thread-107): 00:34:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5ce8a185-c08d-44a4-a4f2-ae4ad553881f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a740a9040>]}
2022-04-22 00:34:06.087055 (Thread-107): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.37
